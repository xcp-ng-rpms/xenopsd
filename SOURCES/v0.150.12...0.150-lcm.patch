From 8a145f5974193f9048b4a1a53a9a202b1adcaacd Mon Sep 17 00:00:00 2001
From: Pau Ruiz Safont <pau.safont@citrix.com>
Date: Wed, 18 May 2022 10:21:18 +0100
Subject: [PATCH 1/2] test: run as part of the xapi-xenopsd package

Otherwise the CI tries to run them as part of xapi-xenopsd-cli and will
fail to find a library

Signed-off-by: Pau Ruiz Safont <pau.safont@citrix.com>
---
 test/dune             | 1 +
 xapi-xenopsd-cli.opam | 8 ++++----
 2 files changed, 5 insertions(+), 4 deletions(-)

diff --git a/test/dune b/test/dune
index 2b37820a0..cb2a723ba 100644
--- a/test/dune
+++ b/test/dune
@@ -8,6 +8,7 @@
 
 (alias
  (name runtest)
+ (package xapi-xenopsd)
  (deps test.exe)
  (action
   (run %{deps} --show-errors)
diff --git a/xapi-xenopsd-cli.opam b/xapi-xenopsd-cli.opam
index 44edc0dc6..60ca247a0 100644
--- a/xapi-xenopsd-cli.opam
+++ b/xapi-xenopsd-cli.opam
@@ -1,9 +1,9 @@
 opam-version: "2.0"
 maintainer: "xen-api@lists.xen.org"
 authors: [ "xen-api@lists.xen.org" ]
-homepage: "https://github.com/xapi-project/xenops-cli"
-bug-reports: "https://github.com/xapi-project/xenops-cli/issues"
-dev-repo: "git+https://github.com/xapi-project/xenops-cli.git"
+homepage: "https://github.com/xapi-project/xenopsd"
+bug-reports: "https://github.com/xapi-project/xenopsd/issues"
+dev-repo: "git+https://github.com/xapi-project/xenopsd.git"
 build: [
   ["dune" "build" "-p" name]
   ["dune" "runtest" "-p" name "-j" jobs] {with-test}
@@ -23,5 +23,5 @@ description: """
 A simple command-line tool for interacting with xenopsd
 """
 url {
-  src: "https://github.com/xapi-project/xenops-cli/archive/master/master.tar.gz"
+  src: "https://github.com/xapi-project/xenopsd/archive/master/master.tar.gz"
 }

From fa9061d2ad6eb6716d084fe2f8d2d0268bd5cff3 Mon Sep 17 00:00:00 2001
From: Christian Lindig <christian.lindig@citrix.com>
Date: Wed, 17 Aug 2022 15:52:31 +0100
Subject: [PATCH 2/2] Reformat for compatibility with xapi

Current development for xenopsd happens in xapi.git, where xenopsd has
been integrated. To facilitate backports, reformat xenopsd to the same
format used currently in xapi.git.

Signed-off-by: Christian Lindig <christian.lindig@citrix.com>
---
 cli/main.ml                                  |  69 +-
 cli/xn.ml                                    |  78 ++-
 configure.ml                                 |  24 +-
 lib/bootloader.ml                            |  18 +-
 lib/cancellable_subprocess.ml                |  24 +-
 lib/io.ml                                    |   3 +-
 lib/resources.ml                             |  24 +-
 lib/softaffinity.ml                          |   3 +-
 lib/storage.ml                               |  19 +-
 lib/suspend_image.ml                         |  36 +-
 lib/topology.ml                              |  18 +-
 lib/xenops_hooks.ml                          |   5 +-
 lib/xenops_sandbox.ml                        |  12 +-
 lib/xenops_server.ml                         | 377 +++++++----
 lib/xenops_server_simulator.ml               |  51 +-
 lib/xenops_utils.ml                          |  68 +-
 lib/xenopsd.ml                               | 104 ++-
 list_domains/list_domains.ml                 |  15 +-
 suspend_image_viewer/suspend_image_viewer.ml |   6 +-
 test/test.ml                                 | 129 ++--
 test/test_topology.ml                        |  61 +-
 tools/set_domain_uuid.ml                     |   3 +-
 xc/cancel_utils.ml                           |  17 +-
 xc/cancel_utils_test.ml                      |   6 +-
 xc/device.ml                                 | 324 ++++++---
 xc/device_common.ml                          |  36 +-
 xc/domain.ml                                 | 150 +++--
 xc/domain_sethandle.ml                       |   9 +-
 xc/emu_manager.ml                            |  10 +-
 xc/hotplug.ml                                |  30 +-
 xc/list_domains.ml                           |  15 +-
 xc/memory_breakdown.ml                       |  39 +-
 xc/memory_summary.ml                         |   6 +-
 xc/readln.ml                                 |   3 +-
 xc/stats.ml                                  |  29 +-
 xc/xc_resources.ml                           |  12 +-
 xc/xenbus_utils.ml                           |   2 +
 xc/xenguestHelper.ml                         |  13 +-
 xc/xenops_helpers.ml                         |   3 +-
 xc/xenops_server_xen.ml                      | 655 +++++++++++++------
 xc/xenstore_readdir.ml                       |   9 +-
 41 files changed, 1684 insertions(+), 831 deletions(-)

diff --git a/cli/main.ml b/cli/main.ml
index 1b1515035..a8e15edd5 100644
--- a/cli/main.ml
+++ b/cli/main.ml
@@ -48,7 +48,8 @@ let common_options_t =
     Arg.(
       value
       & opt file !Xenops_interface.default_path
-      & info ["socket"] ~docs ~doc)
+      & info ["socket"] ~docs ~doc
+    )
   in
   let queue =
     let default = Some "org.xen.xapi.xenops.classic" in
@@ -71,7 +72,8 @@ let events_cmd =
     @ help
   in
   ( Term.(ret (pure Xn.events $ common_options_t))
-  , Term.info "events" ~sdocs:_common_options ~doc ~man )
+  , Term.info "events" ~sdocs:_common_options ~doc ~man
+  )
 
 let create_cmd =
   let doc = "register a VM and start it immediately" in
@@ -92,7 +94,8 @@ let create_cmd =
     Arg.(value & flag & info ["console"] ~doc)
   in
   ( Term.(ret (pure Xn.create $ common_options_t $ filename $ console))
-  , Term.info "create" ~sdocs:_common_options ~doc ~man )
+  , Term.info "create" ~sdocs:_common_options ~doc ~man
+  )
 
 let add_cmd =
   let doc = "register a new VM with xenopsd" in
@@ -104,7 +107,8 @@ let add_cmd =
     Arg.(value & pos 0 (some file) None & info [] ~doc)
   in
   ( Term.(ret (pure Xn.add $ common_options_t $ filename))
-  , Term.info "add" ~sdocs:_common_options ~doc ~man )
+  , Term.info "add" ~sdocs:_common_options ~doc ~man
+  )
 
 let list_cmd =
   let doc = "list the VMs registered with xenopsd" in
@@ -122,7 +126,8 @@ let list_cmd =
     @ help
   in
   ( Term.(pure Xn.list $ common_options_t)
-  , Term.info "list" ~sdocs:_common_options ~doc ~man )
+  , Term.info "list" ~sdocs:_common_options ~doc ~man
+  )
 
 let vm_arg verb =
   let doc = Printf.sprintf "The name or UUID of the VM to be %s." verb in
@@ -154,7 +159,8 @@ let remove_cmd =
     ]
   in
   ( Term.(ret (pure Xn.remove $ common_options_t $ vm))
-  , Term.info "remove" ~sdocs:_common_options ~doc ~man )
+  , Term.info "remove" ~sdocs:_common_options ~doc ~man
+  )
 
 let start_cmd =
   let vm = vm_arg "started" in
@@ -184,7 +190,8 @@ let start_cmd =
     @ help
   in
   ( Term.(ret (pure Xn.start $ common_options_t $ paused $ console $ vm))
-  , Term.info "start" ~sdocs:_common_options ~doc ~man )
+  , Term.info "start" ~sdocs:_common_options ~doc ~man
+  )
 
 let console_cmd =
   let vm =
@@ -204,7 +211,8 @@ let console_cmd =
     @ help
   in
   ( Term.(ret (pure Xn.console_connect $ common_options_t $ vm))
-  , Term.info "console" ~sdocs:_common_options ~doc ~man )
+  , Term.info "console" ~sdocs:_common_options ~doc ~man
+  )
 
 let shutdown_cmd =
   let vm = vm_arg "shutdown and powered off" in
@@ -231,7 +239,8 @@ let shutdown_cmd =
     @ help
   in
   ( Term.(ret (pure Xn.shutdown $ common_options_t $ timeout $ vm))
-  , Term.info "shutdown" ~sdocs:_common_options ~doc ~man )
+  , Term.info "shutdown" ~sdocs:_common_options ~doc ~man
+  )
 
 let reboot_cmd =
   let vm = vm_arg "rebooted" in
@@ -259,7 +268,8 @@ let reboot_cmd =
     @ help
   in
   ( Term.(ret (pure Xn.reboot $ common_options_t $ timeout $ vm))
-  , Term.info "reboot" ~sdocs:_common_options ~doc ~man )
+  , Term.info "reboot" ~sdocs:_common_options ~doc ~man
+  )
 
 let suspend_cmd =
   let vm = vm_arg "suspended" in
@@ -281,7 +291,8 @@ let suspend_cmd =
     @ help
   in
   ( Term.(ret (pure Xn.suspend $ common_options_t $ device $ vm))
-  , Term.info "suspend" ~sdocs:_common_options ~doc ~man )
+  , Term.info "suspend" ~sdocs:_common_options ~doc ~man
+  )
 
 let resume_cmd =
   let vm = vm_arg "resumed" in
@@ -303,7 +314,8 @@ let resume_cmd =
     @ help
   in
   ( Term.(ret (pure Xn.resume $ common_options_t $ device $ vm))
-  , Term.info "resume" ~sdocs:_common_options ~doc ~man )
+  , Term.info "resume" ~sdocs:_common_options ~doc ~man
+  )
 
 let pause_cmd =
   let vm = vm_arg "paused" in
@@ -322,7 +334,8 @@ let pause_cmd =
     @ help
   in
   ( Term.(ret (pure Xn.pause $ common_options_t $ vm))
-  , Term.info "pause" ~sdocs:_common_options ~doc ~man )
+  , Term.info "pause" ~sdocs:_common_options ~doc ~man
+  )
 
 let unpause_cmd =
   let vm = vm_arg "unpaused" in
@@ -340,7 +353,8 @@ let unpause_cmd =
     @ help
   in
   ( Term.(ret (pure Xn.unpause $ common_options_t $ vm))
-  , Term.info "unpause" ~sdocs:_common_options ~doc ~man )
+  , Term.info "unpause" ~sdocs:_common_options ~doc ~man
+  )
 
 let import_cmd =
   let filename =
@@ -367,7 +381,8 @@ let import_cmd =
     @ help
   in
   ( Term.(ret (pure Xn.import $ common_options_t $ metadata $ filename))
-  , Term.info "import" ~sdocs:_common_options ~doc ~man )
+  , Term.info "import" ~sdocs:_common_options ~doc ~man
+  )
 
 let export_cmd =
   let vm = vm_arg "exported" in
@@ -395,8 +410,10 @@ let export_cmd =
     @ help
   in
   ( Term.(
-      ret (pure Xn.export $ common_options_t $ metadata $ xm $ filename $ vm))
-  , Term.info "export" ~sdocs:_common_options ~doc ~man )
+      ret (pure Xn.export $ common_options_t $ metadata $ xm $ filename $ vm)
+    )
+  , Term.info "export" ~sdocs:_common_options ~doc ~man
+  )
 
 let diagnostics_cmd =
   let doc = "retrieve diagnostic information" in
@@ -408,7 +425,8 @@ let diagnostics_cmd =
     @ help
   in
   ( Term.(ret (pure Xn.diagnostics $ common_options_t))
-  , Term.info "diagnostics" ~sdocs:_common_options ~doc ~man )
+  , Term.info "diagnostics" ~sdocs:_common_options ~doc ~man
+  )
 
 let tasks_cmd =
   let doc = "List in-progress tasks" in
@@ -416,7 +434,8 @@ let tasks_cmd =
     [`S "DESCRIPTION"; `P "Describe the set of in-progress tasks."] @ help
   in
   ( Term.(ret (pure Xn.task_list $ common_options_t))
-  , Term.info "tasks" ~sdocs:_common_options ~doc ~man )
+  , Term.info "tasks" ~sdocs:_common_options ~doc ~man
+  )
 
 let task_cancel_cmd =
   let doc = "Cancel an in-progress task" in
@@ -434,7 +453,8 @@ let task_cancel_cmd =
     Arg.(value & pos 0 (some string) None & info [] ~doc)
   in
   ( Term.(ret (pure Xn.task_cancel $ common_options_t $ task))
-  , Term.info "task-cancel" ~sdocs:_common_options ~doc ~man )
+  , Term.info "task-cancel" ~sdocs:_common_options ~doc ~man
+  )
 
 let cd_eject_cmd =
   let doc = "Eject a CDROM" in
@@ -444,7 +464,8 @@ let cd_eject_cmd =
     Arg.(value & pos 0 (some string) None & info [] ~doc)
   in
   ( Term.(ret (pure Xn.cd_eject $ common_options_t $ vbd))
-  , Term.info "cd-eject" ~sdocs:_common_options ~doc ~man )
+  , Term.info "cd-eject" ~sdocs:_common_options ~doc ~man
+  )
 
 let stat_vm_cmd =
   let doc = "Query the runtime status of a running VM." in
@@ -456,13 +477,15 @@ let stat_vm_cmd =
     Arg.(required & pos 0 (some string) None & info [] ~doc ~docv:"uuid")
   in
   ( Term.(ret (pure Xn.stat_vm $ common_options_t $ vm))
-  , Term.info "vm-stat" ~sdocs:_common_options ~doc ~man )
+  , Term.info "vm-stat" ~sdocs:_common_options ~doc ~man
+  )
 
 let default_cmd =
   let doc = "interact with the XCP xenopsd VM management service" in
   let man = help in
   ( Term.(ret (pure (fun _ -> `Help (`Pager, None)) $ common_options_t))
-  , Term.info "xenops-cli" ~version:"1.0.0" ~sdocs:_common_options ~doc ~man )
+  , Term.info "xenops-cli" ~version:"1.0.0" ~sdocs:_common_options ~doc ~man
+  )
 
 let cmds =
   [
diff --git a/cli/xn.ml b/cli/xn.ml
index 1ee8df905..22ea4aa72 100644
--- a/cli/xn.ml
+++ b/cli/xn.ml
@@ -157,7 +157,8 @@ let success_task f id =
             | Error (`Msg x) ->
                 Xenopsd_error
                   (Internal_error
-                     (Printf.sprintf "Error unmarshalling failure: %s" x))
+                     (Printf.sprintf "Error unmarshalling failure: %s" x)
+                  )
           in
           match exn with
           | Xenopsd_error (Failed_to_contact_remote_service x) ->
@@ -168,7 +169,8 @@ let success_task f id =
               raise exn
         )
       | Task.Pending _ ->
-          failwith "task pending")
+          failwith "task pending"
+    )
     (fun () -> Client.TASK.destroy dbg id)
 
 let parse_source x =
@@ -257,7 +259,8 @@ let parse_pci vm_id (x, idx) =
             | _ ->
                 Printf.fprintf stderr
                   "Failed to parse PCI option: %s. It should be key=value.\n" x ;
-                exit 2)
+                exit 2
+          )
           options
       in
       let bool_opt k opts =
@@ -390,7 +393,8 @@ let parse_vif vm_id (x, idx) =
               "I don't understand '%s'. Please use \
                'mac=xx:xx:xx:xx:xx:xx,bridge=xenbrX'.\n"
               x ;
-            exit 2)
+            exit 2
+      )
       xs
   in
   {
@@ -447,7 +451,9 @@ let print_vm id =
       ( _disk
       , Printf.sprintf "[ %s ]"
           (String.concat ", "
-             (List.map (fun x -> Printf.sprintf "'%s'" (print_disk x)) vbds)) )
+             (List.map (fun x -> Printf.sprintf "'%s'" (print_disk x)) vbds)
+          )
+      )
     ]
   in
   let vifs = Client.VIF.list dbg id |> List.map fst in
@@ -456,7 +462,9 @@ let print_vm id =
       ( _vif
       , Printf.sprintf "[ %s ]"
           (String.concat ", "
-             (List.map (fun x -> Printf.sprintf "'%s'" (print_vif x)) vifs)) )
+             (List.map (fun x -> Printf.sprintf "'%s'" (print_vif x)) vifs)
+          )
+      )
     ]
   in
   let pcis = Client.PCI.list dbg id |> List.map fst in
@@ -469,7 +477,9 @@ let print_vm id =
       ( _pci
       , Printf.sprintf "[ %s ]"
           (String.concat ", "
-             (List.map (fun x -> Printf.sprintf "'%s'" (print_pci x)) pcis)) )
+             (List.map (fun x -> Printf.sprintf "'%s'" (print_pci x)) pcis)
+          )
+      )
     ]
   in
   let global_pci_opts =
@@ -481,7 +491,8 @@ let print_vm id =
   String.concat "\n"
     (List.map
        (fun (k, v) -> Printf.sprintf "%s=%s" k v)
-       (name @ boot @ vcpus @ memory @ vbds @ vifs @ pcis @ global_pci_opts))
+       (name @ boot @ vcpus @ memory @ vbds @ vifs @ pcis @ global_pci_opts)
+    )
 
 let canonicalise_filename x =
   try
@@ -519,8 +530,10 @@ let add' _copts x () =
             List.rev
               (List.fold_left
                  (fun acc x ->
-                   match x.disk with None -> acc | Some x -> x :: acc)
-                 [] disks)
+                   match x.disk with None -> acc | Some x -> x :: acc
+                 )
+                 [] disks
+              )
           in
           let open Vm in
           let builder_info =
@@ -674,7 +687,8 @@ let add' _copts x () =
           let one x = x |> parse_pci id |> Client.PCI.add dbg in
           let (_ : Pci.id list) = List.map one pcis in
           Printf.fprintf stdout "%s\n" id ;
-          `Ok id)
+          `Ok id
+        )
         (fun () -> close_in ic)
 
 let add copts x () =
@@ -706,7 +720,8 @@ let list_verbose () =
       Printf.printf "%-45s%-5s\n" vm.Vm.name
         (state.Vm.power_state |> string_of_power_state) ;
       Printf.printf "  %s\n" (vm |> rpc_of Vm.t |> Jsonrpc.to_string) ;
-      Printf.printf "  %s\n" (state |> rpc_of Vm.state |> Jsonrpc.to_string))
+      Printf.printf "  %s\n" (state |> rpc_of Vm.state |> Jsonrpc.to_string)
+    )
     vms
 
 let list_compact () =
@@ -785,8 +800,7 @@ let pp x =
         [
           Line "{"
         ; Block
-            (List.concat
-               (List.map (fun (s, t) -> Line (s ^ ": ") :: to_t t) xs))
+            (List.concat (List.map (fun (s, t) -> Line (s ^ ": ") :: to_t t) xs))
         ; Line "}"
         ]
     | Base64 x ->
@@ -905,7 +919,8 @@ let import_metadata _copts filename =
           | n ->
               Buffer.add_bytes buf (Bytes.sub line 0 n)
         done
-      with End_of_file -> ())
+      with End_of_file -> ()
+    )
     (fun () -> close_in ic) ;
   let txt = Buffer.contents buf in
   let id = Client.VM.import_metadata dbg txt in
@@ -1056,7 +1071,8 @@ let vbd_list x =
           | Some (VDI path) ->
               path |> trim 32
         in
-        line id position mode ty plugged disk disk2)
+        line id position mode ty plugged disk disk2
+      )
       vbds
   in
   List.iter print_endline (header :: lines)
@@ -1072,7 +1088,8 @@ let console_list _copts x =
         let protocol =
           match c.Vm.protocol with Vm.Rfb -> "RFB" | Vm.Vt100 -> "VT100"
         in
-        line protocol (string_of_int c.Vm.port))
+        line protocol (string_of_int c.Vm.port)
+      )
       s.Vm.consoles
   in
   List.iter print_endline (header :: lines)
@@ -1179,7 +1196,8 @@ let raw_console_proxy sockaddr =
         (fun () ->
           Unix.connect s sockaddr ;
           delay := 0.1 ;
-          proxy s)
+          proxy s
+        )
         (fun () -> Unix.close s)
     with
     | Unix.Unix_error (_, _, _) when !delay <= long_connection_retry_timeout ->
@@ -1214,7 +1232,8 @@ let vncviewer_binary =
           then
             Some path
           else
-            None)
+            None
+    )
     None dirs
 
 let unix_proxy path =
@@ -1283,13 +1302,13 @@ let console_connect' _copts x =
   List.iter
     (fun exe ->
       if Sys.file_exists exe then
-        Unix.execv exe [|exe; string_of_int (List.hd s.Vm.domids)|])
+        Unix.execv exe [|exe; string_of_int (List.hd s.Vm.domids)|]
+    )
     xenconsoles ;
   Printf.fprintf stderr "Failed to find a text console.\n%!" ;
   exit 1
 
-let console_connect copts x =
-  diagnose_error (need_vm (console_connect' copts) x)
+let console_connect copts x = diagnose_error (need_vm (console_connect' copts) x)
 
 let start' copts paused console x =
   let vm, _ = find_by_name x in
@@ -1351,7 +1370,8 @@ let pci_list x =
           Printf.sprintf "%04x:%02x:%02x.%01x" pci.address.domain
             pci.address.bus pci.address.dev pci.address.fn
         in
-        line id (string_of_int pci.position) bdf)
+        line id (string_of_int pci.position) bdf
+      )
       pcis
   in
   List.iter print_endline (header :: lines)
@@ -1411,7 +1431,8 @@ let rec events_watch from =
         | Vgpu id ->
             Printf.sprintf "VGPU %s.%s" (fst id) (snd id)
         | Vusb id ->
-            Printf.sprintf "VUSB %s.%s" (fst id) (snd id))
+            Printf.sprintf "VUSB %s.%s" (fst id) (snd id)
+        )
       events
   in
   List.iter (fun x -> Printf.printf "%-8d %s\n" next x) lines ;
@@ -1438,8 +1459,10 @@ let task_list _ =
       List.iter
         (fun (name, state) ->
           Printf.printf "  |_ %-30s %s\n" name
-            (state |> rpc_of Task.state |> Jsonrpc.to_string))
-        t.Task.subtasks)
+            (state |> rpc_of Task.state |> Jsonrpc.to_string)
+        )
+        t.Task.subtasks
+    )
     all ;
   `Ok ()
 
@@ -1486,7 +1509,8 @@ let old_main () =
           ) else if x = key then
             (acc, true)
           else
-            (x :: acc, false))
+            (x :: acc, false)
+        )
         ([], false) args
       |> fst
       |> List.rev
diff --git a/configure.ml b/configure.ml
index e782c785f..8b24a04d7 100644
--- a/configure.ml
+++ b/configure.ml
@@ -16,14 +16,16 @@ let libexecdir =
   Arg.(
     value
     & opt string "/usr/lib/xenopsd"
-    & info ["libexecdir"] ~docv:"LIBEXECDIR" ~doc)
+    & info ["libexecdir"] ~docv:"LIBEXECDIR" ~doc
+  )
 
 let qemu_wrapper_dir =
   let doc = "Set the directory for installing xen helper executables" in
   Arg.(
     value
     & opt string "/usr/lib/xenopsd"
-    & info ["qemu_wrapper_dir"] ~docv:"QEMU_WRAPPER_DIR" ~doc)
+    & info ["qemu_wrapper_dir"] ~docv:"QEMU_WRAPPER_DIR" ~doc
+  )
 
 let coverage =
   let doc = "Enable coverage profiling" in
@@ -34,7 +36,8 @@ let scriptsdir =
   Arg.(
     value
     & opt string "/usr/lib/xenopsd/scripts"
-    & info ["scriptsdir"] ~docv:"SCRIPTSDIR" ~doc)
+    & info ["scriptsdir"] ~docv:"SCRIPTSDIR" ~doc
+  )
 
 let etcdir =
   let doc = "Set the directory for installing configuration files" in
@@ -43,14 +46,16 @@ let etcdir =
 let mandir =
   let doc = "Set the directory for installing manpages" in
   Arg.(
-    value & opt string "/usr/share/man" & info ["mandir"] ~docv:"MANDIR" ~doc)
+    value & opt string "/usr/share/man" & info ["mandir"] ~docv:"MANDIR" ~doc
+  )
 
 let optdir =
   let doc = "Set the directory for installing system binaries" in
   Arg.(
     value
     & opt string "/opt/xensource/libexec"
-    & info ["optdir"] ~docv:"OPTDIR" ~doc)
+    & info ["optdir"] ~docv:"OPTDIR" ~doc
+  )
 
 let info =
   let doc = "Configures a package" in
@@ -90,7 +95,8 @@ let find_ml_val verbose name libs =
     Sys.command
       (Printf.sprintf "ocamlfind ocamlc -package %s -c %s %s"
          (String.concat "," libs) ml_file
-         (if verbose then "" else "2>/dev/null"))
+         (if verbose then "" else "2>/dev/null")
+      )
     = 0
   in
   if Sys.file_exists ml_file then Sys.remove ml_file ;
@@ -125,7 +131,8 @@ let find_xentoollog verbose =
   let found =
     Sys.command
       (Printf.sprintf "cc -Werror %s -lxentoollog -o %s %s" c_file exe_file
-         (if verbose then "" else "2>/dev/null"))
+         (if verbose then "" else "2>/dev/null")
+      )
     = 0
   in
   if Sys.file_exists c_file then Sys.remove c_file ;
@@ -197,7 +204,8 @@ let configure_t =
     $ etcdir
     $ mandir
     $ optdir
-    $ coverage)
+    $ coverage
+  )
 
 let () =
   match Term.eval (configure_t, info) with `Error _ -> exit 1 | _ -> exit 0
diff --git a/lib/bootloader.ml b/lib/bootloader.ml
index 30c047c05..e66eb9392 100644
--- a/lib/bootloader.ml
+++ b/lib/bootloader.ml
@@ -115,7 +115,8 @@ let parse_output_simple x =
       | Some _ ->
           raise
             (Bad_error
-               ("More than one kernel line when parsing bootloader result: " ^ x))
+               ("More than one kernel line when parsing bootloader result: " ^ x)
+            )
       | None ->
           debug "Using kernel line from bootloader output: %s" l ;
           {acc with kernel= Some (String.sub l pos (String.length l - pos))}
@@ -127,7 +128,8 @@ let parse_output_simple x =
             (Bad_error
                ("More than one ramdisk line when parsing bootloader result: "
                ^ x
-               ))
+               )
+            )
       | None ->
           debug "Using ramdisk line from bootloader output: %s" l ;
           {acc with ramdisk= Some (String.sub l pos (String.length l - pos))}
@@ -137,7 +139,8 @@ let parse_output_simple x =
       | Some _ ->
           raise
             (Bad_error
-               ("More than one args line when parsing bootloader result: " ^ x))
+               ("More than one args line when parsing bootloader result: " ^ x)
+            )
       | None ->
           debug "Using args line from bootloader output: %s" l ;
           {acc with args= Some (String.sub l pos (String.length l - pos))}
@@ -149,7 +152,8 @@ let parse_output_simple x =
           (Bad_error
              ("Unrecognised start of line when parsing bootloader result: line="
              ^ l
-             ))
+             )
+          )
   in
   let parse_line acc l =
     try parse_line_optimistic acc l with Not_found -> acc
@@ -195,7 +199,8 @@ let sanity_check_path p =
   | p when Filename.is_relative p ->
       raise
         (Bad_error
-           ("Bootloader returned a relative path for kernel or ramdisk: " ^ p))
+           ("Bootloader returned a relative path for kernel or ramdisk: " ^ p)
+        )
   | p -> (
       let canonical_path = Xapi_stdext_unix.Unixext.resolve_dot_and_dotdot p in
       match Filename.dirname canonical_path with
@@ -209,7 +214,8 @@ let sanity_check_path p =
                ("Malicious guest? Bootloader returned a kernel or ramdisk path \
                  outside the allowed directories: "
                ^ p
-               ))
+               )
+            )
     )
 
 (** Extract the default kernel using the -q option *)
diff --git a/lib/cancellable_subprocess.ml b/lib/cancellable_subprocess.ml
index 049ec68a5..0ba4edeb7 100644
--- a/lib/cancellable_subprocess.ml
+++ b/lib/cancellable_subprocess.ml
@@ -27,7 +27,8 @@ let run (task : Xenops_task.task_handle) ?env ?stdin fds
     Option.map
       (fun str ->
         let x, y = Unix.pipe () in
-        (str, x, y))
+        (str, x, y)
+      )
       stdin
   in
   (* Used so that cancel -> kills subprocess -> Unix.WSIGNALED -> raise
@@ -51,16 +52,21 @@ let run (task : Xenops_task.task_handle) ?env ?stdin fds
                       (fun () ->
                         cancelled := true ;
                         info "Cancelling: sending SIGKILL to %d" pid' ;
-                        try Unix.kill pid' Sys.sigkill with _ -> ())
+                        try Unix.kill pid' Sys.sigkill with _ -> ()
+                      )
                       (fun () ->
                         Option.iter
                           (fun (str, _, wr) ->
-                            Unixext.really_write wr str 0 (String.length str))
+                            Unixext.really_write wr str 0 (String.length str)
+                          )
                           stdinandpipes ;
                         done_waitpid := true ;
-                        snd (Forkhelpers.waitpid t)))
-                  (fun () ->
-                    if not !done_waitpid then Forkhelpers.dontwaitpid t)))
+                        snd (Forkhelpers.waitpid t)
+                      )
+                  )
+                  (fun () -> if not !done_waitpid then Forkhelpers.dontwaitpid t)
+            )
+        )
       with
       | Success (out, Success (err, status)) -> (
         match status with
@@ -83,6 +89,8 @@ let run (task : Xenops_task.task_handle) ?env ?stdin fds
             )
       )
       | Success (_, Failure (_, exn)) | Failure (_, exn) ->
-          raise exn)
+          raise exn
+    )
     (fun () ->
-      Option.iter (fun (_, x, y) -> Unix.close x ; Unix.close y) stdinandpipes)
+      Option.iter (fun (_, x, y) -> Unix.close x ; Unix.close y) stdinandpipes
+    )
diff --git a/lib/io.ml b/lib/io.ml
index 14a37cb32..354cea6d5 100644
--- a/lib/io.ml
+++ b/lib/io.ml
@@ -115,7 +115,8 @@ let unmarshall_int64 ~endianness buffer =
     ||| shift_left e 24
     ||| shift_left f 16
     ||| shift_left g 8
-    ||| h)
+    ||| h
+  )
 
 let read_int64 ~endianness fd =
   let buffer = read fd 8 in
diff --git a/lib/resources.ml b/lib/resources.ml
index e4db50861..aee7bc4db 100644
--- a/lib/resources.ml
+++ b/lib/resources.ml
@@ -48,15 +48,18 @@ let hvm_guests =
   ; ( X_OK
     , "qemu-dm-wrapper"
     , qemu_dm_wrapper
-    , "path to the qemu-dm-wrapper script" )
+    , "path to the qemu-dm-wrapper script"
+    )
   ; ( X_OK
     , "qemu-system-i386"
     , qemu_system_i386
-    , "path to the qemu-system-i386 binary" )
+    , "path to the qemu-system-i386 binary"
+    )
   ; ( X_OK
     , "upstream-compat-qemu-dm-wrapper"
     , upstream_compat_qemu_dm_wrapper
-    , "path to the upstream compat qemu-dm-wrapper script" )
+    , "path to the upstream compat qemu-dm-wrapper script"
+    )
   ]
 
 let pv_guests =
@@ -70,7 +73,8 @@ let pvinpvh_guests =
     ( X_OK
     , "pvinpvh-xen"
     , pvinpvh_xen
-    , "path to the inner-xen for PV-in-PVH guests" )
+    , "path to the inner-xen for PV-in-PVH guests"
+    )
   ]
 
 (* libvirt xc *)
@@ -89,21 +93,25 @@ let nonessentials =
     ( X_OK
     , "convert-legacy-stream"
     , legacy_conv_tool
-    , "path to convert-legacy-stream tool" )
+    , "path to convert-legacy-stream tool"
+    )
   ; (R_OK, "cpu-info-file", cpu_info_file, "Where to cache boot-time CPU info")
   ; ( X_OK
     , "verify-stream-v2"
     , verify_libxc_v2
-    , "tool to verify suspend image libxc stream" )
+    , "tool to verify suspend image libxc stream"
+    )
   ]
 
 let make_resources ~essentials ~nonessentials =
   let open Xcp_service in
   List.map
     (fun (perm, name, path, description) ->
-      {essential= true; name; description; path; perms= [perm]})
+      {essential= true; name; description; path; perms= [perm]}
+    )
     essentials
   @ List.map
       (fun (perm, name, path, description) ->
-        {essential= false; name; description; path; perms= [perm]})
+        {essential= false; name; description; path; perms= [perm]}
+      )
       nonessentials
diff --git a/lib/softaffinity.ml b/lib/softaffinity.ml
index 6f557c133..34274ef45 100644
--- a/lib/softaffinity.ml
+++ b/lib/softaffinity.ml
@@ -84,7 +84,8 @@ let plan host nodes ~vm =
     let candidate = nodes.(nodeidx) in
     ( NUMAResource.union allocated candidate
     , node :: picked
-    , NUMARequest.shrink requested candidate )
+    , NUMARequest.shrink requested candidate
+    )
   in
   let plan_valid (avg, nodes) =
     let allocated, picked, remaining =
diff --git a/lib/storage.ml b/lib/storage.ml
index 7693a4ba1..efb1623d1 100644
--- a/lib/storage.ml
+++ b/lib/storage.ml
@@ -39,7 +39,8 @@ let id_of frontend vbd = Printf.sprintf "vbd/%s/%s" frontend (snd vbd)
 let epoch_begin task sr vdi domid persistent =
   transform_exception
     (fun () ->
-      Client.VDI.epoch_begin (Xenops_task.get_dbg task) sr vdi domid persistent)
+      Client.VDI.epoch_begin (Xenops_task.get_dbg task) sr vdi domid persistent
+    )
     ()
 
 let epoch_end task sr vdi domid =
@@ -64,12 +65,16 @@ let attach_and_activate ~task ~_vm ~vmdomid ~dp ~sr ~vdi ~read_write =
       (Printf.sprintf "VDI.attach3 %s" dp)
       (transform_exception (fun () ->
            Client.VDI.attach3 "attach_and_activate_impl" dp sr vdi vmdomid
-             read_write))
+             read_write
+       )
+      )
   in
   Xenops_task.with_subtask task
     (Printf.sprintf "VDI.activate3 %s" dp)
     (transform_exception (fun () ->
-         Client.VDI.activate3 "attach_and_activate_impl" dp sr vdi vmdomid)) ;
+         Client.VDI.activate3 "attach_and_activate_impl" dp sr vdi vmdomid
+     )
+    ) ;
   result
 
 let deactivate task dp sr vdi vmdomid =
@@ -77,7 +82,9 @@ let deactivate task dp sr vdi vmdomid =
   Xenops_task.with_subtask task
     (Printf.sprintf "VDI.deactivate %s" dp)
     (transform_exception (fun () ->
-         Client.VDI.deactivate "deactivate" dp sr vdi vmdomid))
+         Client.VDI.deactivate "deactivate" dp sr vdi vmdomid
+     )
+    )
 
 let dp_destroy task dp =
   Xenops_task.with_subtask task
@@ -102,7 +109,9 @@ let dp_destroy task dp =
                warn "DP destroy returned unexpected exception: %s"
                  (Printexc.to_string e) ;
                waiting_for_plugin := false
-         done))
+         done
+     )
+    )
 
 let get_disk_by_name _task path =
   match Astring.String.cut ~sep:"/" path with
diff --git a/lib/suspend_image.ml b/lib/suspend_image.ml
index 2f527de66..892ad237f 100644
--- a/lib/suspend_image.ml
+++ b/lib/suspend_image.ml
@@ -168,8 +168,7 @@ let read_legacy_qemu_header fd =
 
 let write_qemu_header_for_legacy_libxc fd size =
   wrap (fun () -> Io.write fd qemu_save_signature_legacy_libxc) >>= fun () ->
-  wrap (fun () ->
-      Io.write_int ~endianness:`little fd (Io.int_of_int64_exn size))
+  wrap (fun () -> Io.write_int ~endianness:`little fd (Io.int_of_int64_exn size))
 
 let read_header fd =
   read_int64 fd >>= fun x ->
@@ -186,7 +185,8 @@ let check_conversion_script () =
   with _ ->
     `Error
       (Failure
-         (Printf.sprintf "Executable not found: %s" !Resources.legacy_conv_tool))
+         (Printf.sprintf "Executable not found: %s" !Resources.legacy_conv_tool)
+      )
 
 type 'a thread_status = Running | Thread_failure of exn | Success of 'a
 
@@ -228,11 +228,14 @@ let with_conversion_script task name hvm fd f =
             let result = finally (fun () -> f ()) (fun () -> Unix.close fd') in
             Mutex.execute m (fun () ->
                 status := Success result ;
-                Condition.signal c)
+                Condition.signal c
+            )
           with e ->
             Mutex.execute m (fun () ->
                 status := Thread_failure e ;
-                Condition.signal c))
+                Condition.signal c
+            )
+        )
         ()
     in
     (thread, status)
@@ -243,7 +246,8 @@ let with_conversion_script task name hvm fd f =
           (String.concat "; " args) ;
         Cancellable_subprocess.run task
           [(fd_uuid, fd); (pipe_w_uuid, pipe_w)]
-          conv_script args)
+          conv_script args
+    )
   and f_th, f_st = spawn_thread_and_close_fd name pipe_r (fun () -> f pipe_r) in
   debug "Spawned threads for conversion script and %s" name ;
   let rec handle_threads () =
@@ -254,30 +258,38 @@ let with_conversion_script task name hvm fd f =
         match status with
         | Unix.WEXITED n ->
             `Error
-              (Failure
-                 (Printf.sprintf "Conversion script exited with code %d" n))
+              (Failure (Printf.sprintf "Conversion script exited with code %d" n)
+              )
         | Unix.WSIGNALED n ->
             `Error
               (Failure
                  (Printf.sprintf "Conversion script exited with signal %s"
-                    (Unixext.string_of_signal n)))
+                    (Unixext.string_of_signal n)
+                 )
+              )
         | Unix.WSTOPPED n ->
             `Error
               (Failure
                  (Printf.sprintf "Conversion script stopped with signal %s"
-                    (Unixext.string_of_signal n)))
+                    (Unixext.string_of_signal n)
+                 )
+              )
       )
       | _ ->
           `Error
             (Failure
                (Printf.sprintf "Conversion script thread caught exception: %s"
-                  (Printexc.to_string e)))
+                  (Printexc.to_string e)
+               )
+            )
     )
     | _, Thread_failure e ->
         `Error
           (Failure
              (Printf.sprintf "Thread executing %s caught exception: %s" name
-                (Printexc.to_string e)))
+                (Printexc.to_string e)
+             )
+          )
     | Running, _ | _, Running ->
         Condition.wait c m ; handle_threads ()
     | Success _, Success res ->
diff --git a/lib/topology.ml b/lib/topology.ml
index dbbc0a292..1d8b1e014 100644
--- a/lib/topology.ml
+++ b/lib/topology.ml
@@ -57,7 +57,8 @@ module NUMAResource = struct
         [
           Dump.field "affinity" (fun t -> t.affinity) CPUSet.pp_dump
         ; Dump.field "memfree" (fun t -> t.memfree) int64
-        ])
+        ]
+    )
 end
 
 module NUMARequest = struct
@@ -85,7 +86,8 @@ module NUMARequest = struct
         [
           Dump.field "memory" (fun t -> t.memory) int64
         ; Dump.field "vcpus" (fun t -> t.vcpus) int
-        ])
+        ]
+    )
 end
 
 (** [seq_range a b] is the sequence of numbers between [a, b). *)
@@ -192,13 +194,14 @@ module NUMA = struct
         let d = distances.(i).(i) in
         if d <> 10 then
           invalid_arg
-            (Printf.sprintf "NUMA distance from node to itself must be 10: %d"
-               d) ;
+            (Printf.sprintf "NUMA distance from node to itself must be 10: %d" d) ;
         Array.iteri
           (fun _ d ->
             if d < 10 then
-              invalid_arg (Printf.sprintf "NUMA distance must be >= 10: %d" d))
-          row)
+              invalid_arg (Printf.sprintf "NUMA distance must be >= 10: %d" d)
+          )
+          row
+      )
       distances ;
     let all = Array.fold_left CPUSet.union CPUSet.empty node_cpus in
     let candidates = gen_candidates distances in
@@ -266,5 +269,6 @@ module NUMA = struct
         ; Dump.field "node_cpus"
             (fun t -> t.node_cpus)
             (Dump.array CPUSet.pp_dump)
-        ])
+        ]
+    )
 end
diff --git a/lib/xenops_hooks.ml b/lib/xenops_hooks.ml
index 72a2c30d3..c1b859df6 100644
--- a/lib/xenops_hooks.ml
+++ b/lib/xenops_hooks.ml
@@ -107,7 +107,10 @@ let execute_vm_hook ~script_name ~id ~reason ~extra_args =
           raise
             (Xenopsd_error
                (Errors.Hook_failed
-                  (script_name ^ "/" ^ script, reason, stdout, string_of_int i))))
+                  (script_name ^ "/" ^ script, reason, stdout, string_of_int i)
+               )
+            )
+    )
     scripts
 
 type script =
diff --git a/lib/xenops_sandbox.ml b/lib/xenops_sandbox.ml
index 7334f60f2..92e8d6a8f 100644
--- a/lib/xenops_sandbox.ml
+++ b/lib/xenops_sandbox.ml
@@ -51,7 +51,8 @@ end = struct
       if not (Filename.is_implicit relative) then
         invalid_arg
           (Printf.sprintf "Expected implicit filename, but got '%s' (at %s)"
-             relative __LOC__) ;
+             relative __LOC__
+          ) ;
       relative
   end
 
@@ -87,7 +88,8 @@ end = struct
       let prepare path =
         let fullpath = absolute_path_outside chroot path in
         Xenops_utils.Unixext.with_file fullpath [Unix.O_CREAT; Unix.O_EXCL]
-          0o600 (fun fd -> Unix.fchown fd chroot.uid chroot.gid)
+          0o600 (fun fd -> Unix.fchown fd chroot.uid chroot.gid
+        )
       in
       List.iter prepare paths ; chroot
     with e ->
@@ -98,7 +100,8 @@ end = struct
 
   let destroy chroot =
     Xenops_utils.best_effort (Printf.sprintf "removing chroot %s" chroot.root)
-      (fun () -> Xenops_utils.FileFS.rmtree chroot.root)
+      (fun () -> Xenops_utils.FileFS.rmtree chroot.root
+    )
 end
 
 module Varstore_guard = struct
@@ -150,7 +153,8 @@ module Varstore_guard = struct
       in
       Xenops_utils.best_effort "Stop listening on deprivileged socket"
         (fun () ->
-          Varstore_privileged_client.Client.destroy dbg gid absolute_socket_path) ;
+          Varstore_privileged_client.Client.destroy dbg gid absolute_socket_path
+      ) ;
       Chroot.destroy chroot
     ) else
       D.warn "Can't stop varstored for %d (%s): %s does not exist" domid vm_uuid
diff --git a/lib/xenops_server.ml b/lib/xenops_server.ml
index a5f94bd5b..0bdf38b5e 100644
--- a/lib/xenops_server.ml
+++ b/lib/xenops_server.ml
@@ -68,9 +68,11 @@ let filter_prefix prefix xs =
       if Astring.String.is_prefix ~affix:prefix x then
         Some
           (String.sub x (String.length prefix)
-             (String.length x - String.length prefix))
+             (String.length x - String.length prefix)
+          )
       else
-        None)
+        None
+    )
     xs
 
 type atomic =
@@ -227,12 +229,14 @@ module VM_DB = struct
     debug "VM_DB.signal %s" id ;
     Mutex.execute m (fun () ->
         if exists id then
-          Updates.add (Dynamic.Vm id) updates)
+          Updates.add (Dynamic.Vm id) updates
+    )
 
   let remove id =
     Mutex.execute m (fun () ->
         Updates.remove (Dynamic.Vm id) updates ;
-        remove id)
+        remove id
+    )
 
   let add' x =
     debug "VM.add %s" (Jsonrpc.to_string (rpc_of Vm.t x)) ;
@@ -274,12 +278,14 @@ module PCI_DB = struct
     debug "PCI_DB.signal %s" (string_of_id id) ;
     Mutex.execute m (fun () ->
         if exists id then
-          Updates.add (Dynamic.Pci id) updates)
+          Updates.add (Dynamic.Pci id) updates
+    )
 
   let remove id =
     Mutex.execute m (fun () ->
         Updates.remove (Dynamic.Pci id) updates ;
-        remove id)
+        remove id
+    )
 
   let add' x =
     let open Pci in
@@ -336,12 +342,14 @@ module VBD_DB = struct
     debug "VBD_DB.signal %s" (string_of_id id) ;
     Mutex.execute m (fun () ->
         if exists id then
-          Updates.add (Dynamic.Vbd id) updates)
+          Updates.add (Dynamic.Vbd id) updates
+    )
 
   let remove id =
     Mutex.execute m (fun () ->
         Updates.remove (Dynamic.Vbd id) updates ;
-        remove id)
+        remove id
+    )
 
   let add' x =
     debug "VBD.add %s %s" (string_of_id x.Vbd.id)
@@ -399,7 +407,8 @@ module VIF_DB = struct
   let remove id =
     Mutex.execute m (fun () ->
         Updates.remove (Dynamic.Vif id) updates ;
-        remove id)
+        remove id
+    )
 
   let add' x =
     debug "VIF.add %s" (Jsonrpc.to_string (rpc_of Vif.t x)) ;
@@ -453,7 +462,8 @@ module VGPU_DB = struct
     | _ ->
         raise
           (Xenopsd_error
-             (Internal_error ("String cannot be interpreted as vgpu id: " ^ str)))
+             (Internal_error ("String cannot be interpreted as vgpu id: " ^ str))
+          )
 
   let ids vm : Vgpu.id list =
     list [vm] |> filter_prefix "vgpu." |> List.map (fun id -> (vm, id))
@@ -473,12 +483,14 @@ module VGPU_DB = struct
     debug "VGPU_DB.signal %s" (string_of_id id) ;
     Mutex.execute m (fun () ->
         if exists id then
-          Updates.add (Dynamic.Vgpu id) updates)
+          Updates.add (Dynamic.Vgpu id) updates
+    )
 
   let remove id =
     Mutex.execute m (fun () ->
         Updates.remove (Dynamic.Vgpu id) updates ;
-        remove id)
+        remove id
+    )
 
   let add' x =
     debug "VGPU.add %s %s" (string_of_id x.Vgpu.id)
@@ -537,7 +549,8 @@ module VUSB_DB = struct
   let remove id =
     Mutex.execute m (fun () ->
         Updates.remove (Dynamic.Vusb id) updates ;
-        remove id)
+        remove id
+    )
 
   let add' x =
     debug "VUSB.add %s %s" (string_of_id x.Vusb.id)
@@ -620,11 +633,13 @@ module Queues = struct
         if StringMap.mem tag qs.qs then
           StringMap.find tag qs.qs
         else
-          Queue.create ())
+          Queue.create ()
+    )
 
   let tags qs =
     Mutex.execute qs.m (fun () ->
-        StringMap.fold (fun x _ acc -> x :: acc) qs.qs [])
+        StringMap.fold (fun x _ acc -> x :: acc) qs.qs []
+    )
 
   let get_last_tag qs = Mutex.execute qs.m (fun () -> qs.last_tag)
 
@@ -638,7 +653,8 @@ module Queues = struct
         in
         push_with_coalesce should_keep item q ;
         qs.qs <- StringMap.add tag q qs.qs ;
-        Condition.signal qs.c)
+        Condition.signal qs.c
+    )
 
   let pop qs =
     Mutex.execute qs.m (fun () ->
@@ -659,7 +675,8 @@ module Queues = struct
         (* remove empty queues from the whole mapping *)
         qs.qs <-
           (if Queue.is_empty q then StringMap.remove last_tag qs.qs else qs.qs) ;
-        (last_tag, item))
+        (last_tag, item)
+    )
 
   let transfer_tag tag a b =
     Mutex.execute a.m (fun () ->
@@ -668,7 +685,9 @@ module Queues = struct
               b.qs <- StringMap.add tag (StringMap.find tag a.qs) b.qs ;
               a.qs <- StringMap.remove tag a.qs ;
               Condition.signal b.c
-            )))
+            )
+        )
+    )
 end
 
 module Redirector = struct
@@ -738,8 +757,13 @@ module Redirector = struct
                  (List.rev
                     (Queue.fold
                        (fun acc (b, _) -> string_of_operation b :: acc)
-                       [] (Queues.get tag q)))) ;
-            Queues.push_with_coalesce should_keep real_tag item q))
+                       [] (Queues.get tag q)
+                    )
+                 )
+              ) ;
+            Queues.push_with_coalesce should_keep real_tag item q
+        )
+      )
       ()
 
   let pop t () =
@@ -753,7 +777,9 @@ module Redirector = struct
             Queues.transfer_tag tag t.queues q ;
             overrides := StringMap.add tag q !overrides ;
             (* All items with [tag] will enter queue [q] *)
-            (tag, q, item)))
+            (tag, q, item)
+        )
+    )
 
   let finished t tag queue =
     Mutex.execute m (fun () ->
@@ -761,7 +787,8 @@ module Redirector = struct
         overrides := StringMap.remove tag !overrides ;
         (* All items with [tag] will enter the queues queue *)
         (* Sanity check: there should be no override for tag in overrides *)
-        aliases := StringMap.filter (fun _ v -> v <> tag) !aliases)
+        aliases := StringMap.filter (fun _ v -> v <> tag) !aliases
+    )
 
   let alias ~tag ~alias =
     Mutex.execute m (fun () ->
@@ -769,7 +796,8 @@ module Redirector = struct
           debug "Queue: Aliasing existing tag '%s' to new tag '%s'" tag alias ;
           aliases := StringMap.add alias tag !aliases
         ) else
-          debug "Queue: Warning: Not aliasing non-existing tag")
+          debug "Queue: Warning: Not aliasing non-existing tag"
+    )
 
   module Dump = struct
     type q = {tag: string; items: operation list} [@@deriving rpcty]
@@ -787,8 +815,10 @@ module Redirector = struct
                     List.rev
                       (Queue.fold
                          (fun acc (b, _) -> b :: acc)
-                         [] (Queues.get t queue))
-                })
+                         [] (Queues.get t queue)
+                      )
+                }
+              )
               (Queues.tags queue)
           in
           List.concat
@@ -796,7 +826,9 @@ module Redirector = struct
                (default.queues
                :: parallel_queues.queues
                :: List.map snd (StringMap.bindings !overrides)
-               )))
+               )
+            )
+      )
   end
 end
 
@@ -827,7 +859,8 @@ module Worker = struct
   let join t =
     Mutex.execute t.m (fun () ->
         assert (t.state = Shutdown) ;
-        Option.iter Thread.join t.t)
+        Option.iter Thread.join t.t
+    )
 
   let is_active t =
     Mutex.execute t.m (fun () ->
@@ -835,7 +868,8 @@ module Worker = struct
         | Idle | Processing (_, _) ->
             true
         | Shutdown_requested | Shutdown ->
-            false)
+            false
+    )
 
   let shutdown t =
     Mutex.execute t.m (fun () ->
@@ -843,7 +877,8 @@ module Worker = struct
           t.shutdown_requested <- true ;
           true (* success *)
         ) else
-          false)
+          false
+    )
 
   let restart t =
     Mutex.execute t.m (fun () ->
@@ -851,7 +886,8 @@ module Worker = struct
           t.shutdown_requested <- false ;
           true (* success *)
         ) else
-          false)
+          false
+    )
 
   let create redirector =
     let t =
@@ -871,7 +907,9 @@ module Worker = struct
             not
               (Mutex.execute t.m (fun () ->
                    if t.shutdown_requested then t.state <- Shutdown ;
-                   t.shutdown_requested))
+                   t.shutdown_requested
+               )
+              )
           do
             Mutex.execute t.m (fun () -> t.state <- Idle) ;
             let tag, queue, (op, item) = Redirector.pop redirector () in
@@ -885,7 +923,8 @@ module Worker = struct
                   (fun () ->
                     debug "Task %s reference %s: %s" id t'.Task.dbg
                       (string_of_operation op) ;
-                    Xenops_task.run item)
+                    Xenops_task.run item
+                  )
                   ()
               with e -> debug "Queue caught: %s" (Printexc.to_string e)
             ) ;
@@ -901,7 +940,8 @@ module Worker = struct
                 ()
             ) ;
             TASK.signal id
-          done)
+          done
+        )
         ()
     in
     t.t <- Some thread ;
@@ -934,7 +974,8 @@ module WorkerPool = struct
       ; subtasks=
           List.map
             (fun (name, state) ->
-              (name, state |> rpc_of Task.state |> Jsonrpc.to_string))
+              (name, state |> rpc_of Task.state |> Jsonrpc.to_string)
+            )
             t'.Task.subtasks
           |> List.rev
       }
@@ -959,8 +1000,10 @@ module WorkerPool = struct
               | Worker.Shutdown_requested ->
                   {state= "Shutdown_requested"; task= None}
               | Worker.Shutdown ->
-                  {state= "Shutdown"; task= None})
-            !pool)
+                  {state= "Shutdown"; task= None}
+            )
+            !pool
+      )
   end
 
   (* Compute the number of active threads ie those which will continue to
@@ -974,7 +1017,8 @@ module WorkerPool = struct
           (fun w -> w.Worker.redirector == queues && Worker.is_active w)
           !pool
         |> List.filter (fun x -> x)
-        |> List.length)
+        |> List.length
+    )
 
   let find_one queues f =
     List.fold_left
@@ -992,7 +1036,8 @@ module WorkerPool = struct
         then (
           Worker.join w ; acc
         ) else
-          w :: acc)
+          w :: acc
+      )
       [] pool
 
   let incr queues =
@@ -1000,14 +1045,16 @@ module WorkerPool = struct
     Mutex.execute m (fun () ->
         pool := gc queues !pool ;
         if not (find_one queues Worker.restart !pool) then
-          pool := Worker.create queues :: !pool)
+          pool := Worker.create queues :: !pool
+    )
 
   let decr queues =
     debug "Removing a worker from the thread pool" ;
     Mutex.execute m (fun () ->
         pool := gc queues !pool ;
         if not (find_one queues Worker.shutdown !pool) then
-          debug "There are no worker threads left to shutdown.")
+          debug "There are no worker threads left to shutdown."
+    )
 
   let start size =
     for _i = 1 to size do
@@ -1037,11 +1084,12 @@ let rebooting_vms = ref []
 let rebooting_vms_m = Mutex.create ()
 
 let rebooting id f =
-  Mutex.execute rebooting_vms_m (fun () ->
-      rebooting_vms := id :: !rebooting_vms) ;
+  Mutex.execute rebooting_vms_m (fun () -> rebooting_vms := id :: !rebooting_vms) ;
   finally f (fun () ->
       Mutex.execute rebooting_vms_m (fun () ->
-          rebooting_vms := List.filter (fun x -> x <> id) !rebooting_vms))
+          rebooting_vms := List.filter (fun x -> x <> id) !rebooting_vms
+      )
+  )
 
 let is_rebooting id =
   Mutex.execute rebooting_vms_m (fun () -> List.mem id !rebooting_vms)
@@ -1147,7 +1195,8 @@ let export_metadata vdi_map vif_map vgpu_pci_map id =
   let vbds =
     List.map
       (fun vbd ->
-        {vbd with Vbd.backend= Option.map (remap_vdi vdi_map) vbd.Vbd.backend})
+        {vbd with Vbd.backend= Option.map (remap_vdi vdi_map) vbd.Vbd.backend}
+      )
       vbds
   in
   {Metadata.vm= vm_t; vbds; vifs; pcis; vgpus; vusbs; domains= Some domains}
@@ -1194,7 +1243,8 @@ let import_metadata id md =
         let new_device_name =
           Device_number.upgrade_linux_device (snd x.Vbd.id)
         in
-        {x with Vbd.id= (vm, new_device_name)})
+        {x with Vbd.id= (vm, new_device_name)}
+      )
       md.Metadata.vbds
   in
   let vifs =
@@ -1289,7 +1339,8 @@ let must_dequarantine vgpu =
     | Nvidia _ ->
         true
     | _ ->
-        false)
+        false
+  )
 
 (* compute a list of PCI_dequarantine operations for PCI devices *)
 let dequarantine_ops vgpus =
@@ -1297,7 +1348,8 @@ let dequarantine_ops vgpus =
   |> List.filter must_dequarantine
   |> List.map
        Xenops_interface.Vgpu.(
-         fun vgpu -> PCI_dequarantine vgpu.physical_pci_address)
+         fun vgpu -> PCI_dequarantine vgpu.physical_pci_address
+       )
 
 let rec atomics_of_operation = function
   | VM_start (id, force) ->
@@ -1332,20 +1384,26 @@ let rec atomics_of_operation = function
                   (fun vbd ->
                     Option.map
                       (fun x ->
-                        VBD_epoch_begin (vbd.Vbd.id, x, vbd.Vbd.persistent))
-                      vbd.Vbd.backend)
-                  vbds ))
+                        VBD_epoch_begin (vbd.Vbd.id, x, vbd.Vbd.persistent)
+                      )
+                      vbd.Vbd.backend
+                  )
+                  vbds
+              )
+          )
           [("RW", vbds_rw); ("RO", vbds_ro)]
       ; [
           (* rw vbds must be plugged before ro vbds, see vbd_plug_sets *)
           Parallel
             ( id
             , Printf.sprintf "VBD.plug RW vm=%s" id
-            , List.map (fun vbd -> VBD_plug vbd.Vbd.id) vbds_rw )
+            , List.map (fun vbd -> VBD_plug vbd.Vbd.id) vbds_rw
+            )
         ; Parallel
             ( id
             , Printf.sprintf "VBD.plug RO vm=%s" id
-            , List.map (fun vbd -> VBD_plug vbd.Vbd.id) vbds_ro )
+            , List.map (fun vbd -> VBD_plug vbd.Vbd.id) vbds_ro
+            )
         ]
       ; List.map (fun vif -> VIF_set_active (vif.Vif.id, true)) vifs
       ; List.map (fun vif -> VIF_plug vif.Vif.id) vifs
@@ -1379,7 +1437,8 @@ let rec atomics_of_operation = function
         ; Parallel
             ( id
             , Printf.sprintf "VBD.unplug vm=%s" id
-            , List.map (fun vbd -> VBD_unplug (vbd.Vbd.id, true)) vbds )
+            , List.map (fun vbd -> VBD_unplug (vbd.Vbd.id, true)) vbds
+            )
         ]
       ; List.map (fun vif -> VIF_unplug (vif.Vif.id, true)) vifs
       ; List.map (fun pci -> PCI_unplug pci.Pci.id) pcis
@@ -1407,11 +1466,13 @@ let rec atomics_of_operation = function
           Parallel
             ( id
             , Printf.sprintf "VBD.plug RW vm=%s" id
-            , List.map (fun vbd -> VBD_plug vbd.Vbd.id) vbds_rw )
+            , List.map (fun vbd -> VBD_plug vbd.Vbd.id) vbds_rw
+            )
         ; Parallel
             ( id
             , Printf.sprintf "VBD.plug RO vm=%s" id
-            , List.map (fun vbd -> VBD_plug vbd.Vbd.id) vbds_ro )
+            , List.map (fun vbd -> VBD_plug vbd.Vbd.id) vbds_ro
+            )
         ]
       ; (if restore_vifs then atomics_of_operation (VM_restore_vifs id) else [])
       ; List.map (fun vgpu -> VGPU_set_active (vgpu.Vgpu.id, true)) vgpus
@@ -1445,8 +1506,10 @@ let rec atomics_of_operation = function
                 (fun vbd ->
                   Option.map
                     (fun x -> VBD_epoch_end (vbd.Vbd.id, x))
-                    vbd.Vbd.backend)
-                vbds )
+                    vbd.Vbd.backend
+                )
+                vbds
+            )
         ]
       ; List.map (fun vbd -> VBD_set_active (vbd.Vbd.id, false)) vbds
       ; List.map (fun vif -> VIF_set_active (vif.Vif.id, false)) vifs
@@ -1475,8 +1538,10 @@ let rec atomics_of_operation = function
                 (fun vbd ->
                   Option.map
                     (fun x -> VBD_epoch_end (vbd.Vbd.id, x))
-                    vbd.Vbd.backend)
-                vbds )
+                    vbd.Vbd.backend
+                )
+                vbds
+            )
         ]
       ; [
           VM_hook_script (id, Xenops_hooks.VM_post_destroy, reason)
@@ -1594,13 +1659,15 @@ let rec perform_atomic ~progress_callback ?subtask:_ ?result (op : atomic)
                   | Error (`Msg x) ->
                       Xenopsd_error
                         (Internal_error
-                           (Printf.sprintf "Error unmarshalling failure: %s" x))
+                           (Printf.sprintf "Error unmarshalling failure: %s" x)
+                        )
                 in
                 Some e
             | Task.Pending _ ->
                 error "Parallel: queue_atomics_and_wait returned a pending task" ;
                 Xenops_task.cancel task_handle ;
-                Some (Xenopsd_error (Cancelled id)))
+                Some (Xenopsd_error (Cancelled id))
+          )
           task_list
       in
       (* if any error was present, raise first one, so that
@@ -1625,7 +1692,8 @@ let rec perform_atomic ~progress_callback ?subtask:_ ?result (op : atomic)
           (* Nb, this VIF_DB write needs to come before the call to move as the
              scripts will read from the disk! *)
           VIF_DB.write id {vif with Vif.backend= network} ;
-          B.VIF.move t (VIF_DB.vm_of id) vif network)
+          B.VIF.move t (VIF_DB.vm_of id) vif network
+        )
         (fun () -> VIF_DB.signal id)
   | VIF_set_carrier (id, carrier) ->
       debug "VIF.set_carrier %s %b" (VIF_DB.string_of_id id) carrier ;
@@ -1633,7 +1701,8 @@ let rec perform_atomic ~progress_callback ?subtask:_ ?result (op : atomic)
         (fun () ->
           let vif = VIF_DB.read_exn id in
           B.VIF.set_carrier t (VIF_DB.vm_of id) vif carrier ;
-          VIF_DB.write id {vif with Vif.carrier})
+          VIF_DB.write id {vif with Vif.carrier}
+        )
         (fun () -> VIF_DB.signal id)
   | VIF_set_locking_mode (id, mode) ->
       debug "VIF.set_locking_mode %s %s" (VIF_DB.string_of_id id)
@@ -1644,7 +1713,8 @@ let rec perform_atomic ~progress_callback ?subtask:_ ?result (op : atomic)
           (* Nb, this VIF_DB write needs to come before the call to
              set_locking_mode as the scripts will read from the disk! *)
           VIF_DB.write id {vif with Vif.locking_mode= mode} ;
-          B.VIF.set_locking_mode t (VIF_DB.vm_of id) vif mode)
+          B.VIF.set_locking_mode t (VIF_DB.vm_of id) vif mode
+        )
         (fun () -> VIF_DB.signal id)
   | VIF_set_pvs_proxy (id, proxy) ->
       let s =
@@ -1659,7 +1729,8 @@ let rec perform_atomic ~progress_callback ?subtask:_ ?result (op : atomic)
         (fun () ->
           let vif = VIF_DB.read_exn id in
           VIF_DB.write id {vif with Vif.pvs_proxy= proxy} ;
-          B.VIF.set_pvs_proxy t (VIF_DB.vm_of id) vif proxy)
+          B.VIF.set_pvs_proxy t (VIF_DB.vm_of id) vif proxy
+        )
         (fun () -> VIF_DB.signal id)
   | VIF_set_ipv4_configuration (id, ipv4_configuration) ->
       let setting =
@@ -1682,7 +1753,8 @@ let rec perform_atomic ~progress_callback ?subtask:_ ?result (op : atomic)
           let vif = VIF_DB.read_exn id in
           VIF_DB.write id {vif with Vif.ipv4_configuration} ;
           B.VIF.set_ipv4_configuration t (VIF_DB.vm_of id) vif
-            ipv4_configuration)
+            ipv4_configuration
+        )
         (fun () -> VIF_DB.signal id)
   | VIF_set_ipv6_configuration (id, ipv6_configuration) ->
       let setting =
@@ -1705,7 +1777,8 @@ let rec perform_atomic ~progress_callback ?subtask:_ ?result (op : atomic)
           let vif = VIF_DB.read_exn id in
           VIF_DB.write id {vif with Vif.ipv6_configuration} ;
           B.VIF.set_ipv6_configuration t (VIF_DB.vm_of id) vif
-            ipv6_configuration)
+            ipv6_configuration
+        )
         (fun () -> VIF_DB.signal id)
   | VIF_set_active (id, b) ->
       debug "VIF.set_active %s %b" (VIF_DB.string_of_id id) b ;
@@ -1802,7 +1875,8 @@ let rec perform_atomic ~progress_callback ?subtask:_ ?result (op : atomic)
             let id = get_id i in
             rm id ;
             let id' = new_key id in
-            add id' (set_id id' i))
+            add id' (set_id id' i)
+          )
           items
       in
       let vm = VM_DB.read_exn id1 in
@@ -1905,7 +1979,9 @@ let rec perform_atomic ~progress_callback ?subtask:_ ?result (op : atomic)
         (Option.value ~default:"None"
            (Option.map
               (fun x -> x |> rpc_of domain_action_request |> Jsonrpc.to_string)
-              dar)) ;
+              dar
+           )
+        ) ;
       B.VM.set_domain_action_request (VM_DB.read_exn id) dar
   | VM_create_device_model (id, save_state) ->
       debug "VM.create_device_model %s" id ;
@@ -1926,7 +2002,8 @@ let rec perform_atomic ~progress_callback ?subtask:_ ?result (op : atomic)
   | VM_create (id, memory_upper_bound, final_id, no_sharept) ->
       debug "VM.create %s memory_upper_bound = %s" id
         (Option.value ~default:"None"
-           (Option.map Int64.to_string memory_upper_bound)) ;
+           (Option.map Int64.to_string memory_upper_bound)
+        ) ;
       B.VM.create t memory_upper_bound (VM_DB.read_exn id) final_id no_sharept
   | VM_build (id, force) ->
       debug "VM.build %s" id ;
@@ -1957,7 +2034,8 @@ let rec perform_atomic ~progress_callback ?subtask:_ ?result (op : atomic)
       if
         not
           (B.VM.request_shutdown t vm reason
-             (min !domain_shutdown_ack_timeout timeout))
+             (min !domain_shutdown_ack_timeout timeout)
+          )
       then
         raise (Xenopsd_error Failed_to_acknowledge_shutdown_request) ;
       let remaining_timeout =
@@ -2003,7 +2081,8 @@ and queue_atomic_int ~progress_callback dbg id op =
       (let r = ref None in
        fun t ->
          perform_atomic ~progress_callback ~result:r op t ;
-         !r)
+         !r
+      )
   in
   Redirector.push Redirector.parallel_queues id (Atomic op, task) ;
   task
@@ -2021,7 +2100,8 @@ and queue_atomics_and_wait ~progress_callback ~max_parallel_atoms dbg id ops =
                let atom_id =
                  Printf.sprintf "%s.chunk=%d.atom=%d" id chunk_idx atom_idx
                in
-               queue_atomic_int ~progress_callback dbg atom_id op)
+               queue_atomic_int ~progress_callback dbg atom_id op
+             )
              ops
          in
          let timeout_start = Unix.gettimeofday () in
@@ -2029,9 +2109,11 @@ and queue_atomics_and_wait ~progress_callback ~max_parallel_atoms dbg id ops =
            (fun task ->
              event_wait updates task ~from ~timeout_start 1200.0
                (task_finished_p (Xenops_task.id_of_handle task))
-             |> ignore)
+             |> ignore
+           )
            task_list ;
-         task_list)
+         task_list
+     )
   |> List.concat
 
 (* Used to divide up the progress (bar) amongst atomic operations *)
@@ -2063,7 +2145,8 @@ let perform_atomics atomics t =
         debug "Performing: %s" (string_of_atomic x) ;
         perform_atomic ~subtask:(string_of_atomic x) ~progress_callback x t ;
         progress_callback 1. ;
-        progress +. (weight /. total_weight))
+        progress +. (weight /. total_weight)
+      )
       0. atomics
   in
   ()
@@ -2076,7 +2159,8 @@ let rec immediate_operation dbg _id op =
     (fun () ->
       debug "Task %s reference %s: %s" task_id
         (Xenops_task.to_interface_task task).Task.dbg (string_of_operation op) ;
-      Xenops_task.run task)
+      Xenops_task.run task
+    )
     () ;
   match Xenops_task.get_state task with
   | Task.Pending _ ->
@@ -2090,7 +2174,8 @@ let rec immediate_operation dbg _id op =
     | Error (`Msg m) ->
         raise
           (Xenopsd_error
-             (Internal_error (Printf.sprintf "Failed to unmarshal error: %s" m)))
+             (Internal_error (Printf.sprintf "Failed to unmarshal error: %s" m))
+          )
   )
 
 (* At all times we ensure that an operation which partially fails leaves the
@@ -2265,7 +2350,8 @@ and perform_exn ?subtask ?result (op : operation) (t : Xenops_task.task_handle)
         Xenops_interface.XenopsAPI (Idl.Exn.GenClient (struct
           let rpc =
             Xcp_client.xml_http_rpc ~srcstr:"xenops" ~dststr:"dst_xenops"
-              (fun () -> vmm.vmm_url)
+              (fun () -> vmm.vmm_url
+            )
         end)) in
         let regexp = Re.Pcre.regexp id in
         debug "Destination domain will be built with uuid=%s" new_dest_id ;
@@ -2278,7 +2364,9 @@ and perform_exn ?subtask ?result (op : operation) (t : Xenops_task.task_handle)
           Remote.VM.import_metadata dbg
             (Re.replace_string regexp ~by:new_dest_id
                (export_metadata vmm.vmm_vdi_map vmm.vmm_vif_map
-                  vmm.vmm_vgpu_pci_map id))
+                  vmm.vmm_vgpu_pci_map id
+               )
+            )
         in
         debug "Received vm-id = %s" id' ;
         let make_url snippet id_str =
@@ -2396,8 +2484,10 @@ and perform_exn ?subtask ?result (op : operation) (t : Xenops_task.task_handle)
                     Handshake.send ~verbose:true mem_fd Handshake.Success ;
                     debug "VM.migrate: Synchronisation point 1-vgpu ACK" ;
                     first_handshake () ;
-                    save ~vgpu_fd:(FD vgpu_fd) ()) ;
-                final_handshake ()) ;
+                    save ~vgpu_fd:(FD vgpu_fd) ()
+                ) ;
+                final_handshake ()
+        ) ;
         (* cleanup tmp src VM *)
         let atomics =
           [
@@ -2405,7 +2495,8 @@ and perform_exn ?subtask ?result (op : operation) (t : Xenops_task.task_handle)
               ( id
               , Xenops_hooks.VM_pre_destroy
               , Xenops_hooks.reason__suspend
-              , new_src_id )
+              , new_src_id
+              )
           ]
           @ atomics_of_operation (VM_shutdown (new_src_id, None))
           @ [
@@ -2413,7 +2504,8 @@ and perform_exn ?subtask ?result (op : operation) (t : Xenops_task.task_handle)
                 ( id
                 , Xenops_hooks.VM_post_destroy
                 , Xenops_hooks.reason__suspend
-                , new_src_id )
+                , new_src_id
+                )
             ; VM_remove new_src_id
             ]
         in
@@ -2511,16 +2603,19 @@ and perform_exn ?subtask ?result (op : operation) (t : Xenops_task.task_handle)
                      VM_restore
                        (id, FD s, Option.map (fun x -> FD x.vgpu_fd) vgpu_info)
                    ]
-                 ])
+                 ]
+              )
               t ;
-            debug "VM.receive_memory restore complete")
+            debug "VM.receive_memory restore complete"
+          )
           (fun () ->
             (* Tell the vGPU receive thread that we're done, so that it can
                clean up vgpu_receiver_sync id and terminate *)
             let vgpu_info = Hashtbl.find_opt vgpu_receiver_sync id in
             Option.iter
               (fun x -> Event.send x.vgpu_channel () |> Event.sync)
-              vgpu_info) ;
+              vgpu_info
+          ) ;
         debug "VM.receive_memory: Synchronisation point 2" ;
         try
           (* Receive the all-clear to unpause *)
@@ -2539,7 +2634,8 @@ and perform_exn ?subtask ?result (op : operation) (t : Xenops_task.task_handle)
               ; VM_hook_script
                   ( final_id
                   , Xenops_hooks.VM_post_migrate
-                  , Xenops_hooks.reason__migrate_dest )
+                  , Xenops_hooks.reason__migrate_dest
+                  )
               ]
             )
             t ;
@@ -2553,9 +2649,9 @@ and perform_exn ?subtask ?result (op : operation) (t : Xenops_task.task_handle)
               debug "Caught %s: cleaning up VM state" (Printexc.to_string e) ;
               perform_atomics
                 (atomics_of_operation (VM_shutdown (id, None)) @ [VM_remove id])
-                t)
-            (fun () ->
-              Handshake.send s (Handshake.Error (Printexc.to_string e)))
+                t
+            )
+            (fun () -> Handshake.send s (Handshake.Error (Printexc.to_string e)))
       )
     | VM_check_state id ->
         let vm = VM_DB.read_exn id in
@@ -2575,11 +2671,7 @@ and perform_exn ?subtask ?result (op : operation) (t : Xenops_task.task_handle)
                    shutting down"
                   id run_time ;
                 vm.Vm.on_crash
-                |> List.map (function
-                     | Vm.Start ->
-                         Vm.Shutdown
-                     | other ->
-                         other)
+                |> List.map (function Vm.Start -> Vm.Shutdown | other -> other)
               ) else
                 vm.Vm.on_crash
           | Some Needs_suspend ->
@@ -2765,14 +2857,16 @@ let uses_mxgpu id =
   List.exists
     (fun vgpu_id ->
       let vgpu = VGPU_DB.read_exn vgpu_id in
-      match vgpu.Vgpu.implementation with Vgpu.MxGPU _ -> true | _ -> false)
+      match vgpu.Vgpu.implementation with Vgpu.MxGPU _ -> true | _ -> false
+    )
     (VGPU_DB.ids id)
 
 let queue_operation_int dbg id op =
   let task =
     Xenops_task.add tasks dbg
       (let r = ref None in
-       fun t -> perform ~result:r op t ; !r)
+       fun t -> perform ~result:r op t ; !r
+      )
   in
   let tag = if uses_mxgpu id then "mxgpu" else id in
   Redirector.push Redirector.default tag (op, task) ;
@@ -2973,7 +3067,8 @@ module HOST = struct
       (fun () ->
         debug "HOST.stat" ;
         let module B = (val get_backend () : S) in
-        B.HOST.stat ())
+        B.HOST.stat ()
+      )
       ()
 
   let get_console_data _ dbg =
@@ -2981,7 +3076,8 @@ module HOST = struct
       (fun () ->
         debug "HOST.get_console_data" ;
         let module B = (val get_backend () : S) in
-        B.HOST.get_console_data ())
+        B.HOST.get_console_data ()
+      )
       ()
 
   let get_total_memory_mib _ dbg =
@@ -2989,7 +3085,8 @@ module HOST = struct
       (fun () ->
         debug "HOST.get_total_memory_mib" ;
         let module B = (val get_backend () : S) in
-        B.HOST.get_total_memory_mib ())
+        B.HOST.get_total_memory_mib ()
+      )
       ()
 
   let send_debug_keys _ dbg keys =
@@ -2997,14 +3094,16 @@ module HOST = struct
       (fun () ->
         debug "HOST.send_debug_keys %s" keys ;
         let module B = (val get_backend () : S) in
-        B.HOST.send_debug_keys keys)
+        B.HOST.send_debug_keys keys
+      )
       ()
 
   let set_worker_pool_size _ dbg size =
     Debug.with_thread_associated dbg
       (fun () ->
         debug "HOST.set_worker_pool_size %d" size ;
-        WorkerPool.set_size size)
+        WorkerPool.set_size size
+      )
       ()
 
   let update_guest_agent_features _ dbg features =
@@ -3015,7 +3114,8 @@ module HOST = struct
           |> Jsonrpc.to_string
           ) ;
         let module B = (val get_backend () : S) in
-        B.HOST.update_guest_agent_features features)
+        B.HOST.update_guest_agent_features features
+      )
       ()
 end
 
@@ -3043,7 +3143,8 @@ module VM = struct
           | Error (`Msg m) ->
               Xenopsd_error
                 (Internal_error
-                   (Printf.sprintf "Error unmarshalling error: %s" m))
+                   (Printf.sprintf "Error unmarshalling error: %s" m)
+                )
         in
         raise e
     | Task.Pending _ ->
@@ -3111,8 +3212,7 @@ module VM = struct
 
   let reboot _ dbg id timeout = queue_operation dbg id (VM_reboot (id, timeout))
 
-  let suspend _ dbg id disk =
-    queue_operation dbg id (VM_suspend (id, Disk disk))
+  let suspend _ dbg id disk = queue_operation dbg id (VM_suspend (id, Disk disk))
 
   let resume _ dbg id disk = queue_operation dbg id (VM_resume (id, Disk disk))
 
@@ -3135,7 +3235,8 @@ module VM = struct
          ; vmm_url
          ; vmm_tmp_src_id= tmp_uuid_of id ~kind:`src
          ; vmm_tmp_dest_id= tmp_uuid_of id ~kind:`dest
-         })
+         }
+      )
 
   let migrate_receive_memory _ _ _ _ _ _ = failwith "Unimplemented"
 
@@ -3175,7 +3276,8 @@ module VM = struct
               Cohttp.Response.make ~version:`HTTP_1_1 ~status:`Not_found
                 ~headers ()
             in
-            Response.write (fun _ -> ()) response s)
+            Response.write (fun _ -> ()) response s
+      )
       ()
 
   (* This is modelled closely on receive_memory and there is significant scope
@@ -3198,7 +3300,9 @@ module VM = struct
                 raise
                   (Xenopsd_error
                      (Internal_error
-                        ("Could not retrieve vgpu id from path " ^ path)))
+                        ("Could not retrieve vgpu id from path " ^ path)
+                     )
+                  )
           in
           let vgpu_id = VGPU_DB.id_of_string vgpu_id_str in
           debug "VM.receive_vgpu vgpu_id_str = %s" vgpu_id_str ;
@@ -3218,8 +3322,8 @@ module VM = struct
                   cookie_vgpu_migration
               in
               Xenops_migrate.(
-                Handshake.send ~verbose:true transferred_fd
-                  (Handshake.Error msg)) ;
+                Handshake.send ~verbose:true transferred_fd (Handshake.Error msg)
+              ) ;
               debug "VM.receive_vgpu: Synchronisation point 1-vgpu ERR %s" msg ;
               raise (Xenopsd_error (Internal_error msg))
             ) ;
@@ -3229,25 +3333,29 @@ module VM = struct
               {vgpu_fd= transferred_fd; vgpu_channel= Event.new_channel ()}
             in
             Mutex.execute vgpu_receiver_sync_m (fun () ->
-                Hashtbl.add vgpu_receiver_sync vm_id info) ;
+                Hashtbl.add vgpu_receiver_sync vm_id info
+            ) ;
             (* Inform the sender that everything is in place to start
                save/restore *)
             Xenops_migrate.(
-              Handshake.send ~verbose:true transferred_fd Handshake.Success) ;
+              Handshake.send ~verbose:true transferred_fd Handshake.Success
+            ) ;
             debug "VM.receive_vgpu: Synchronisation point 1-vgpu" ;
             (* Keep the thread/connection open until the restore is done on the
                other thread *)
             Event.receive info.vgpu_channel |> Event.sync ;
             debug "VM.receive_vgpu: Synchronisation point 2-vgpu" ;
             Mutex.execute vgpu_receiver_sync_m (fun () ->
-                Hashtbl.remove vgpu_receiver_sync vm_id)
+                Hashtbl.remove vgpu_receiver_sync vm_id
+            )
         | None ->
             let headers = Cohttp.Header.of_list [("User-agent", "xenopsd")] in
             let response =
               Cohttp.Response.make ~version:`HTTP_1_1 ~status:`Not_found
                 ~headers ()
             in
-            Response.write (fun _ -> ()) response s)
+            Response.write (fun _ -> ()) response s
+      )
       ()
 
   let generate_state_string _ _dbg vm =
@@ -3268,7 +3376,9 @@ module VM = struct
           raise
             (Xenopsd_error
                (Internal_error
-                  (Printf.sprintf "Unable to unmarshal metadata: %s" m)))
+                  (Printf.sprintf "Unable to unmarshal metadata: %s" m)
+               )
+            )
     in
     (md.Metadata.vm.Vm.id, md)
 
@@ -3287,7 +3397,8 @@ module VM = struct
           in
           id
         else
-          import_metadata id md)
+          import_metadata id md
+      )
       ()
 
   let import_metadata_async _ dbg s =
@@ -3306,7 +3417,8 @@ module DEBUG = struct
               dbg n ;
             Xenops_task.set_cancel_trigger tasks dbg (int_of_string n)
         | _, _ ->
-            B.DEBUG.trigger cmd args)
+            B.DEBUG.trigger cmd args
+      )
       ()
 
   let shutdown _ dbg () =
@@ -3340,14 +3452,16 @@ module UPDATES = struct
           | Dynamic.Vgpu (id, _) ->
               id = vm_id
         in
-        Updates.inject_barrier id filter updates)
+        Updates.inject_barrier id filter updates
+      )
       ()
 
   let remove_barrier _ dbg id =
     Debug.with_thread_associated dbg
       (fun () ->
         debug "UPDATES.remove_barrier %d" id ;
-        Updates.remove_barrier id updates)
+        Updates.remove_barrier id updates
+      )
       ()
 
   let refresh_vm _ dbg id =
@@ -3360,7 +3474,8 @@ module UPDATES = struct
         List.iter PCI_DB.signal (PCI_DB.ids id) ;
         List.iter VGPU_DB.signal (VGPU_DB.ids id) ;
         List.iter VUSB_DB.signal (VUSB_DB.ids id) ;
-        ())
+        ()
+      )
       ()
 end
 
@@ -3409,7 +3524,8 @@ let internal_event_thread_body =
                     |> TASK.destroy'
                 | x ->
                     debug "Ignoring event on %s"
-                      (Jsonrpc.to_string (rpc_of Dynamic.id x)))
+                      (Jsonrpc.to_string (rpc_of Dynamic.id x))
+                )
               updates ;
             id := Some next_id
           done
@@ -3417,7 +3533,8 @@ let internal_event_thread_body =
           error "Event thread caught: %s; restarting after 5s"
             (Printexc.to_string e) ;
           Thread.delay 5.
-      done)
+      done
+  )
 
 let set_backend m =
   backend := m ;
@@ -3435,7 +3552,8 @@ let register_objects () =
       List.iter VBD_DB.signal (VIF_DB.ids vm) ;
       List.iter PCI_DB.signal (PCI_DB.ids vm) ;
       List.iter VGPU_DB.signal (VGPU_DB.ids vm) ;
-      List.iter VUSB_DB.signal (VUSB_DB.ids vm))
+      List.iter VUSB_DB.signal (VUSB_DB.ids vm)
+    )
     (VM_DB.ids ())
 
 let upgrade_internal_state_of_running_vms () =
@@ -3445,7 +3563,8 @@ let upgrade_internal_state_of_running_vms () =
   List.iter
     (fun vm ->
       let vm_t = VM_DB.read_exn vm in
-      B.VM.get_internal_state [] [] vm_t |> B.VM.set_internal_state vm_t)
+      B.VM.get_internal_state [] [] vm_t |> B.VM.set_internal_state vm_t
+    )
     (VM_DB.ids ())
 
 type rpc_t = Rpc.t
@@ -3458,7 +3577,8 @@ let typ_of_rpc_t =
       ; test_data= [Rpc.Null]
       ; rpc_of= (fun x -> x)
       ; of_rpc= (fun x -> Ok x)
-      })
+      }
+  )
 
 module Diagnostics = struct
   type t = {
@@ -3486,7 +3606,8 @@ module Diagnostics = struct
             | Some vm ->
                 Some (id, B.VM.get_domain_action_request vm)
             | None ->
-                None)
+                None
+          )
           (VM_DB.ids ())
     }
 end
diff --git a/lib/xenops_server_simulator.ml b/lib/xenops_server_simulator.ml
index 665ba977a..d8f68cbc6 100644
--- a/lib/xenops_server_simulator.ml
+++ b/lib/xenops_server_simulator.ml
@@ -249,7 +249,8 @@ let add_vbd (vm : Vm.id) (vbd : Vbd.t) () =
     debug "VBD.plug %s.%s: Already exists" (fst vbd.Vbd.id) (snd vbd.Vbd.id) ;
     raise
       (Xenopsd_error
-         (Already_exists ("vbd", Device_number.to_debug_string this_dn)))
+         (Already_exists ("vbd", Device_number.to_debug_string this_dn))
+      )
   ) else
     DB.write vm
       {
@@ -269,7 +270,9 @@ let move_vif vm vif network () =
       raise
         (Xenopsd_error
            (Does_not_exist
-              ("VIF", Printf.sprintf "%s.%s" (fst vif.Vif.id) (snd vif.Vif.id))))
+              ("VIF", Printf.sprintf "%s.%s" (fst vif.Vif.id) (snd vif.Vif.id))
+           )
+        )
   | _ ->
       assert false
 
@@ -375,7 +378,9 @@ let remove_vif vm vif () =
     raise
       (Xenopsd_error
          (Does_not_exist
-            ("VIF", Printf.sprintf "%s.%s" (fst vif.Vif.id) (snd vif.Vif.id))))
+            ("VIF", Printf.sprintf "%s.%s" (fst vif.Vif.id) (snd vif.Vif.id))
+         )
+      )
   else
     DB.write vm
       {
@@ -392,7 +397,8 @@ let set_carrier vm vif carrier () =
         {
           vif with
           Vif.carrier= (if this_one vif then carrier else vif.Vif.carrier)
-        })
+        }
+      )
       d.Domain.vifs
   in
   DB.write vm {d with Domain.vifs}
@@ -406,7 +412,8 @@ let set_locking_mode vm vif mode () =
         {
           vif with
           Vif.locking_mode= (if this_one vif then mode else vif.Vif.locking_mode)
-        })
+        }
+      )
       d.Domain.vifs
   in
   DB.write vm {d with Domain.vifs}
@@ -425,7 +432,8 @@ let set_ipv4_configuration vm vif ipv4_configuration () =
             else
               vif.Vif.ipv4_configuration
             )
-        })
+        }
+      )
       d.Domain.vifs
   in
   DB.write vm {d with Domain.vifs}
@@ -444,7 +452,8 @@ let set_ipv6_configuration vm vif ipv6_configuration () =
             else
               vif.Vif.ipv6_configuration
             )
-        })
+        }
+      )
       d.Domain.vifs
   in
   DB.write vm {d with Domain.vifs}
@@ -458,7 +467,8 @@ let set_pvs_proxy vm vif proxy () =
         {
           vif with
           Vif.pvs_proxy= (if this_one vif then proxy else vif.Vif.pvs_proxy)
-        })
+        }
+      )
       d.Domain.vifs
   in
   DB.write vm {d with Domain.vifs}
@@ -470,7 +480,9 @@ let remove_pci vm pci () =
     raise
       (Xenopsd_error
          (Does_not_exist
-            ("PCI", Printf.sprintf "%s.%s" (fst pci.Pci.id) (snd pci.Pci.id))))
+            ("PCI", Printf.sprintf "%s.%s" (fst pci.Pci.id) (snd pci.Pci.id))
+         )
+      )
   else
     DB.write vm
       {
@@ -485,7 +497,9 @@ let remove_vbd vm vbd () =
     raise
       (Xenopsd_error
          (Does_not_exist
-            ("VBD", Printf.sprintf "%s.%s" (fst vbd.Vbd.id) (snd vbd.Vbd.id))))
+            ("VBD", Printf.sprintf "%s.%s" (fst vbd.Vbd.id) (snd vbd.Vbd.id))
+         )
+      )
   else
     DB.write vm
       {
@@ -500,7 +514,9 @@ let set_qos_vbd vm vbd () =
     raise
       (Xenopsd_error
          (Does_not_exist
-            ("VBD", Printf.sprintf "%s.%s" (fst vbd.Vbd.id) (snd vbd.Vbd.id)))) ;
+            ("VBD", Printf.sprintf "%s.%s" (fst vbd.Vbd.id) (snd vbd.Vbd.id))
+         )
+      ) ;
   (* XXX *)
   ()
 
@@ -588,7 +604,8 @@ module VM = struct
     let vbds =
       List.map
         (fun vbd ->
-          {vbd with Vbd.backend= Option.map (remap_vdi vdi_map) vbd.Vbd.backend})
+          {vbd with Vbd.backend= Option.map (remap_vdi vdi_map) vbd.Vbd.backend}
+        )
         state.Domain.vbds
     in
     let vifs = List.map (fun vif -> remap_vif vif_map vif) state.Domain.vifs in
@@ -604,7 +621,9 @@ module VM = struct
         raise
           (Xenopsd_error
              (Internal_error
-                (Printf.sprintf "Failed to unmarshal Domain.t: %s" m)))
+                (Printf.sprintf "Failed to unmarshal Domain.t: %s" m)
+             )
+          )
 
   let wait_ballooning _ _ = ()
 
@@ -670,8 +689,7 @@ module VIF = struct
 
   let move _ vm vif network = Mutex.execute m (move_vif vm vif network)
 
-  let set_carrier _ vm vif carrier =
-    Mutex.execute m (set_carrier vm vif carrier)
+  let set_carrier _ vm vif carrier = Mutex.execute m (set_carrier vm vif carrier)
 
   let set_locking_mode _ vm vif mode =
     Mutex.execute m (set_locking_mode vm vif mode)
@@ -682,8 +700,7 @@ module VIF = struct
   let set_ipv6_configuration _ vm vif ipv6_configuration =
     Mutex.execute m (set_ipv6_configuration vm vif ipv6_configuration)
 
-  let set_pvs_proxy _ vm vif proxy =
-    Mutex.execute m (set_pvs_proxy vm vif proxy)
+  let set_pvs_proxy _ vm vif proxy = Mutex.execute m (set_pvs_proxy vm vif proxy)
 
   let get_state vm vif = Mutex.execute m (vif_state vm vif)
 
diff --git a/lib/xenops_utils.ml b/lib/xenops_utils.ml
index f56d917a7..e4aa2ab9b 100644
--- a/lib/xenops_utils.ml
+++ b/lib/xenops_utils.ml
@@ -102,7 +102,8 @@ let prefixes_of k =
   let prefixes, _ =
     List.fold_left
       (fun (acc, prefix) element ->
-        ((element :: prefix) :: acc, element :: prefix))
+        ((element :: prefix) :: acc, element :: prefix)
+      )
       ([], []) k
   in
   List.map List.rev prefixes
@@ -180,7 +181,8 @@ module FileFS = struct
         | e ->
             (* Anything else probably is an error, but we just log and continue *)
             error "Failed to DB.delete %s : %s" path (Printexc.to_string e) ;
-            ())
+            ()
+      )
       (paths_of path)
 
   (** [rmtree path] removes a file or directory recursively without following
@@ -255,7 +257,8 @@ module MemFS = struct
       (fun p ->
         let dir = dir_locked (dirname p) in
         if not (StringMap.mem (filename p) !dir) then
-          dir := StringMap.add (filename p) (Dir (ref StringMap.empty)) !dir)
+          dir := StringMap.add (filename p) (Dir (ref StringMap.empty)) !dir
+      )
       (List.rev (prefixes_of path))
 
   let mkdir path = Mutex.execute m (fun () -> mkdir_locked path)
@@ -268,24 +271,28 @@ module MemFS = struct
               Some x
           | Dir _ ->
               None
-        with _ -> None)
+        with _ -> None
+    )
 
   let write path x =
     Mutex.execute m (fun () ->
         (* debug "DB.write %s <- %s" (String.concat "/" path) x; *)
         mkdir_locked (dirname path) ;
         let dir = dir_locked (dirname path) in
-        dir := StringMap.add (filename path) (Leaf x) !dir)
+        dir := StringMap.add (filename path) (Leaf x) !dir
+    )
 
   let exists path =
     Mutex.execute m (fun () ->
         try StringMap.mem (filename path) !(dir_locked (dirname path))
-        with _ -> false)
+        with _ -> false
+    )
 
   let readdir path =
     Mutex.execute m (fun () ->
         try StringMap.fold (fun x _ acc -> x :: acc) !(dir_locked path) []
-        with _ -> [])
+        with _ -> []
+    )
 
   let rm path =
     Mutex.execute m (fun () ->
@@ -302,8 +309,10 @@ module MemFS = struct
               else
                 false
             in
-            if deletable then dir := StringMap.remove (filename p) !dir)
-          (prefixes_of path))
+            if deletable then dir := StringMap.remove (filename p) !dir
+          )
+          (prefixes_of path)
+    )
 
   let rename path path' =
     Mutex.execute m (fun () ->
@@ -319,11 +328,13 @@ module MemFS = struct
                   (Printf.sprintf
                      "Invalid: rename must be called on files not directories. \
                       %s is a directory"
-                     (filename path))
+                     (filename path)
+                  )
           in
           let dir = dir_locked (dirname path') in
           dir := StringMap.add (filename path') (Leaf contents) !dir
-        with _ -> ())
+        with _ -> ()
+    )
 
   let init () = ()
 end
@@ -380,7 +391,8 @@ functor
               x
           | Error (`Msg m) ->
               failwith
-                (Printf.sprintf "Failed to unmarshal '%s': %s" I.namespace m))
+                (Printf.sprintf "Failed to unmarshal '%s': %s" I.namespace m)
+        )
         (FS.read path)
 
     let read_exn (k : I.key) =
@@ -390,7 +402,9 @@ functor
       | None ->
           raise
             (Xenopsd_error
-               (Errors.Does_not_exist (I.namespace, I.key k |> String.concat "/")))
+               (Errors.Does_not_exist (I.namespace, I.key k |> String.concat "/")
+               )
+            )
 
     let exists (k : I.key) =
       let module FS = (val get_fs_backend () : FS) in
@@ -415,7 +429,8 @@ functor
             debug "Key %s already exists" path ;
             raise (Xenopsd_error (Errors.Already_exists (I.namespace, path)))
           ) else
-            write k x)
+            write k x
+      )
 
     let remove (k : I.key) =
       Mutex.execute m (fun () ->
@@ -425,7 +440,8 @@ functor
             debug "Key %s does not exist" path ;
             raise (Xenopsd_error (Errors.Does_not_exist (I.namespace, path)))
           ) else
-            delete k)
+            delete k
+      )
 
     (* The call `update k f` reads key `k` from the DB, passes the value to `f`,
        and updates the DB with the result. If the result is `None`, then the key
@@ -445,7 +461,8 @@ functor
             | Some y' ->
                 write k y' ; true
           ) else
-            false)
+            false
+      )
 
     let rename (k : I.key) (k' : I.key) =
       Mutex.execute m (fun () ->
@@ -461,7 +478,8 @@ functor
             debug "Key %s does not exist" path ;
             raise (Xenopsd_error (Errors.Does_not_exist (I.namespace, path)))
           ) ;
-          rename k k')
+          rename k k'
+      )
 
     (* Version of `update` that raises an exception if the read fails *)
     let update_exn (k : I.key) (f : t -> t option) =
@@ -470,9 +488,12 @@ functor
             raise
               (Xenopsd_error
                  (Errors.Does_not_exist
-                    (I.namespace, I.key k |> String.concat "/")))
+                    (I.namespace, I.key k |> String.concat "/")
+                 )
+              )
         | Some x ->
-            f x)
+            f x
+        )
   end
 
 (******************************************************************************)
@@ -568,7 +589,8 @@ let get_network_backend () =
   with _ ->
     failwith
       (Printf.sprintf "Failed to read network backend from: %s"
-         !Resources.network_conf)
+         !Resources.network_conf
+      )
 
 let _sys_hypervisor_type = "/sys/hypervisor/type"
 
@@ -610,7 +632,8 @@ let chunks size lst =
           if List.length xs < size then
             (op :: xs) :: xss
           else
-            [op] :: xs :: xss)
+            [op] :: xs :: xss
+    )
     [] lst
   |> List.map (fun xs -> List.rev xs)
   |> List.rev
@@ -642,7 +665,8 @@ let char_max_encoded_length =
         let empty = Rpc.String "" in
         max
           (json_length rpc - json_length empty)
-          (xml_length rpc - xml_length empty))
+          (xml_length rpc - xml_length empty)
+  )
 
 let str_max_encoded_length str =
   let s = ref 0 in
diff --git a/lib/xenopsd.ml b/lib/xenopsd.ml
index abb72d249..5f8826bea 100644
--- a/lib/xenopsd.ml
+++ b/lib/xenopsd.ml
@@ -80,7 +80,8 @@ let for_each_line path f =
         while true do
           f ic
         done
-      with End_of_file -> ()) ;
+      with End_of_file -> ()
+  ) ;
   close_in_noerr ic
 
 let parse_oxenstored_conf path =
@@ -92,7 +93,8 @@ let parse_oxenstored_conf path =
       | Some (k, v) ->
           config := (k, v) :: !config
       | None ->
-          ()) ;
+          ()
+  ) ;
   D.debug "%s: %d config entries" path (List.length !config) ;
   !config
 
@@ -136,125 +138,154 @@ let options =
     ( "queue"
     , Arg.Set_string Xenops_interface.queue_name
     , (fun () -> !Xenops_interface.queue_name)
-    , "Listen on a specific queue" )
+    , "Listen on a specific queue"
+    )
   ; ( "sockets-path"
     , Arg.Set_string sockets_path
     , (fun () -> !sockets_path)
-    , "Directory to create listening sockets" )
+    , "Directory to create listening sockets"
+    )
   ; ( "persist"
     , Arg.Bool (fun b -> persist := b)
     , (fun () -> string_of_bool !persist)
-    , "True if we want to persist metadata across restarts" )
+    , "True if we want to persist metadata across restarts"
+    )
   ; ( "worker-pool-size"
     , Arg.Set_int worker_pool_size
     , (fun () -> string_of_int !worker_pool_size)
-    , "Number of threads for the worker pool" )
+    , "Number of threads for the worker pool"
+    )
   ; ( "database-path"
     , Arg.String (fun x -> Xenops_utils.root := Some x)
     , (fun () -> Xenops_utils.get_root ())
-    , "Location to store the metadata" )
+    , "Location to store the metadata"
+    )
   ; ( "run_hotplug_scripts"
     , Arg.Bool (fun x -> run_hotplug_scripts := x)
     , (fun () -> string_of_bool !run_hotplug_scripts)
-    , "True if xenopsd should execute the hotplug scripts directly" )
+    , "True if xenopsd should execute the hotplug scripts directly"
+    )
   ; ( "use_old_pci_add"
     , Arg.Bool (fun x -> use_old_pci_add := x)
     , (fun () -> string_of_bool !use_old_pci_add)
-    , "True if xenopsd should use the old pci add function" )
+    , "True if xenopsd should use the old pci add function"
+    )
   ; ( "hotplug_timeout"
     , Arg.Set_float hotplug_timeout
     , (fun () -> string_of_float !hotplug_timeout)
-    , "Time before we assume hotplug scripts have failed" )
+    , "Time before we assume hotplug scripts have failed"
+    )
   ; ( "qemu_dm_ready_timeout"
     , Arg.Set_float qemu_dm_ready_timeout
     , (fun () -> string_of_float !qemu_dm_ready_timeout)
-    , "Time before we assume qemu has become stuck" )
+    , "Time before we assume qemu has become stuck"
+    )
   ; ( "vgpu-ready-timeout"
     , Arg.Set_float vgpu_ready_timeout
     , (fun () -> string_of_float !vgpu_ready_timeout)
-    , "Time before we assume vgpu has become stuck or unresponsive" )
+    , "Time before we assume vgpu has become stuck or unresponsive"
+    )
   ; ( "varstored-ready-timeout"
     , Arg.Set_float varstored_ready_timeout
     , (fun () -> string_of_float !varstored_ready_timeout)
-    , "Time before we assume varstored has become stuck or unresponsive" )
+    , "Time before we assume varstored has become stuck or unresponsive"
+    )
   ; ( "watch_queue_length"
     , Arg.Set_int watch_queue_length
     , (fun () -> string_of_int !watch_queue_length)
-    , "Maximum number of unprocessed xenstore watch events before we restart" )
+    , "Maximum number of unprocessed xenstore watch events before we restart"
+    )
   ; ( "use-upstream-qemu"
     , Arg.Bool (fun x -> use_upstream_qemu := x)
     , (fun () -> string_of_bool !use_upstream_qemu)
-    , "True if we want to use upsteam QEMU" )
+    , "True if we want to use upsteam QEMU"
+    )
   ; ( "default-vbd-backend-kind"
     , Arg.Set_string default_vbd_backend_kind
     , (fun () -> !default_vbd_backend_kind)
-    , "Default backend for VBDs" )
+    , "Default backend for VBDs"
+    )
   ; ( "ca-140252-workaround"
     , Arg.Bool (fun x -> ca_140252_workaround := x)
     , (fun () -> string_of_bool !ca_140252_workaround)
-    , "Workaround for evtchn misalignment for legacy PV tools" )
+    , "Workaround for evtchn misalignment for legacy PV tools"
+    )
   ; ( "additional-ballooning-timeout"
     , Arg.Set_float additional_ballooning_timeout
     , (fun () -> string_of_float !additional_ballooning_timeout)
     , "Time we allow the guests to do additional memory ballooning before live \
-       migration" )
+       migration"
+    )
   ; ( "domain_shutdown_ack_timeout"
     , Arg.Set_float Xenops_server.domain_shutdown_ack_timeout
     , (fun () -> string_of_float !Xenops_server.domain_shutdown_ack_timeout)
     , "Time to wait for in-guest PV drivers to acknowledge a shutdown request \
-       before we conclude that the drivers have failed" )
+       before we conclude that the drivers have failed"
+    )
   ; ( "vif-ready-for-igmp-query-timeout"
     , Arg.Set_int vif_ready_for_igmp_query_timeout
     , (fun () -> string_of_int !vif_ready_for_igmp_query_timeout)
-    , "Time before we assume vif has connected" )
+    , "Time before we assume vif has connected"
+    )
   ; ( "action-after-qemu-crash"
     , Arg.String
         (fun x -> action_after_qemu_crash := if x = "" then None else Some x)
     , (fun () -> match !action_after_qemu_crash with None -> "" | Some x -> x)
     , "Action to take for VMs if QEMU crashes or dies unexpectedly: pause, \
-       poweroff. Otherwise, no action (default)." )
+       poweroff. Otherwise, no action (default)."
+    )
   ; ( "feature-flags-path"
     , Arg.Set_string feature_flags_path
     , (fun () -> !feature_flags_path)
-    , "Directory of experimental feature flags" )
+    , "Directory of experimental feature flags"
+    )
   ; ( "pvinpvh-xen-cmdline"
     , Arg.Set_string pvinpvh_xen_cmdline
     , (fun () -> !pvinpvh_xen_cmdline)
-    , "Command line for the inner-xen for PV-in-PVH guests" )
+    , "Command line for the inner-xen for PV-in-PVH guests"
+    )
   ; ( "numa-placement"
     , Arg.Bool (fun x -> numa_placement := x)
     , (fun () -> string_of_bool !numa_placement)
-    , "NUMA-aware placement of VMs" )
+    , "NUMA-aware placement of VMs"
+    )
   ; ( "numa-placement-strict"
     , Arg.Bool (fun x -> numa_placement_strict := x)
     , (fun () -> string_of_bool !numa_placement)
-    , "Fail if NUMA-aware placement is not possible" )
+    , "Fail if NUMA-aware placement is not possible"
+    )
   ; ( "pci-quarantine"
     , Arg.Bool (fun b -> pci_quarantine := b)
     , (fun () -> string_of_bool !pci_quarantine)
     , "True if IOMMU contexts of PCI devices are needed to be placed in \
-       quarantine" )
+       quarantine"
+    )
   ; ( "vm-guest-agent-xenstore-quota"
     , Arg.String
         (fun s ->
           if s <> "N/A" then
             vm_guest_agent_xenstore_quota_bytes :=
-              max_bytes_of_xenstore_entries (int_of_string s))
+              max_bytes_of_xenstore_entries (int_of_string s)
+        )
     , (fun () -> "N/A")
-    , "(Deprecated, use vm-xenstore-data-quota-bytes instead)" )
+    , "(Deprecated, use vm-xenstore-data-quota-bytes instead)"
+    )
   ; ( "vm-guest-agent-xenstore-quota-warn-interval"
     , Arg.Set_int vm_guest_agent_xenstore_quota_warn_interval
     , (fun () -> string_of_int !vm_guest_agent_xenstore_quota_warn_interval)
-    , "How often to warn that a VM is still over its xenstore quota" )
+    , "How often to warn that a VM is still over its xenstore quota"
+    )
   ; ( "oxenstored-conf"
     , Arg.Set_string oxenstored_conf
     , (fun () -> !oxenstored_conf)
-    , "Path to oxenstored conf (for reading quotas)" )
+    , "Path to oxenstored conf (for reading quotas)"
+    )
   ; ( "vm-guest-agent-xenstore-quota-bytes"
     , Arg.Set_int vm_guest_agent_xenstore_quota_bytes
     , (fun () -> string_of_int !vm_guest_agent_xenstore_quota_bytes)
     , "Maximum size in bytes of VM xenstore-data field, and guest metrics \
-       copied from guest's vm-data/ and data/ xenstore tree" )
+       copied from guest's vm-data/ and data/ xenstore tree"
+    )
   ]
 
 let path () = Filename.concat !sockets_path "xenopsd"
@@ -278,6 +309,7 @@ let rpc_fn call =
               [Rpc.Dict [("debug_info", debug_info); ("metadata", metadata)]]
           ; notif= false
           }
+        
     | "query", [debug_info; unit_p] ->
         debug "Upgrading query" ;
         Rpc.
@@ -286,6 +318,7 @@ let rpc_fn call =
           ; params= [Rpc.Dict [("debug_info", debug_info); ("unit", unit_p)]]
           ; notif= false
           }
+        
     | _ ->
         call
   in
@@ -339,7 +372,8 @@ let handle_received_fd this_connection =
           Cohttp.Response.make ~version:`HTTP_1_1 ~status:`Not_found ~headers ()
         in
         Response.write (fun _ -> ()) response this_connection
-      ))
+      )
+    )
     (fun () -> Unix.close received_fd)
 
 let doc =
@@ -401,7 +435,8 @@ let main backend =
            (module Xenops_utils.FileFS : Xenops_utils.FS)
        else
          (module Xenops_utils.MemFS : Xenops_utils.FS)
-       )) ;
+       )
+    ) ;
   Xenops_server.register_objects () ;
   Xenops_server.set_backend (Some backend) ;
   Xenops_server.upgrade_internal_state_of_running_vms () ;
@@ -413,7 +448,8 @@ let main backend =
       let (_ : Thread.t) =
         Thread.create (fun () -> Xcp_service.serve_forever xml_server) ()
       in
-      ())
+      ()
+    )
     () ;
   Xenops_server.WorkerPool.start !worker_pool_size ;
   while true do
diff --git a/list_domains/list_domains.ml b/list_domains/list_domains.ml
index 00d018ab7..8def8d8f8 100644
--- a/list_domains/list_domains.ml
+++ b/list_domains/list_domains.ml
@@ -87,7 +87,8 @@ let select table keys =
     (fun key ->
       if not (Hashtbl.mem table key) then
         failwith (Printf.sprintf "Failed to find key: %s" key) ;
-      Hashtbl.find table key)
+      Hashtbl.find table key
+    )
     keys
 
 let columns () =
@@ -142,16 +143,20 @@ let _ =
          , Arg.Unit
              (fun () ->
                memory := true ;
-               all_the_rest := true)
-         , " show all available stats (needs a wide window!)" )
+               all_the_rest := true
+             )
+         , " show all available stats (needs a wide window!)"
+         )
        ; ("-bytes", Arg.Set bytes, " use bytes for memory values")
        ; ( "-domid"
          , Arg.Int (fun i -> domid := Some i)
-         , " show only a particular domain" )
+         , " show only a particular domain"
+         )
        ; ("-memory", Arg.Set memory, " show memory statistics")
        ; ("-minimal", Arg.Set minimal, " show only domain UUID")
        ; ("-pages", Arg.Set pages, " use pages for memory values")
-       ])
+       ]
+    )
     (fun x -> Printf.printf "Warning, ignoring unknown argument: %s" x)
     "List domains" ;
   let cols = columns () in
diff --git a/suspend_image_viewer/suspend_image_viewer.ml b/suspend_image_viewer/suspend_image_viewer.ml
index 1b4ffd792..ac6bc3564 100644
--- a/suspend_image_viewer/suspend_image_viewer.ml
+++ b/suspend_image_viewer/suspend_image_viewer.ml
@@ -121,7 +121,8 @@ module D = Debug.Make (struct let name = "suspend-image-viewer" end)
 
 let print_image path =
   Xapi_stdext_unix.Unixext.with_file path [Unix.O_RDONLY] 0o400 (fun fd ->
-      print_layout (parse_layout fd))
+      print_layout (parse_layout fd)
+  )
 
 (* Command line interface *)
 let () =
@@ -136,7 +137,8 @@ let () =
       ( "path"
       , Arg.Set_string path
       , (fun () -> !path)
-      , "Path to the suspend image device" )
+      , "Path to the suspend image device"
+      )
     ]
   in
   match
diff --git a/test/test.ml b/test/test.ml
index 7ff3dded3..88bc5a4e5 100644
--- a/test/test.ml
+++ b/test/test.ml
@@ -103,7 +103,8 @@ let wait_for_tasks id =
         | Dynamic.Task id' ->
             if task_ended dbg id' then ids := StringSet.remove id' !ids
         | _ ->
-            ())
+            ()
+        )
       deltas
   done
 
@@ -120,7 +121,8 @@ let success_task id =
     | Error _ ->
         raise
           (Xenops_interface.Xenopsd_error
-             (Errors.Internal_error (Jsonrpc.to_string x)))
+             (Errors.Internal_error (Jsonrpc.to_string x))
+          )
   )
   | Task.Pending _ ->
       failwith "task pending"
@@ -140,7 +142,8 @@ let fail_not_built_task id =
     | Error _ ->
         raise
           (Xenops_interface.Xenopsd_error
-             (Errors.Internal_error (Jsonrpc.to_string x)))
+             (Errors.Internal_error (Jsonrpc.to_string x))
+          )
   )
   | Task.Pending _ ->
       failwith "task pending"
@@ -160,7 +163,8 @@ let fail_invalid_vcpus_task id =
     | Error _ ->
         raise
           (Xenops_interface.Xenopsd_error
-             (Errors.Internal_error (Jsonrpc.to_string x)))
+             (Errors.Internal_error (Jsonrpc.to_string x))
+          )
   )
   | Task.Pending _ ->
       failwith "task pending"
@@ -310,17 +314,20 @@ let vm_assert_equal vm vm' =
   assert_equal ~msg:"on_crash"
     ~printer:(fun x ->
       String.concat ", "
-        (List.map (fun x -> x |> rpc_of_action |> Jsonrpc.to_string) x))
+        (List.map (fun x -> x |> rpc_of_action |> Jsonrpc.to_string) x)
+    )
     vm.on_crash vm'.on_crash ;
   assert_equal ~msg:"on_shutdown"
     ~printer:(fun x ->
       String.concat ", "
-        (List.map (fun x -> x |> rpc_of_action |> Jsonrpc.to_string) x))
+        (List.map (fun x -> x |> rpc_of_action |> Jsonrpc.to_string) x)
+    )
     vm.on_shutdown vm'.on_shutdown ;
   assert_equal ~msg:"on_reboot"
     ~printer:(fun x ->
       String.concat ", "
-        (List.map (fun x -> x |> rpc_of_action |> Jsonrpc.to_string) x))
+        (List.map (fun x -> x |> rpc_of_action |> Jsonrpc.to_string) x)
+    )
     vm.on_reboot vm'.on_reboot ;
   assert_equal ~msg:"has_vendor_device" ~printer:string_of_bool
     vm.has_vendor_device vm'.has_vendor_device ;
@@ -419,20 +426,23 @@ let with_vm id f =
       with e ->
         Printf.fprintf stderr "Caught failure during with_vm cleanup: %s"
           (Printexc.to_string e) ;
-        raise e)
+        raise e
+    )
 
 let vm_test_add_remove _ = with_vm example_uuid (fun _ -> ())
 
 let vm_test_create_destroy _ =
   with_vm example_uuid (fun id ->
       Client.VM.create dbg id |> wait_for_task |> success_task ;
-      Client.VM.destroy dbg id |> wait_for_task |> success_task)
+      Client.VM.destroy dbg id |> wait_for_task |> success_task
+  )
 
 let vm_test_pause_unpause _ =
   with_vm example_uuid (fun id ->
       Client.VM.create dbg id |> wait_for_task |> success_task ;
       Client.VM.pause dbg id |> wait_for_task |> fail_not_built_task ;
-      Client.VM.destroy dbg id |> wait_for_task |> success_task)
+      Client.VM.destroy dbg id |> wait_for_task |> success_task
+  )
 
 let vm_test_build_pause_unpause _ =
   with_vm example_uuid (fun id ->
@@ -444,7 +454,8 @@ let vm_test_build_pause_unpause _ =
       |> success_task ;
       Client.VM.unpause dbg id |> wait_for_task |> success_task ;
       Client.VM.pause dbg id |> wait_for_task |> success_task ;
-      Client.VM.destroy dbg id |> wait_for_task |> success_task)
+      Client.VM.destroy dbg id |> wait_for_task |> success_task
+  )
 
 let vm_test_build_vcpus _ =
   with_vm example_uuid (fun id ->
@@ -465,14 +476,16 @@ let vm_test_build_vcpus _ =
         failwith (Printf.sprintf "vcpu_target %d <> 2" state.Vm.vcpu_target) ;
       Client.VM.set_vcpus dbg id 4 |> wait_for_task |> fail_invalid_vcpus_task ;
       Client.VM.set_vcpus dbg id 0 |> wait_for_task |> fail_invalid_vcpus_task ;
-      Client.VM.destroy dbg id |> wait_for_task |> success_task)
+      Client.VM.destroy dbg id |> wait_for_task |> success_task
+  )
 
 let vm_test_add_list_remove _ =
   with_vm example_uuid (fun id ->
       let vm = create_vm example_uuid in
       let (vms : (Vm.t * Vm.state) list) = Client.VM.list dbg () in
       let vm' = List.find (fun x -> x.Vm.id = id) (List.map fst vms) in
-      vm_assert_equal vm vm')
+      vm_assert_equal vm vm'
+  )
 
 let vm_remove_running _ =
   with_vm example_uuid (fun id ->
@@ -483,13 +496,15 @@ let vm_remove_running _ =
       |> success_task ;
       Client.VM.unpause dbg id |> wait_for_task |> success_task ;
       fail_running (fun () -> Client.VM.remove dbg id) ;
-      Client.VM.destroy dbg id |> wait_for_task |> success_task)
+      Client.VM.destroy dbg id |> wait_for_task |> success_task
+  )
 
 let vm_test_start_shutdown _ =
   with_vm example_uuid (fun id ->
       Client.VM.start dbg id false |> wait_for_task |> success_task ;
       fail_running (fun () -> Client.VM.remove dbg id) ;
-      Client.VM.shutdown dbg id None |> wait_for_task |> success_task)
+      Client.VM.shutdown dbg id None |> wait_for_task |> success_task
+  )
 
 let vm_test_parallel_start_shutdown _ =
   let rec ints start finish =
@@ -501,7 +516,8 @@ let vm_test_parallel_start_shutdown _ =
     List.map
       (fun x ->
         let vm = create_vm x in
-        Client.VM.add dbg vm)
+        Client.VM.add dbg vm
+      )
       ints
   in
   if !verbose_timings then (
@@ -513,7 +529,8 @@ let vm_test_parallel_start_shutdown _ =
     List.map
       (fun id ->
         let id = Client.VM.start dbg id false in
-        (* Printf.fprintf stderr "%s\n" id; flush stderr; *) id)
+        (* Printf.fprintf stderr "%s\n" id; flush stderr; *) id
+      )
       ids
   in
   wait_for_tasks tasks ;
@@ -570,8 +587,10 @@ let vm_test_reboot _ =
                 false
           )
         | _ ->
-            false) ;
-      Client.VM.shutdown dbg id None |> wait_for_task |> success_task)
+            false
+        ) ;
+      Client.VM.shutdown dbg id None |> wait_for_task |> success_task
+  )
 
 let vm_test_halt _ =
   with_vm example_uuid (fun id ->
@@ -594,7 +613,9 @@ let vm_test_halt _ =
                 false
           )
         | _ ->
-            false))
+            false
+        )
+  )
 
 let vm_test_suspend_resume _ =
   with_vm example_uuid (fun id ->
@@ -612,7 +633,8 @@ let vm_test_suspend_resume _ =
       |> success_task ;
       Client.VM.unpause dbg id |> wait_for_task |> success_task ;
       Client.VM.shutdown dbg id None |> wait_for_task |> success_task ;
-      Client.VM.destroy dbg id |> wait_for_task |> success_task)
+      Client.VM.destroy dbg id |> wait_for_task |> success_task
+  )
 
 module type DEVICE = sig
   type t
@@ -655,15 +677,16 @@ functor
       with_vm example_uuid (fun _id ->
           let dev = create (List.hd ids) (List.hd positions) in
           let (dev_id : id) = add dev in
-          remove dev_id)
+          remove dev_id
+      )
 
     let with_added_vm id f =
       with_vm id (fun id ->
           Client.VM.create dbg id |> wait_for_task |> success_task ;
           finally
             (fun () -> f id)
-            (fun () ->
-              Client.VM.destroy dbg id |> wait_for_task |> success_task))
+            (fun () -> Client.VM.destroy dbg id |> wait_for_task |> success_task)
+      )
 
     let add_plug_unplug_remove _ =
       with_added_vm example_uuid (fun _id ->
@@ -671,7 +694,8 @@ functor
           let (dev_id : id) = add dev in
           plug dev_id |> wait_for_task |> success_task ;
           unplug dev_id |> wait_for_task |> success_task ;
-          remove dev_id)
+          remove dev_id
+      )
 
     let add_plug_unplug_many_remove _ =
       with_added_vm example_uuid (fun _id ->
@@ -681,14 +705,17 @@ functor
                 let dev = create id position in
                 let id = add dev in
                 plug id |> wait_for_task |> success_task ;
-                id)
+                id
+              )
               (List.combine ids positions)
           in
           List.iter
             (fun id ->
               unplug id |> wait_for_task |> success_task ;
-              remove id)
-            ids)
+              remove id
+            )
+            ids
+      )
 
     let add_list_remove _ =
       with_vm example_uuid (fun id ->
@@ -696,13 +723,15 @@ functor
           let (dev_id : id) = add dev in
           let (devs : (t * state) list) = list id in
           let dev' = find dev_id devs in
-          assert_equal dev dev' ; remove dev_id)
+          assert_equal dev dev' ; remove dev_id
+      )
 
     let add_vm_remove _ =
       with_vm example_uuid (fun _id ->
           let dev = create (List.hd ids) (List.hd positions) in
           let (_ : id) = add dev in
-          ())
+          ()
+      )
 
     let remove_running _ =
       with_added_vm example_uuid (fun _id ->
@@ -710,7 +739,8 @@ functor
           let (dev_id : id) = add dev in
           plug dev_id |> wait_for_task |> success_task ;
           (* no unplug *)
-          fail_connected (fun () -> remove dev_id))
+          fail_connected (fun () -> remove dev_id)
+      )
   end
 
 let default_of t =
@@ -773,7 +803,8 @@ module VbdDeviceTests = DeviceTests (struct
     assert_equal ~msg:"backend"
       ~printer:(fun x ->
         Option.value ~default:"None"
-          (Option.map (fun x -> x |> rpc_of_disk |> Jsonrpc.to_string) x))
+          (Option.map (fun x -> x |> rpc_of_disk |> Jsonrpc.to_string) x)
+      )
       vbd.backend vbd'.backend ;
     assert_equal ~msg:"unpluggable" ~printer:string_of_bool vbd.unpluggable
       vbd'.unpluggable ;
@@ -838,7 +869,8 @@ module VifDeviceTests = DeviceTests (struct
     assert_equal ~msg:"mtu" ~printer:string_of_int vif.mtu vif'.mtu ;
     assert_equal ~msg:"rate"
       ~printer:(function
-        | Some (a, b) -> Printf.sprintf "Some %Ld %Ld" a b | None -> "None")
+        | Some (a, b) -> Printf.sprintf "Some %Ld %Ld" a b | None -> "None"
+        )
       vif.rate vif'.rate ;
     assert_equal ~msg:"backend"
       ~printer:(fun x -> x |> rpc_of_network_t |> Jsonrpc.to_string)
@@ -875,11 +907,14 @@ let vbd_plug_ordering_good _ =
           List.iter
             (fun vbd ->
               let (_ : Vbd.id) = Client.VBD.add dbg (vbd id) in
-              ())
+              ()
+            )
             vbds ;
           Client.VM.start dbg id false |> wait_for_task |> success_task ;
           Client.DEBUG.trigger dbg "check-vbd-plug-ordering" [id] ;
-          Client.VM.shutdown dbg id None |> wait_for_task |> success_task))
+          Client.VM.shutdown dbg id None |> wait_for_task |> success_task
+      )
+    )
     vbds
 
 let ionice_qos_scheduler _ =
@@ -898,7 +933,8 @@ let ionice_qos_scheduler _ =
       in
       assert_equal ~msg:"qos"
         ~printer:(fun x -> x |> rpc_of_qos_scheduler |> Jsonrpc.to_string)
-        x y)
+        x y
+    )
     xs
 
 let ionice_output _ =
@@ -919,8 +955,10 @@ let ionice_output _ =
           | None ->
               "None"
           | Some x ->
-              x |> rpc_of_qos_scheduler |> Jsonrpc.to_string)
-        x' y)
+              x |> rpc_of_qos_scheduler |> Jsonrpc.to_string
+          )
+        x' y
+    )
     equals
 
 let barrier_ordering () =
@@ -976,10 +1014,12 @@ let _ =
       ; ("vbd_test_add_vm_remove", `Quick, VbdDeviceTests.add_vm_remove)
       ; ( "vbd_test_add_plug_unplug_remove"
         , `Quick
-        , VbdDeviceTests.add_plug_unplug_remove )
+        , VbdDeviceTests.add_plug_unplug_remove
+        )
       ; ( "vbd_test_add_plug_unplug_many_remove"
         , `Quick
-        , VbdDeviceTests.add_plug_unplug_many_remove )
+        , VbdDeviceTests.add_plug_unplug_many_remove
+        )
       ; ("vbd_remove_running", `Quick, VbdDeviceTests.remove_running)
       ; ("vbd_plug_ordering_good", `Quick, vbd_plug_ordering_good)
       ; ("vif_test_add_remove", `Quick, VifDeviceTests.add_remove)
@@ -987,17 +1027,20 @@ let _ =
       ; ("vif_test_add_vm_remove", `Quick, VifDeviceTests.add_vm_remove)
       ; ( "vif_test_add_plug_unplug_remove"
         , `Quick
-        , VifDeviceTests.add_plug_unplug_remove )
+        , VifDeviceTests.add_plug_unplug_remove
+        )
       ; ( "vif_test_add_plug_unplug_many_remove"
         , `Quick
-        , VifDeviceTests.add_plug_unplug_many_remove )
+        , VifDeviceTests.add_plug_unplug_many_remove
+        )
       ; ("vif_remove_running", `Quick, VifDeviceTests.remove_running)
       ; ("vm_test_suspend_resume", `Quick, vm_test_suspend_resume)
       ; ("ionice_qos_scheduler", `Quick, ionice_qos_scheduler)
       ; ("ionice_output", `Quick, ionice_output)
       ; ("barrier_ordering", `Quick, barrier_ordering)
       ; ("test_ca351823", `Quick, test_ca351823)
-      ] )
+      ]
+    )
   in
   Debug.log_to_stdout () ;
   Alcotest.run "xenops test" [suite; Test_topology.suite]
diff --git a/test/test_topology.ml b/test/test_topology.ml
index b7be6a857..79d0f7921 100644
--- a/test/test_topology.ml
+++ b/test/test_topology.ml
@@ -4,8 +4,7 @@ module D = Debug.Make (struct let name = "test_topology" end)
 
 let make_numa ~numa ~cores =
   let distances =
-    Array.init numa (fun i ->
-        Array.init numa (fun j -> 10 + (11 * abs (j - i))))
+    Array.init numa (fun i -> Array.init numa (fun j -> 10 + (11 * abs (j - i))))
   in
   let cores_per_numa = cores / numa in
   let cpu_to_node = Array.init cores (fun core -> core / cores_per_numa) in
@@ -41,7 +40,8 @@ let pp =
       ; Dump.field "average" (fun t -> t.average) float
       ; Dump.field "nodes" (fun t -> t.nodes) (Dump.list NUMA.pp_dump_node)
       ; Dump.field "best" (fun t -> t.best) int
-      ])
+      ]
+  )
 
 let sum_costs l =
   D.debug "====" ;
@@ -52,7 +52,8 @@ let sum_costs l =
       ; average= accum.average +. cost.average
       ; nodes= cost.nodes @ accum.nodes
       ; best= min accum.best cost.best
-      })
+      }
+    )
     {worst= min_int; average= 0.; nodes= []; best= max_int}
     l
 
@@ -72,7 +73,8 @@ let vm_access_costs host all_vms (vcpus, nodes, cpuset) =
            let worst = List.fold_left max 0 distances in
            let best = List.fold_left min max_int distances in
            let average = float (List.fold_left ( + ) 0 distances) /. float n in
-           {worst; best; nodes= []; average})
+           {worst; best; nodes= []; average}
+       )
     |> sum_costs
   in
   D.debug "Costs: %s" (Fmt.to_to_string pp costs) ;
@@ -91,12 +93,14 @@ let cost_not_worse ~default c =
     (Fmt.to_to_string pp c) ;
   Alcotest.(
     check int "The worst-case access time must not be changed from default"
-      default.worst worst) ;
+      default.worst worst
+  ) ;
   Alcotest.(check int "Best case access time must not change" best c.best) ;
   Alcotest.(
     check (float 1e-3)
       "Average access times could improve, but must not be worse" average
-      c.average) ;
+      c.average
+  ) ;
   if c.best < default.best then
     D.debug "The new plan has improved the best-case access time!" ;
   if c.worst < default.worst then
@@ -120,7 +124,8 @@ let check_aggregate_costs_not_worse (default, next, plans) ~cores ~vms =
   let balancing_next = balancing next.nodes ~vms in
   let balancing_best = max balancing_next balancing_default in
   Alcotest.(
-    check (float 1e-3) "Balancing could improve" balancing_best balancing_next) ;
+    check (float 1e-3) "Balancing could improve" balancing_best balancing_next
+  ) ;
   if balancing_next > balancing_default then D.debug "Balancing has improved!" ;
   let used_cpus =
     plans
@@ -174,7 +179,9 @@ let test_allocate ?(mem = default_mem) (expected_cores, h) ~vms () =
              cost_not_worse ~default:costs_default costs_numa_aware ;
              ( costs_default :: costs_old
              , costs_numa_aware :: costs_new
-             , ((vm_cores, List.of_seq usednodes), plan) :: plans ))
+             , ((vm_cores, List.of_seq usednodes), plan) :: plans
+             )
+       )
        ([], [], [])
   |> check_aggregate_costs_not_worse ~cores ~vms
 
@@ -185,35 +192,47 @@ let suite =
   , [
       ( "Allocation of 1 VM on 1 node"
       , `Quick
-      , test_allocate ~vms:1 @@ make_numa ~numa:1 ~cores:2 )
+      , test_allocate ~vms:1 @@ make_numa ~numa:1 ~cores:2
+      )
     ; ( "Allocation of 10 VMs on 1 node"
       , `Quick
-      , test_allocate ~vms:10 @@ make_numa ~numa:1 ~cores:8 )
+      , test_allocate ~vms:10 @@ make_numa ~numa:1 ~cores:8
+      )
     ; ( "Allocation of 1 VM on 2 nodes"
       , `Quick
-      , test_allocate ~vms:1 @@ make_numa ~numa:2 ~cores:4 )
+      , test_allocate ~vms:1 @@ make_numa ~numa:2 ~cores:4
+      )
     ; ( "Allocation of 10 VM on 2 nodes"
       , `Quick
-      , test_allocate ~vms:10 @@ make_numa ~numa:2 ~cores:4 )
+      , test_allocate ~vms:10 @@ make_numa ~numa:2 ~cores:4
+      )
     ; ( "Allocation of 1 VM on 4 nodes"
       , `Quick
-      , test_allocate ~vms:1 @@ make_numa ~numa:4 ~cores:16 )
+      , test_allocate ~vms:1 @@ make_numa ~numa:4 ~cores:16
+      )
     ; ( "Allocation of 10 VM on 4 nodes"
       , `Quick
-      , test_allocate ~vms:10 @@ make_numa ~numa:4 ~cores:16 )
+      , test_allocate ~vms:10 @@ make_numa ~numa:4 ~cores:16
+      )
     ; ( "Allocation of 40 VM on 16 nodes"
       , `Quick
-      , test_allocate ~vms:40 @@ make_numa ~numa:16 ~cores:256 )
+      , test_allocate ~vms:40 @@ make_numa ~numa:16 ~cores:256
+      )
     ; ( "Allocation of 40 VM on 32 nodes"
       , `Quick
-      , test_allocate ~vms:40 @@ make_numa ~numa:32 ~cores:256 )
+      , test_allocate ~vms:40 @@ make_numa ~numa:32 ~cores:256
+      )
     ; ( "Allocation of 40 VM on 64 nodes"
       , `Quick
-      , test_allocate ~vms:80 @@ make_numa ~numa:64 ~cores:256 )
+      , test_allocate ~vms:80 @@ make_numa ~numa:64 ~cores:256
+      )
     ; ( "Allocation of 10 VM on assymetric nodes"
       , `Quick
-      , test_allocate ~vms:10 (make_numa_amd ~cores_per_numa:4) )
+      , test_allocate ~vms:10 (make_numa_amd ~cores_per_numa:4)
+      )
     ; ( "Allocation of 10 VM on assymetric nodes"
       , `Quick
-      , test_allocate ~vms:6 ~mem:mem3 (make_numa_amd ~cores_per_numa:4) )
-    ] )
+      , test_allocate ~vms:6 ~mem:mem3 (make_numa_amd ~cores_per_numa:4)
+      )
+    ]
+  )
diff --git a/tools/set_domain_uuid.ml b/tools/set_domain_uuid.ml
index 227f8719b..5485589a5 100644
--- a/tools/set_domain_uuid.ml
+++ b/tools/set_domain_uuid.ml
@@ -17,7 +17,8 @@ let set domain uuid =
       `Error
         ( false
         , Printf.sprintf "Caught exception while setting uuid: %s"
-            (Printexc.to_string e) )
+            (Printexc.to_string e)
+        )
 
 open Cmdliner
 
diff --git a/xc/cancel_utils.ml b/xc/cancel_utils.ml
index 01f4fee10..c4d1f3774 100644
--- a/xc/cancel_utils.ml
+++ b/xc/cancel_utils.ml
@@ -131,7 +131,8 @@ let on_shutdown ~xs domid =
         info
           "Not cancelling watches associated with domid: %d- domain nolonger \
            exists"
-          domid)
+          domid
+  )
 
 let with_path ~xs key f =
   let path = cancel_path_of ~xs key in
@@ -143,7 +144,8 @@ let with_path ~xs key f =
         debug "ignoring cancel request: operation has already terminated" ;
         (* This means a cancel happened just as we succeeded; it was too late
            and we ignore it. *)
-        ())
+        ()
+    )
 
 let cancellable_watch key good_watches error_watches
     (task : Xenops_task.task_handle) ~xs ~timeout () =
@@ -158,7 +160,9 @@ let cancellable_watch key good_watches error_watches
                 (Watch.any_of
                    (List.map
                       (fun w -> ((), w))
-                      (good_watches @ error_watches @ cancel_watches)))
+                      (good_watches @ error_watches @ cancel_watches)
+                   )
+                )
             in
             let any_have_fired ws =
               List.fold_left ( || ) false (List.map (Watch.has_fired ~xs) ws)
@@ -170,7 +174,8 @@ let cancellable_watch key good_watches error_watches
             match
               ( any_have_fired good_watches
               , any_have_fired error_watches
-              , any_have_fired cancel_watches )
+              , any_have_fired cancel_watches
+              )
             with
             | true, _, _ ->
                 true
@@ -182,4 +187,6 @@ let cancellable_watch key good_watches error_watches
                 (* they must have fired and then fired again: retest *)
                 loop ()
           in
-          loop ()))
+          loop ()
+        )
+  )
diff --git a/xc/cancel_utils_test.ml b/xc/cancel_utils_test.ml
index 08378391d..f8f4cec9b 100644
--- a/xc/cancel_utils_test.ml
+++ b/xc/cancel_utils_test.ml
@@ -28,7 +28,8 @@ let xenstore_test xs _ =
     Thread.create
       (fun () ->
         Thread.delay 1. ;
-        Xenops_task.cancel tasks task.Xenops_task.id)
+        Xenops_task.cancel tasks task.Xenops_task.id
+      )
       ()
   in
   try
@@ -45,7 +46,8 @@ let subprocess_test _ =
     Thread.create
       (fun () ->
         Thread.delay 1. ;
-        Xenops_task.cancel tasks task.Xenops_task.id)
+        Xenops_task.cancel tasks task.Xenops_task.id
+      )
       ()
   in
   try
diff --git a/xc/device.ml b/xc/device.ml
index a1bf45b22..69bd49960 100644
--- a/xc/device.ml
+++ b/xc/device.ml
@@ -170,7 +170,9 @@ module Generic = struct
               ) ;
             t.Xst.mkdirperms extra_xenserver_path
               (Xenbus_utils.rwperm_for_guest device.frontend.domid) ;
-            t.Xst.writev extra_xenserver_path xenserver_list))
+            t.Xst.writev extra_xenserver_path xenserver_list
+        )
+    )
 
   let get_private_key ~xs device x =
     let private_data_path =
@@ -238,7 +240,8 @@ module Generic = struct
         if state <> Xenbus_utils.Closed then (
           debug "Device.del_device setting backend to Closing" ;
           t.Xst.write state_path (Xenbus_utils.string_of Xenbus_utils.Closing)
-        ))
+        )
+    )
 
   let unplug_watch ~xs (x : device) =
     Hotplug.path_written_by_hotplug_scripts x |> Watch.key_to_disappear
@@ -251,7 +254,8 @@ module Generic = struct
       (fun () -> "")
       (Watch.value_to_become
          (frontend_rw_path_of_device ~xs x ^ "/state")
-         (Xenbus_utils.string_of Xenbus_utils.Closed))
+         (Xenbus_utils.string_of Xenbus_utils.Closed)
+      )
 
   let backend_closed ~xs (x : device) =
     Watch.value_to_become
@@ -270,7 +274,8 @@ module Generic = struct
            debug "Backend closed for %s, deleting hotplug-status"
              (string_of_device x) ;
            (* deleting this key causes the udev rule to fire *)
-           safe_rm ~xs (Hotplug.path_written_by_hotplug_scripts x))
+           safe_rm ~xs (Hotplug.path_written_by_hotplug_scripts x)
+       )
 
   let clean_shutdown_wait (task : Xenops_task.task_handle) ~xs
       ~ignore_transients (x : device) =
@@ -605,7 +610,8 @@ module Vbd_Common = struct
           |> Device_number.spec
           |> function
           | _, disk, _ ->
-              disk)
+              disk
+        )
         (Device_common.list_frontends ~xs domid)
     in
     let next = List.fold_left max 0 disks + 1 in
@@ -673,7 +679,8 @@ module Vbd_Common = struct
           | Disk ->
               "disk"
           | Floppy ->
-              "floppy" )
+              "floppy"
+        )
       ] ;
     List.iter
       (fun (k, v) -> Hashtbl.replace back_tbl k v)
@@ -707,7 +714,8 @@ module Vbd_Common = struct
     ) ;
     Option.iter
       (fun protocol ->
-        Hashtbl.add front_tbl "protocol" (string_of_protocol protocol))
+        Hashtbl.add front_tbl "protocol" (string_of_protocol protocol)
+      )
       x.protocol ;
     let back = Hashtbl.fold (fun k v acc -> (k, v) :: acc) back_tbl [] in
     let front = Hashtbl.fold (fun k v acc -> (k, v) :: acc) front_tbl [] in
@@ -807,9 +815,11 @@ module Vif = struct
       (match rate with None -> "none" | Some (a, b) -> sprintf "(%Ld,%Ld)" a b)
       (String.concat "; " (List.map (fun (k, v) -> k ^ "=" ^ v) other_config))
       (String.concat "; "
-         (List.map (fun (k, v) -> k ^ "=" ^ v) extra_private_keys))
+         (List.map (fun (k, v) -> k ^ "=" ^ v) extra_private_keys)
+      )
       (String.concat "; "
-         (List.map (fun (k, v) -> k ^ "=" ^ v) extra_xenserver_keys)) ;
+         (List.map (fun (k, v) -> k ^ "=" ^ v) extra_xenserver_keys)
+      ) ;
     (* Filter the other_config keys using vif_udev_keys as a whitelist *)
     let other_config =
       List.filter (fun (x, _) -> List.mem x vif_udev_keys) other_config
@@ -980,9 +990,11 @@ module NetSriovVf = struct
       vlan_str mac carrier rate_str
       (String.concat "; " (List.map (fun (k, v) -> k ^ "=" ^ v) other_config))
       (String.concat "; "
-         (List.map (fun (k, v) -> k ^ "=" ^ v) extra_private_keys))
+         (List.map (fun (k, v) -> k ^ "=" ^ v) extra_private_keys)
+      )
       (String.concat "; "
-         (List.map (fun (k, v) -> k ^ "=" ^ v) extra_xenserver_keys)) ;
+         (List.map (fun (k, v) -> k ^ "=" ^ v) extra_xenserver_keys)
+      ) ;
     let frontend = {domid; kind= NetSriovVf; devid} in
     let backend = {domid= backend_domid; kind= NetSriovVf; devid} in
     let device = {backend; frontend} in
@@ -1018,7 +1030,9 @@ module NetSriovVf = struct
               "Failed to configure network SR-IOV VF (pci:%s) with mac=%s \
                vlan=%s rate=%s: %s"
               (Pci.string_of_address pci)
-              mac vlan_str rate_str s)) ;
+              mac vlan_str rate_str s
+           )
+    ) ;
     device
 
   let hard_shutdown ~xs (x : device) =
@@ -1109,7 +1123,8 @@ module DaemonMgmt (D : DAEMONPIDPATH) = struct
                 None
               with Unix.Unix_error (Unix.EAGAIN, _, _) ->
                 (* cannot obtain lock: process is alive *)
-                Some pid)
+                Some pid
+          )
       | _ ->
           (* backward compatibility during update installation: only has
              xenstore pid *)
@@ -1142,8 +1157,7 @@ module DaemonMgmt (D : DAEMONPIDPATH) = struct
         | None ->
             ()
         | Some path ->
-            best_effort (sprintf "removing %s" path) (fun () ->
-                Unix.unlink path)
+            best_effort (sprintf "removing %s" path) (fun () -> Unix.unlink path)
       )
 
   let syslog_key ~domid = Printf.sprintf "%s-%d" D.name domid
@@ -1298,8 +1312,8 @@ module PV_Vnc = struct
     else
       try
         Some
-          (Socket.Port
-             (int_of_string (xs.Xs.read (Generic.vnc_port_path domid))))
+          (Socket.Port (int_of_string (xs.Xs.read (Generic.vnc_port_path domid)))
+          )
       with _ -> None
 
   let get_tc_port ~xs domid =
@@ -1407,19 +1421,20 @@ module PCI = struct
           Some
             (Printf.sprintf "Domain_not_running(inserting pci=%s,domid=%d)"
                (Xenops_interface.Pci.string_of_address addr)
-               domid)
+               domid
+            )
       | Cannot_add (devices, e) ->
           let addrs =
             devices
             |> List.map Xenops_interface.Pci.string_of_address
             |> String.concat ";"
           in
-          Some
-            (Printf.sprintf "Cannot_add(%s, %s)" addrs (Printexc.to_string e))
+          Some (Printf.sprintf "Cannot_add(%s, %s)" addrs (Printexc.to_string e))
       | Ioemu_failed (name, msg) ->
           Some (Printf.sprintf "Ioemu_failed(%s, %s)" name msg)
       | _ ->
-          None)
+          None
+      )
 
   (* From
      https://github.com/torvalds/linux/blob/v4.19/include/linux/pci.h#L76-L102 *)
@@ -1450,7 +1465,8 @@ module PCI = struct
           ()
         with e ->
           debug "xl %s: %s" cmd (Printexc.to_string e) ;
-          raise e)
+          raise e
+      )
       pcidevs
 
   let add_xl = xl_pci "pci-attach"
@@ -1476,14 +1492,16 @@ module PCI = struct
       (* remove the silly prefix *)
       int_of_string
         (String.sub x (String.length prefix)
-           (String.length x - String.length prefix))
+           (String.length x - String.length prefix)
+        )
     in
     let pairs =
       List.map
         (fun x ->
           ( device_number_of_string x
           , Xenops_interface.Pci.address_of_string (xs.Xs.read (path ^ "/" ^ x))
-          ))
+          )
+        )
         all
     in
     (* Sort into the order the devices were plugged *)
@@ -1551,7 +1569,8 @@ module PCI = struct
                      ; hostaddr= string_of_address host
                      ; permissive= false
                      }
-               })
+               }
+            )
         in
         ()
       else
@@ -1576,7 +1595,8 @@ module PCI = struct
             let scan_start = Nativeint.(shift_right_logical scan_start 12) in
             let scan_size =
               Nativeint.(
-                shift_right_logical (add _page_size scan_size |> pred) 12)
+                shift_right_logical (add _page_size scan_size |> pred) 12
+              )
             in
             Xenctrl.domain_iomem_permission xc domid scan_start scan_size true
     in
@@ -1602,8 +1622,10 @@ module PCI = struct
           xs.Xs.write
             (Printf.sprintf "%s/dev-%d"
                (device_model_pci_device_path xs 0 domid)
-               dev)
-            (Pci.string_of_address pcidev))
+               dev
+            )
+            (Pci.string_of_address pcidev)
+        )
         pcidevs
     with exn ->
       Backtrace.is_important exn ;
@@ -1628,7 +1650,8 @@ module PCI = struct
           ignore
             (Forkhelpers.execute_command_get_output
                !Xc_resources.pci_flr_script
-               [s; devstr])
+               [s; devstr]
+            )
         with _ -> ()
     in
     callscript "flr-pre" device ;
@@ -1711,7 +1734,8 @@ module PCI = struct
           | Some ("i915", _) ->
               true
           | _ ->
-              false)
+              false
+        )
         false "/proc/modules"
     in
     if not is_loaded then
@@ -1727,7 +1751,10 @@ module PCI = struct
           (Xenopsd_error
              (Internal_error
                 (Printf.sprintf "Fail to bind to i915, device is bound to %s"
-                   (string_of_driver drv))))
+                   (string_of_driver drv)
+                )
+             )
+          )
 
   let unbind devstr driver =
     let driverstr = string_of_driver driver in
@@ -1899,8 +1926,10 @@ module PCI = struct
             (* Unbinding from one driver and binding to another driver. *)
             | Some old_driver, new_driver ->
                 unbind_from devstr old_driver ;
-                bind_to devstr new_driver)
-          devices)
+                bind_to devstr new_driver
+          )
+          devices
+    )
 
   let enumerate_devs ~xs (x : device) =
     let backend_path = backend_path_of_device ~xs x in
@@ -1918,7 +1947,8 @@ module PCI = struct
     List.rev
       (List.fold_left
          (fun acc dev -> match dev with None -> acc | Some dev -> dev :: acc)
-         [] (Array.to_list devs))
+         [] (Array.to_list devs)
+      )
 
   let reset ~xs address =
     let devstr = Xenops_interface.Pci.string_of_address address in
@@ -1929,7 +1959,8 @@ module PCI = struct
     debug "Device.Pci.clean_shutdown %s" (string_of_device x) ;
     let devs = enumerate_devs ~xs x in
     Xenctrl.with_intf (fun xc ->
-        try release devs x.frontend.domid with _ -> ()) ;
+        try release devs x.frontend.domid with _ -> ()
+    ) ;
     ()
 
   let hard_shutdown (task : Xenops_task.task_handle) ~xs (x : device) =
@@ -1958,7 +1989,8 @@ module PCI = struct
           [
             (Printf.sprintf "device-model/%d/command" domid, cmd)
           ; (Printf.sprintf "device-model/%d/parameter" domid, parameter)
-          ])
+          ]
+    )
 
   (* Return a list of PCI devices *)
   let list = read_pcidir
@@ -1987,14 +2019,16 @@ module PCI = struct
         else (
           t.Xst.mkdirperms frontend_path
             Xs_protocol.ACL.
-              {owner= frontend_domid; other= NONE; acl= [(backend_domid, READ)]} ;
+              {owner= frontend_domid; other= NONE; acl= [(backend_domid, READ)]}
+             ;
           t.Xst.writev frontend_path
             [
               ("backend", backend_path)
             ; ("backend-id", string_of_int backend_domid)
             ; ("state", "1")
             ]
-        ))
+        )
+    )
 end
 
 module Vfs = struct
@@ -2032,7 +2066,8 @@ module Vfs = struct
         let perms = Xs_protocol.ACL.{owner= domid; other= NONE; acl= []} in
         let request_path = Printf.sprintf "%s/%d" request_path 0 in
         t.Xst.mkdirperms request_path perms ;
-        t.Xst.write (request_path ^ "/frontend") frontend_path) ;
+        t.Xst.write (request_path ^ "/frontend") frontend_path
+    ) ;
     ()
 
   let hard_shutdown (task : Xenops_task.task_handle) ~xs (x : device) =
@@ -2125,7 +2160,10 @@ module Vusb = struct
         (Xenopsd_error
            (Internal_error
               (Printf.sprintf "Call to usb reset failed: %s"
-                 (Printexc.to_string err))))
+                 (Printexc.to_string err)
+              )
+           )
+        )
 
   let cleanup domid =
     try
@@ -2189,13 +2227,15 @@ module Vusb = struct
           qmp_send_cmd domid
             Qmp.(
               Device_add
-                Device.{driver; device= USB {USB.id= driver_id; params= None}})
+                Device.{driver; device= USB {USB.id= driver_id; params= None}}
+            )
           |> ignore
       in
       let usb_bus0 = ("usb-bus.0", fun () -> ()) in
       let ehci0 =
         ( "ehci.0"
-        , fun () -> vusb_controller_plug ~driver:"usb-ehci" ~driver_id:"ehci" )
+        , fun () -> vusb_controller_plug ~driver:"usb-ehci" ~driver_id:"ehci"
+        )
       in
       let speed_of_float x =
         if x <= 0. then
@@ -2249,7 +2289,9 @@ module Vusb = struct
           raise
             (Xenopsd_error
                (Internal_error
-                  (Printf.sprintf "qemu pid does not exist for vm %d" domid)))
+                  (Printf.sprintf "qemu pid does not exist for vm %d" domid)
+               )
+            )
       ) ;
       let cmd =
         Qmp.(
@@ -2258,7 +2300,9 @@ module Vusb = struct
               {
                 driver= "usb-host"
               ; device= USB {USB.id; params= Some USB.{bus; hostbus; hostport}}
-              })
+              }
+            
+        )
       in
       qmp_send_cmd domid cmd |> ignore
     )
@@ -2270,7 +2314,8 @@ module Vusb = struct
         if Qemu.is_running ~xs domid then
           try qmp_send_cmd domid Qmp.(Device_del id) |> ignore
           with QMP_connection_error _ ->
-            raise (Xenopsd_error Device_not_connected))
+            raise (Xenopsd_error Device_not_connected)
+      )
       (fun () -> usb_reset_detach ~hostbus ~hostport ~domid ~privileged)
 end
 
@@ -2445,7 +2490,8 @@ module Dm_Common = struct
         | None ->
             ()
         | Some param ->
-            t.Xst.write (cmdpath ^ "/parameter") param) ;
+            t.Xst.write (cmdpath ^ "/parameter") param
+    ) ;
     match wait_for with
     | Some state ->
         let pw = cmdpath ^ "/state" in
@@ -2519,7 +2565,8 @@ module Dm_Common = struct
         | Some domid ->
             ( []
             , Printf.sprintf "%s,lock-key-sync=off"
-                (Socket.Unix.path (vnc_socket_path domid)) )
+                (Socket.Unix.path (vnc_socket_path domid))
+            )
       in
       let vnc_opt = ["-vnc"; vnc_arg] in
       let keymap_opt = match keymap with Some k -> ["-k"; k] | None -> [] in
@@ -2561,14 +2608,16 @@ module Dm_Common = struct
                | k, None ->
                    ["-" ^ k]
                | k, Some v ->
-                   ["-" ^ k; v])
+                   ["-" ^ k; v]
+               )
           |> List.concat
         ; (info.monitor |> function None -> [] | Some x -> ["-monitor"; x])
         ; (Qemu.pidfile_path domid |> function
            | None ->
                []
            | Some x ->
-               ["-pidfile"; x])
+               ["-pidfile"; x]
+          )
         ]
     in
     {argv; fd_map= []}
@@ -2645,9 +2694,13 @@ module Dm_Common = struct
                    (Xenopsd_error
                       (Internal_error
                          (Printf.sprintf "NVidia vGPU metadata incomplete (%s)"
-                            __LOC__)))
+                            __LOC__
+                         )
+                      )
+                   )
              | _ ->
-                 "")
+                 ""
+         )
     in
     let suspend_file = sprintf demu_save_path domid in
     let base_args =
@@ -2677,14 +2730,16 @@ module Dm_Common = struct
       |> List.map (fun domid ->
              let path = Printf.sprintf "%s/%s/device/vgpu" root domid in
              try List.map (fun x -> path ^ "/" ^ x) (xs.Xs.directory path)
-             with Xs_protocol.Enoent _ -> [])
+             with Xs_protocol.Enoent _ -> []
+         )
       |> List.concat
       |> List.exists (fun vgpu ->
              try
                let path = Printf.sprintf "%s/pf" vgpu in
                let pf = xs.Xs.read path in
                pf = physical_function
-             with Xs_protocol.Enoent _ -> false)
+             with Xs_protocol.Enoent _ -> false
+         )
     with Xs_protocol.Enoent _ -> false
 
   let call_gimtool args =
@@ -2760,21 +2815,26 @@ module Dm_Common = struct
           let open Generic in
           best_effort
             "signalling that qemu is ending as expected, mask further signals"
-            (fun () -> Qemu.SignalMask.set Qemu.signal_mask domid) ;
+            (fun () -> Qemu.SignalMask.set Qemu.signal_mask domid
+          ) ;
           best_effort "killing qemu-dm" (fun () -> really_kill qemu_pid) ;
           best_effort "removing qemu-pid from xenstore" (fun () ->
-              xs.Xs.rm qemu_pid_path) ;
+              xs.Xs.rm qemu_pid_path
+          ) ;
           best_effort
             "unmasking signals, qemu-pid is already gone from xenstore"
-            (fun () -> Qemu.SignalMask.unset Qemu.signal_mask domid) ;
+            (fun () -> Qemu.SignalMask.unset Qemu.signal_mask domid
+          ) ;
           best_effort "removing device model path from xenstore" (fun () ->
-              xs.Xs.rm (device_model_path ~qemu_domid domid)) ;
+              xs.Xs.rm (device_model_path ~qemu_domid domid)
+          ) ;
           match Qemu.pidfile_path domid with
           | None ->
               ()
           | Some path ->
               best_effort (sprintf "removing %s" path) (fun () ->
-                  Unix.unlink path)
+                  Unix.unlink path
+              )
         )
     in
     let stop_vgpu () = Vgpu.stop ~xs domid in
@@ -2806,7 +2866,8 @@ module Dm_Common = struct
            ; (if file <> "" then ["auto-read-only=off"] else [])
            ; Media.readonly_of media
            ; Media.format_of media file
-           ])
+           ]
+        )
     ; "-device"
     ; String.concat ","
         (List.concat
@@ -2818,7 +2879,8 @@ module Dm_Common = struct
              ; sprintf "unit=%d" (index mod 2)
              ]
            ; (if trad_compat then Media.lba_of media else [])
-           ])
+           ]
+        )
     ]
 
   let nvme = "nvme"
@@ -2873,7 +2935,8 @@ module Dm_Common = struct
                | None ->
                    []
              )
-           ])
+           ]
+        )
     ]
 
   let cant_suspend_reason_path domid =
@@ -3002,8 +3065,10 @@ module Backend = struct
             try
               Some
                 (Socket.Port
-                   (int_of_string (xs.Xs.read (Generic.vnc_port_path domid))))
-            with _ -> None)
+                   (int_of_string (xs.Xs.read (Generic.vnc_port_path domid)))
+                )
+            with _ -> None
+        )
 
       let assert_can_suspend ~xs _ = ()
 
@@ -3338,12 +3403,14 @@ module Backend = struct
           (fun () ->
             Lookup.remove c domid ;
             Monitor.remove m (Qmp_protocol.to_fd c) ;
-            debug "Removed QMP Event fd for domain %d" domid)
+            debug "Removed QMP Event fd for domain %d" domid
+          )
           (fun () -> Qmp_protocol.close c)
       with e ->
         debug_exn
           (Printf.sprintf "Got exception trying to remove QMP on domain-%d"
-             domid)
+             domid
+          )
           e
 
     let add domid =
@@ -3358,7 +3425,8 @@ module Backend = struct
       with e ->
         debug_exn
           (Printf.sprintf "QMP domain-%d: negotiation failed: removing socket"
-             domid)
+             domid
+          )
           e ;
         remove domid ;
         raise
@@ -3381,7 +3449,9 @@ module Backend = struct
           @@ Xenopsd_error
                (Internal_error
                   (sprintf "Unexpected result for QMP command: %s"
-                     Qmp.(other |> as_msg |> string_of_message)))
+                     Qmp.(other |> as_msg |> string_of_message)
+                  )
+               )
       | exception QMP_Error (_, msg) -> (
         match Astring.String.find_sub ~sub:"CommandNotFound" msg with
         | None ->
@@ -3407,7 +3477,8 @@ module Backend = struct
                 Int64.(add timeoffset (of_string rtc) |> to_string)
             with e ->
               error "Failed to process RTC_CHANGE for domain %d: %s" domid
-                (Printexc.to_string e))
+                (Printexc.to_string e)
+        )
       in
       let xen_platform_pv_driver_info pv_info =
         with_xs (fun xs ->
@@ -3426,7 +3497,8 @@ module Backend = struct
                 (write_local_domain "control/feature-")
                 ["suspend"; "poweroff"; "reboot"; "vcpu-hotplug"] ;
               List.iter (write_local_domain "data/") ["updated"]
-            ))
+            )
+        )
       in
       qmp_event.data |> function
       | Some (RTC_CHANGE timeoffset) ->
@@ -3488,7 +3560,8 @@ module Backend = struct
                    debug "EPOLL error on domain-%d, close QMP socket" domid ;
                    Readln.free qmp ;
                    remove domid
-                 ))
+                 )
+             )
         with e -> debug_exn "Exception in QMP_Event_thread: %s" e
       done
   end
@@ -3520,7 +3593,9 @@ module Backend = struct
             raise
               (Xenopsd_error
                  (Internal_error
-                    (Printf.sprintf "unexpected disk for devid %d" devid)))
+                    (Printf.sprintf "unexpected disk for devid %d" devid)
+                 )
+              )
 
       let qemu_media_change ~xs device _type params =
         Vbd_Common.qemu_media_change ~xs device _type params ;
@@ -3544,7 +3619,10 @@ module Backend = struct
                         (Xenopsd_error
                            (Internal_error
                               (sprintf "Unexpected result for QMP command: %s"
-                                 Qmp.(other |> as_msg |> string_of_message))))
+                                 Qmp.(other |> as_msg |> string_of_message)
+                              )
+                           )
+                        )
                 in
                 finally
                   (fun () ->
@@ -3556,24 +3634,31 @@ module Backend = struct
                         ; medium_filename= path
                         ; medium_format= Some "raw"
                         }
+                      
                     in
                     let cmd = Qmp.(Blockdev_change_medium medium) in
-                    qmp_send_cmd domid cmd |> ignore)
+                    qmp_send_cmd domid cmd |> ignore
+                  )
                   (fun () ->
                     let cmd = Qmp.(Remove_fd fd_info.fdset_id) in
-                    qmp_send_cmd domid cmd |> ignore))
+                    qmp_send_cmd domid cmd |> ignore
+                  )
+              )
               (fun () -> Unix.close fd_cd)
         with
         | Unix.Unix_error (Unix.ECONNREFUSED, "connect", p) ->
             raise
               (Xenopsd_error
                  (Internal_error
-                    (Printf.sprintf "Failed to connnect QMP socket: %s" p)))
+                    (Printf.sprintf "Failed to connnect QMP socket: %s" p)
+                 )
+              )
         | Unix.Unix_error (Unix.ENOENT, "open", p) ->
             raise
               (Xenopsd_error
-                 (Internal_error
-                    (Printf.sprintf "Failed to open CD Image: %s" p)))
+                 (Internal_error (Printf.sprintf "Failed to open CD Image: %s" p)
+                 )
+              )
         | Xenopsd_error (Internal_error _) as e ->
             raise e
         | e ->
@@ -3582,7 +3667,10 @@ module Backend = struct
                  (Internal_error
                     (Printf.sprintf
                        "Get unexpected error trying to change CD: %s"
-                       (Printexc.to_string e))))
+                       (Printexc.to_string e)
+                    )
+                 )
+              )
     end
 
     (* Backend.Qemu_upstream_compat.Vbd *)
@@ -3612,7 +3700,9 @@ module Backend = struct
                     {
                       driver= VCPU.Driver.(string_of QEMU32_I386_CPU)
                     ; device= VCPU {VCPU.id; socket_id; core_id; thread_id}
-                    })
+                    }
+                  
+              )
             |> ignore
         | false ->
             (* hotunplug *)
@@ -3623,7 +3713,8 @@ module Backend = struct
                   x
                   |> List.filter
                        (fun Qmp.Device.VCPU.{qom_path; props= {socket_id}} ->
-                         socket_id = devid)
+                         socket_id = devid
+                     )
                   |> function
                   | [] ->
                       err (sprintf "No QEMU CPU found with devid %d" devid)
@@ -3636,7 +3727,8 @@ module Backend = struct
                   let as_msg cmd = Qmp.(Success (Some __LOC__, cmd)) in
                   err
                     (sprintf "Unexpected result for QMP command: %s"
-                       Qmp.(other |> as_msg |> string_of_message))
+                       Qmp.(other |> as_msg |> string_of_message)
+                    )
             in
             qom_path |> fun id ->
             qmp_send_cmd domid Qmp.(Device_del id) |> ignore
@@ -3647,7 +3739,8 @@ module Backend = struct
     module Dm = struct
       let get_vnc_port ~xs domid =
         Dm_Common.get_vnc_port ~xs domid ~f:(fun () ->
-            Some (Socket.Unix (Dm_Common.vnc_socket_path domid)))
+            Some (Socket.Unix (Dm_Common.vnc_socket_path domid))
+        )
 
       let assert_can_suspend ~xs domid =
         QMP_Event.update_cant_suspend domid xs ;
@@ -3661,7 +3754,9 @@ module Backend = struct
                     , domid
                       |> Xenops_helpers.uuid_of_domid ~xs
                       |> Uuidm.to_string
-                    , msg ))
+                    , msg
+                    )
+                 )
         | exception e ->
             debug "assert_can_suspend: OK (domid=%d)" domid ;
             ()
@@ -3684,15 +3779,21 @@ module Backend = struct
                     (Xenopsd_error
                        (Internal_error
                           (sprintf "Unexpected result for QMP command: %s"
-                             Qmp.(other |> as_msg |> string_of_message))))
+                             Qmp.(other |> as_msg |> string_of_message)
+                          )
+                       )
+                    )
             in
             finally
               (fun () ->
                 let path = sprintf "/dev/fdset/%d" fd.Qmp.fdset_id in
                 qmp_send_cmd domid Qmp.Stop |> ignore ;
-                qmp_send_cmd domid Qmp.(Xen_save_devices_state path) |> ignore)
+                qmp_send_cmd domid Qmp.(Xen_save_devices_state path) |> ignore
+              )
               (fun () ->
-                qmp_send_cmd domid Qmp.(Remove_fd fd.fdset_id) |> ignore))
+                qmp_send_cmd domid Qmp.(Remove_fd fd.fdset_id) |> ignore
+              )
+          )
           (fun () -> Unix.close save_fd)
 
       (* Wait for QEMU's event socket to appear. Connect to it to make sure it
@@ -3728,7 +3829,8 @@ module Backend = struct
                   Thread.delay 0.1
               ) else
                 Thread.delay 0.05
-            done)
+            done
+          )
           (fun () -> Unix.close socket) ;
         if not !finished then
           raise (Ioemu_failed (name, "Timeout reached while starting daemon"))
@@ -3758,7 +3860,8 @@ module Backend = struct
         (* unmounts devices in /var/xen/qemu/root-* *)
         let path = Printf.sprintf "/var/xen/qemu/root-%d" domid in
         Generic.best_effort (Printf.sprintf "removing %s" path) (fun () ->
-            Xenops_utils.FileFS.rmtree path)
+            Xenops_utils.FileFS.rmtree path
+        )
 
       let tap_open ifname =
         let uuid = Uuidm.to_string (Uuidm.create `V4) in
@@ -3779,7 +3882,8 @@ module Backend = struct
               let devs =
                 devices
                 |> List.map (fun (x, y) ->
-                       ["-device"; sprintf "usb-%s,port=%d" x y])
+                       ["-device"; sprintf "usb-%s,port=%d" x y]
+                   )
                 |> List.concat
               in
               "-usb" :: devs
@@ -3823,7 +3927,9 @@ module Backend = struct
                 (Ioemu_failed
                    ( sprintf "domid %d" domid
                    , sprintf "Unknown platform:disk_type=%s in device-model=%s"
-                       disk_type Config.name ))
+                       disk_type Config.name
+                   )
+                )
         in
         if not (Config.Firmware.supported info.firmware) then
           (* XAPI itself should've already prevented this, but lets double check *)
@@ -3831,14 +3937,17 @@ module Backend = struct
             (Ioemu_failed
                ( sprintf "domid %d" domid
                , sprintf "The firmware doesn't support device-model=%s"
-                   Config.name )) ;
+                   Config.name
+               )
+            ) ;
         let qmp =
           ["libxl"; "event"]
           |> List.map (fun x ->
                  [
                    "-qmp"
                  ; sprintf "unix:/var/run/xen/qmp-%s-%d,server,nowait" x domid
-                 ])
+                 ]
+             )
           |> List.concat
         in
         let pv_device addr =
@@ -3860,8 +3969,7 @@ module Backend = struct
                 "-xen-domid"
               ; string_of_int domid
               ; "-m"
-              ; "size="
-                ^ Int64.to_string (Int64.div info.Dm_Common.memory 1024L)
+              ; "size=" ^ Int64.to_string (Int64.div info.Dm_Common.memory 1024L)
               ; "-boot"
               ; "order=" ^ info.Dm_Common.boot
               ]
@@ -3884,7 +3992,8 @@ module Backend = struct
                | None ->
                    ["-parallel"; "null"]
                | Some x ->
-                   ["-parallel"; x])
+                   ["-parallel"; x]
+              )
             ; qmp
             ; Config.XenPlatform.device ~xs ~domid ~info
             ]
@@ -3979,6 +4088,7 @@ module Backend = struct
                   common.argv @ misc @ disks' @ pv_device pv_device_addr @ none
               ; fd_map= common.fd_map
               }
+            
         | _, fds, argv ->
             Dm_Common.
               {
@@ -3986,6 +4096,7 @@ module Backend = struct
                   common.argv @ misc @ disks' @ pv_device pv_device_addr @ argv
               ; fd_map= common.fd_map @ fds
               }
+            
 
       let after_suspend_image ~xs ~qemu_domid domid =
         (* device model not needed anymore after suspend image has been created *)
@@ -4151,7 +4262,8 @@ module Dm = struct
        | None ->
            return ()
        | Some x ->
-           Add.many ["--pidfile"; x])
+           Add.many ["--pidfile"; x]
+      )
       >>= fun () ->
       Add.many @@ argf "uuid:%s" vm_uuid >>= fun () ->
       on reset_on_boot @@ Add.arg "--nonpersistent" >>= fun () ->
@@ -4220,14 +4332,17 @@ module Dm = struct
           raise
             (Ioemu_failed
                ( "vgpu"
-               , Printf.sprintf "Daemon vgpu returned error: %s" error_code ))
+               , Printf.sprintf "Daemon vgpu returned error: %s" error_code
+               )
+            )
     | [{physical_pci_address= pci; implementation= GVT_g vgpu}] ->
         PCI.bind [pci] PCI.I915
     | [{physical_pci_address= pci; implementation= MxGPU vgpu}] ->
         Mutex.execute gimtool_m (fun () ->
             configure_gim ~xs pci vgpu.vgpus_per_pgpu vgpu.framebufferbytes ;
             let keys = [("pf", Xenops_interface.Pci.string_of_address pci)] in
-            write_vgpu_data ~xs domid 0 keys)
+            write_vgpu_data ~xs domid 0 keys
+        )
     | _ ->
         failwith "Unsupported vGPU configuration"
 
@@ -4278,7 +4393,8 @@ module Dm = struct
       finally
         (fun () ->
           init_daemon ~task ~path:(Profile.wrapper_of dm) ~args:argv ~domid ~xs
-            ~ready_path ~timeout ~cancel ~fds:args.fd_map dm)
+            ~ready_path ~timeout ~cancel ~fds:args.fd_map dm
+        )
         (fun () -> List.iter close args.fd_map)
     in
     match !Xenopsd.action_after_qemu_crash with
@@ -4298,8 +4414,10 @@ module Dm = struct
                        Forkhelpers.waitpid_fail_if_bad_exit x ;
                        None
                      with e -> Some e
-                   ))
-               x)
+                   )
+               )
+               x
+            )
         in
         waitpid_async qemu_pid ~callback:(fun qemu_crash ->
             Forkhelpers.(
@@ -4342,7 +4460,9 @@ module Dm = struct
                 | Some _ ->
                     (* before expected qemu stop: qemu-pid is available in
                        domain xs tree: signal action to take *)
-                    xs.Xs.write (Qemu.pid_path_signal domid) crash_reason))
+                    xs.Xs.write (Qemu.pid_path_signal domid) crash_reason
+            )
+        )
 
   let start (task : Xenops_task.task_handle) ~xc ~xs ~dm ?timeout info domid =
     __start task ~xc ~xs ~dm ?timeout Start info domid
diff --git a/xc/device_common.ml b/xc/device_common.ml
index 7fc3d7234..f071f66e3 100644
--- a/xc/device_common.ml
+++ b/xc/device_common.ml
@@ -215,13 +215,15 @@ let add_backend_keys ~xs (x : device) subdir keys =
     backend ;
   Xs.transaction xs (fun t ->
       ignore (t.Xst.read backend_stub) ;
-      t.Xst.writev backend keys)
+      t.Xst.writev backend keys
+  )
 
 let remove_backend_keys ~xs (x : device) subdir keys =
   let backend_stub = backend_path_of_device ~xs x in
   let backend = backend_stub ^ "/" ^ subdir in
   Xs.transaction xs (fun t ->
-      List.iter (fun key -> t.Xst.rm (backend ^ "/" ^ key)) keys)
+      List.iter (fun key -> t.Xst.rm (backend ^ "/" ^ key)) keys
+  )
 
 let string_of_device (x : device) =
   sprintf "frontend %s; backend %s"
@@ -340,7 +342,8 @@ let list_frontends ~xs ?for_devids domid =
                    try
                      ignore (xs.Xs.read (sprintf "%s/%d" dir devid)) ;
                      true
-                   with _ -> false)
+                   with _ -> false
+                 )
                  devids
          in
          to_list
@@ -355,9 +358,13 @@ let list_frontends ~xs ?for_devids domid =
                       Some {backend= b; frontend}
                   | None ->
                       None
-                with _ -> None)
-              devids))
-       kinds)
+                with _ -> None
+              )
+              devids
+           )
+       )
+       kinds
+    )
 
 (* NB: we only read data from the backend directory. Therefore this gives the
    "backend's point of view". *)
@@ -392,10 +399,16 @@ let list_backends ~xs domid =
                              Some {backend; frontend= f}
                          | None ->
                              None
-                       with _ -> None)
-                     devids))
-              domids))
-       kinds)
+                       with _ -> None
+                     )
+                     devids
+                  )
+              )
+              domids
+           )
+       )
+       kinds
+    )
 
 (** Return a list of devices connecting two domains. Ignore those whose kind we
     don't recognise *)
@@ -550,4 +563,5 @@ let qmp_send_cmd ?send_fd domid cmd =
       | message ->
           let msg' = Qmp.string_of_message message in
           error "QMP result for domid %d: %s (%s)" domid msg' __LOC__ ;
-          raise (QMP_Error (domid, msg')))
+          raise (QMP_Error (domid, msg'))
+  )
diff --git a/xc/domain.ml b/xc/domain.ml
index 683d88b09..a66d84c6b 100644
--- a/xc/domain.ml
+++ b/xc/domain.ml
@@ -158,8 +158,7 @@ let filtered_xsdata =
   (* disallowed by default; allowed only if it has one of a set of prefixes *)
   let is_allowed path dir = Astring.String.is_prefix ~affix:(dir ^ "/") path in
   let allowed (x, _) =
-    List.fold_left ( || ) false
-      (List.map (is_allowed x) allowed_xsdata_prefixes)
+    List.fold_left ( || ) false (List.map (is_allowed x) allowed_xsdata_prefixes)
   in
   List.filter allowed
 
@@ -346,8 +345,7 @@ let make ~xc ~xs vm_info vcpus domain_config uuid final_uuid no_sharept =
         )
     ; max_maptrack_frames=
         ( try
-            int_of_string
-              (List.assoc "max_maptrack_frames" vm_info.platformdata)
+            int_of_string (List.assoc "max_maptrack_frames" vm_info.platformdata)
           with _ -> 1024
         )
     ; arch= domain_config
@@ -407,13 +405,15 @@ let make ~xc ~xs vm_info vcpus domain_config uuid final_uuid no_sharept =
         List.iter
           (fun dir ->
             let ent = sprintf "%s/%s" dom_path dir in
-            t.Xst.mkdirperms ent roperm)
+            t.Xst.mkdirperms ent roperm
+          )
           ["cpu"; "memory"] ;
         let mksubdirs base dirs perms =
           List.iter
             (fun dir ->
               let ent = base ^ "/" ^ dir in
-              t.Xst.mkdirperms ent perms)
+              t.Xst.mkdirperms ent perms
+            )
             dirs
         in
         let device_dirs = ["device"; "device/vbd"; "device/vif"] in
@@ -445,7 +445,8 @@ let make ~xc ~xs vm_info vcpus domain_config uuid final_uuid no_sharept =
           )
           rwperm ;
         (* ...and a few corresponding private nodes for us to use. *)
-        mksubdirs xenops_dom_path device_dirs zeroperm) ;
+        mksubdirs xenops_dom_path device_dirs zeroperm
+    ) ;
     xs.Xs.writev dom_path (filtered_xsdata vm_info.xsdata) ;
     xs.Xs.writev (dom_path ^ "/platform") vm_info.platformdata ;
     xs.Xs.writev (dom_path ^ "/bios-strings") vm_info.bios_strings ;
@@ -565,7 +566,8 @@ let shutdown ~xc ~xs domid req =
          again just in case. *)
       ( try t.Xst.rm path with _ -> ()
       ) ;
-      t.Xst.write path reason)
+      t.Xst.write path reason
+  )
 
 (** If domain is enlightened, signal it to shutdown. If the domain fails to
     respond then throw a Watch.Timeout exception. All other exceptions imply the
@@ -647,7 +649,8 @@ let destroy (task : Xenops_task.task_handle) ~xc ~xs ~qemu_domid ~dm domid =
       log_exn_continue
         ("Reset PCI device " ^ string_of_address pcidev)
         (fun () -> Device.PCI.reset ~xs pcidev)
-        ())
+        ()
+    )
     all_pci_devices ;
   (* PCI specification document says that the Function must complete the FLR
      within 100 ms
@@ -661,8 +664,10 @@ let destroy (task : Xenops_task.task_handle) ~xc ~xs ~qemu_domid ~dm domid =
         ("Deassign PCI device " ^ string_of_address pcidev)
         (fun () ->
           Xenctrl.domain_deassign_device xc domid
-            (pcidev.domain, pcidev.bus, pcidev.dev, pcidev.fn))
-        ())
+            (pcidev.domain, pcidev.bus, pcidev.dev, pcidev.fn)
+        )
+        ()
+    )
     all_pci_devices ;
   (* Now we should kill the domain itself *)
   debug "VM = %s; domid = %d; Domain.destroy calling Xenctrl.domain_destroy"
@@ -685,7 +690,8 @@ let destroy (task : Xenops_task.task_handle) ~xc ~xs ~qemu_domid ~dm domid =
           "VM = %s; domid = %d; Caught exception %s while destroying device %s"
           (Uuid.to_string uuid) domid (Printexc.to_string e)
           (string_of_device device)
-      (* Keep going on a best-effort basis *))
+      (* Keep going on a best-effort basis *)
+    )
     all_devices ;
   (* For each device which has a hotplug entry, perform the cleanup. Even if one
      fails, try to cleanup the rest anyway.*)
@@ -696,8 +702,10 @@ let destroy (task : Xenops_task.task_handle) ~xc ~xs ~qemu_domid ~dm domid =
         ("waiting for hotplug for " ^ string_of_device x)
         (fun () ->
           Hotplug.release task ~xc ~xs x ;
-          released := x :: !released)
-        ())
+          released := x :: !released
+        )
+        ()
+    )
     all_devices ;
   (* If we fail to release a device we leak resources. If we are to tolerate
      this then we need an async cleanup thread. *)
@@ -707,13 +715,13 @@ let destroy (task : Xenops_task.task_handle) ~xc ~xs ~qemu_domid ~dm domid =
   List.iter
     (fun dev ->
       error "VM = %s; domid = %d; Domain.destroy failed to release device: %s"
-        (Uuid.to_string uuid) domid (string_of_device dev))
+        (Uuid.to_string uuid) domid (string_of_device dev)
+    )
     failed_devices ;
   (* Remove our reference to the /vm/<uuid> directory *)
   let vm_path = try Some (xs.Xs.read (dom_path ^ "/vm")) with _ -> None in
   Option.iter
-    (fun vm_path ->
-      log_exn_rm ~xs (vm_path ^ "/domains/" ^ string_of_int domid))
+    (fun vm_path -> log_exn_rm ~xs (vm_path ^ "/domains/" ^ string_of_int domid))
     vm_path ;
   (* Delete /local/domain/<domid>, /xenops/domain/<domid>, /libxl/<domid> and
      all the backend device paths *)
@@ -729,8 +737,10 @@ let destroy (task : Xenops_task.task_handle) ~xc ~xs ~qemu_domid ~dm domid =
       let all_backend_types = try xs.Xs.directory backend_path with _ -> [] in
       List.iter
         (fun ty ->
-          log_exn_rm ~xs (Printf.sprintf "%s/%s/%d" backend_path ty domid))
-        all_backend_types)
+          log_exn_rm ~xs (Printf.sprintf "%s/%s/%d" backend_path ty domid)
+        )
+        all_backend_types
+    )
     ["/backend"; "/xenserver/backend"] ;
   (* If all devices were properly un-hotplugged, then zap the private tree in
      xenstore. If there was some error leave the tree for debugging / async
@@ -779,7 +789,8 @@ let numa_hierarchy =
       let cpu_to_node =
         Xenctrlext.(with_xc cputopoinfo) |> Array.map (fun t -> t.node)
       in
-      NUMA.make ~distances ~cpu_to_node)
+      NUMA.make ~distances ~cpu_to_node
+  )
 
 let numa_mutex = Mutex.create ()
 
@@ -794,7 +805,8 @@ let numa_init () =
     Array.iteri
       (fun i m ->
         let open Xenctrlext in
-        D.debug "NUMA node %d: %Ld/%Ld memory free" i m.memfree m.memsize)
+        D.debug "NUMA node %d: %Ld/%Ld memory free" i m.memfree m.memsize
+      )
       mem
   )
 
@@ -822,7 +834,8 @@ let numa_placement domid ~vcpus ~memory =
               Array.map2 NUMAResource.min_memory (Array.of_list nodes) a
         in
         numa_resources := Some nodea ;
-        Softaffinity.plan host nodea vm)
+        Softaffinity.plan host nodea vm
+    )
   in
   match hint with
   | None ->
@@ -832,7 +845,8 @@ let numa_placement domid ~vcpus ~memory =
       Xenops_helpers.with_xc (fun xc ->
           for i = 0 to vcpus - 1 do
             Xenctrlext.vcpu_setaffinity_soft xc domid i cpua
-          done)
+          done
+      )
 
 let build_pre ~xc ~xs ~vcpus ~memory ~has_hard_affinity domid =
   let open Memory in
@@ -841,13 +855,11 @@ let build_pre ~xc ~xs ~vcpus ~memory ~has_hard_affinity domid =
     (Uuid.to_string uuid) domid memory.required_host_free_mib ;
   (* CA-39743: Wait, if necessary, for the Xen scrubber to catch up. *)
   if
-    not
-      (wait_xen_free_mem ~xc (Memory.kib_of_mib memory.required_host_free_mib))
+    not (wait_xen_free_mem ~xc (Memory.kib_of_mib memory.required_host_free_mib))
   then (
     error "VM = %s; domid = %d; Failed waiting for Xen to free %Ld MiB"
       (Uuid.to_string uuid) domid memory.required_host_free_mib ;
-    raise
-      (Not_enough_memory (Memory.bytes_of_mib memory.required_host_free_mib))
+    raise (Not_enough_memory (Memory.bytes_of_mib memory.required_host_free_mib))
   ) ;
   let shadow_mib = Int64.to_int memory.shadow_mib in
   let dom_path = xs.Xs.getdomainpath domid in
@@ -871,17 +883,22 @@ let build_pre ~xc ~xs ~vcpus ~memory ~has_hard_affinity domid =
   maybe
     (fun mode ->
       log_reraise (Printf.sprintf "domain_set_timer_mode %d" mode) (fun () ->
-          Xenctrlext.domain_set_timer_mode xc domid mode))
+          Xenctrlext.domain_set_timer_mode xc domid mode
+      )
+    )
     timer_mode ;
   log_reraise (Printf.sprintf "domain_max_vcpus %d" vcpus) (fun () ->
-      Xenctrl.domain_max_vcpus xc domid vcpus) ;
+      Xenctrl.domain_max_vcpus xc domid vcpus
+  ) ;
   ( if not Xenctrl.((domain_getinfo xc domid).hvm_guest) then
       let kib = Memory.kib_of_mib memory.xen_max_mib in
       log_reraise (Printf.sprintf "domain_set_memmap_limit %Ld KiB" kib)
-        (fun () -> Xenctrl.domain_set_memmap_limit xc domid kib)
+        (fun () -> Xenctrl.domain_set_memmap_limit xc domid kib
+      )
   ) ;
   log_reraise (Printf.sprintf "shadow_allocation_set %d MiB" shadow_mib)
-    (fun () -> Xenctrl.shadow_allocation_set xc domid shadow_mib) ;
+    (fun () -> Xenctrl.shadow_allocation_set xc domid shadow_mib
+  ) ;
   if !Xenopsd.numa_placement then
     log_reraise (Printf.sprintf "NUMA placement") (fun () ->
         if has_hard_affinity then
@@ -894,7 +911,8 @@ let build_pre ~xc ~xs ~vcpus ~memory ~has_hard_affinity domid =
           if !Xenopsd.numa_placement_strict then
             do_numa_placement ()
           else
-            Xenops_utils.best_effort "NUMA placement" do_numa_placement) ;
+            Xenops_utils.best_effort "NUMA placement" do_numa_placement
+    ) ;
   create_channels ~xc uuid domid
 
 let resume_post ~xc ~xs domid =
@@ -934,7 +952,8 @@ let xenguest_args_hvm ~domid ~store_port ~store_domid ~console_port
      | Xenops_interface.Vgpu.{implementation= Nvidia _} :: _ ->
          ["-vgpu"]
      | _ ->
-         [])
+         []
+    )
   @ xenguest_args_base ~domid ~store_port ~store_domid ~console_port
       ~console_domid ~memory
 
@@ -962,7 +981,8 @@ let xenguest_args_pvh ~domid ~store_port ~store_domid ~console_port
   let module_args =
     List.map
       (fun (m, c) ->
-        "-module" :: m :: (match c with Some x -> ["-cmdline"; x] | None -> []))
+        "-module" :: m :: (match c with Some x -> ["-cmdline"; x] | None -> [])
+      )
       modules
     |> List.flatten
   in
@@ -985,7 +1005,8 @@ let xenguest_args_pvh ~domid ~store_port ~store_domid ~console_port
 let xenguest task xenguest_path domid uuid args =
   let line =
     XenguestHelper.(
-      with_connection task xenguest_path domid args [] receive_success)
+      with_connection task xenguest_path domid args [] receive_success
+    )
   in
   match Astring.String.cuts ~sep:" " line with
   | store_mfn :: console_mfn :: _ ->
@@ -1096,7 +1117,8 @@ let build (task : Xenops_task.task_handle) ~xc ~xs ~store_domid ~console_domid
         , console_mfn
         , console_port
         , [("rtc/timeoffset", timeoffset)]
-        , `hvm )
+        , `hvm
+        )
     | BuildPV pvinfo ->
         let shadow_multiplier = Memory.Linux.shadow_multiplier_default in
         let video_mib = 0 in
@@ -1146,7 +1168,8 @@ let build (task : Xenops_task.task_handle) ~xc ~xs ~store_domid ~console_domid
         , console_mfn
         , console_port
         , [("rtc/timeoffset", timeoffset)]
-        , `pvh )
+        , `pvh
+        )
   in
   let local_stuff = console_keys console_port console_mfn in
   build_post ~xc ~xs ~vcpus ~target_mib ~static_max_mib domid domain_type
@@ -1242,7 +1265,8 @@ let consume_qemu_record fd limit domid uuid =
         error "VM = %s; domid = %d; qemu save file was truncated"
           (Uuid.to_string uuid) domid ;
         raise Domain_restore_truncated_hvmstate
-      ))
+      )
+    )
     (fun () -> Unix.close fd2)
 
 let restore_common (task : Xenops_task.task_handle) ~xc ~xs
@@ -1262,7 +1286,9 @@ let restore_common (task : Xenops_task.task_handle) ~xc ~xs
           with_conversion_script task "Emu_manager" hvm main_fd (fun pipe_r ->
               with_emu_manager_restore task ~domain_type ~dm ~store_port
                 ~console_port ~extras manager_path domid uuid pipe_r vgpu_fd
-                (fun cnx -> restore_libxc_record cnx domid uuid))
+                (fun cnx -> restore_libxc_record cnx domid uuid
+              )
+          )
         with
         | `Ok (s, c) ->
             (s, c)
@@ -1315,10 +1341,11 @@ let restore_common (task : Xenops_task.task_handle) ~xc ~xs
                request to emu-manager. *)
             let wakeup = Event.new_channel () in
             Mutex.execute thread_requests_m (fun () ->
-                thread_requests := (emu, wakeup) :: !thread_requests) ;
+                thread_requests := (emu, wakeup) :: !thread_requests
+            ) ;
             wrap (fun () ->
-                Mutex.execute emu_manager_send_m (fun () ->
-                    send_restore cnx emu))
+                Mutex.execute emu_manager_send_m (fun () -> send_restore cnx emu)
+            )
             >>= fun () ->
             debug "Sent restore:%s to emu-manager. Waiting for result..."
               (string_of_emu emu) ;
@@ -1326,7 +1353,8 @@ let restore_common (task : Xenops_task.task_handle) ~xc ~xs
                received. *)
             Event.receive wakeup |> Event.sync ;
             Mutex.execute thread_requests_m (fun () ->
-                thread_requests := List.remove_assoc emu !thread_requests) ;
+                thread_requests := List.remove_assoc emu !thread_requests
+            ) ;
             return ()
           in
           let rec process_header fd res =
@@ -1411,7 +1439,8 @@ let restore_common (task : Xenops_task.task_handle) ~xc ~xs
                         return (Some (store, console))
                     | _ ->
                         acc
-                  ))
+                  )
+                )
               (return None) results
           in
           let cancel_on_error result =
@@ -1444,8 +1473,10 @@ let restore_common (task : Xenops_task.task_handle) ~xc ~xs
                       wrap_exn (fun () -> process_header fd (return ()))
                       |> cancel_on_error
                       |> Event.send ch
-                      |> Event.sync)
-                    ())
+                      |> Event.sync
+                    )
+                    ()
+                )
                 ()
             in
             (th, ch)
@@ -1457,7 +1488,8 @@ let restore_common (task : Xenops_task.task_handle) ~xc ~xs
             List.map
               (fun (th, ch) _ ->
                 let status = Event.receive ch |> Event.sync in
-                Thread.join th ; status)
+                Thread.join th ; status
+              )
               threads_and_channels
             |> fun statuses ->
             fold (fun x -> x) statuses () >>= fun () ->
@@ -1485,7 +1517,8 @@ let restore_common (task : Xenops_task.task_handle) ~xc ~xs
           | `Ok None ->
               failwith "Well formed, but useless stream"
           | `Error e ->
-              raise e)
+              raise e
+      )
   | `Error e ->
       error "VM = %s; domid = %d; Error reading save signature: %s"
         (Uuid.to_string uuid) domid e ;
@@ -1650,7 +1683,8 @@ let suspend_emu_manager ~(task : Xenops_task.task_handle) ~xc ~xs ~domain_type
               `Error
                 (Emu_manager_failure
                    "Received prepare:vgpu from emu-manager, but there is no \
-                    vGPU fd")
+                    vGPU fd"
+                )
         )
         | Result x ->
             debug "VM = %s; domid = %d; emu-manager completed successfully"
@@ -1661,13 +1695,15 @@ let suspend_emu_manager ~(task : Xenops_task.task_handle) ~xc ~xs ~domain_type
               (Uuid.to_string uuid) domid x ;
             `Error
               (Emu_manager_failure
-                 (Printf.sprintf "Received error from emu-manager: %s" x))
+                 (Printf.sprintf "Received error from emu-manager: %s" x)
+              )
         | _ ->
             error "VM = %s; domid = %d; unexpected message from emu-manager"
               (Uuid.to_string uuid) domid ;
             `Error Emu_manager_protocol_failure
       in
-      wait_for_message ())
+      wait_for_message ()
+  )
 
 let write_qemu_record domid uuid fd =
   let file = sprintf qemu_save_path domid in
@@ -1683,7 +1719,8 @@ let write_qemu_record domid uuid fd =
         (Uuid.to_string uuid) domid size file ;
       if Unixext.copy_file ~limit:size fd2 fd <> size then
         failwith "Failed to write whole qemu-dm state file" ;
-      return ())
+      return ()
+    )
     (fun () -> Unix.unlink file ; Unix.close fd2)
 
 let write_varstored_record task ~xs domid main_fd =
@@ -1798,7 +1835,8 @@ let vcpu_affinity_set ~xc domid vcpu cpumap =
   debug "VM = %s; domid = %d; vcpu_affinity_set %d <- %s" (Uuid.to_string uuid)
     domid vcpu
     (String.concat ""
-       (List.map (fun b -> if b then "1" else "0") (Array.to_list cpumap))) ;
+       (List.map (fun b -> if b then "1" else "0") (Array.to_list cpumap))
+    ) ;
   Xenctrl.vcpu_affinity_set xc domid vcpu cpumap
 
 let vcpu_affinity_get ~xc domid vcpu =
@@ -1876,7 +1914,8 @@ let set_xsdata ~xs domid xsdata =
   let dom_path = Printf.sprintf "/local/domain/%d" domid in
   Xs.transaction xs (fun t ->
       List.iter (fun x -> t.Xst.rm (dom_path ^ "/" ^ x)) allowed_xsdata_prefixes ;
-      t.Xst.writev dom_path (filtered_xsdata xsdata))
+      t.Xst.writev dom_path (filtered_xsdata xsdata)
+  )
 
 type node = {contents: string; subtrees: (string * node) list}
 
@@ -1940,6 +1979,7 @@ let move_xstree ~xs domid olduuid newuuid =
           | name :: path' ->
               fixup false (List.rev path') (name, tree)
           | _ ->
-              failwith "Internal error: mv_tree called on empty path")
+              failwith "Internal error: mv_tree called on empty path"
+    )
   in
   List.iter mv_tree search_paths
diff --git a/xc/domain_sethandle.ml b/xc/domain_sethandle.ml
index e601beb5a..5dfefc402 100644
--- a/xc/domain_sethandle.ml
+++ b/xc/domain_sethandle.ml
@@ -25,11 +25,14 @@ let _ =
        [
          ( "-domid"
          , Arg.Int (fun i -> domid := Some i)
-         , " the domain id whose handle we will change" )
+         , " the domain id whose handle we will change"
+         )
        ; ( "-handle"
          , Arg.String (fun i -> handle := Some i)
-         , " the new handle value" )
-       ])
+         , " the new handle value"
+         )
+       ]
+    )
     (fun x -> Printf.printf "Warning, ignoring unknown argument: %s" x)
     "Set a domain's handle" ;
   match (!domid, !handle) with
diff --git a/xc/emu_manager.ml b/xc/emu_manager.ml
index 7c9b54a77..369de03c7 100644
--- a/xc/emu_manager.ml
+++ b/xc/emu_manager.ml
@@ -79,7 +79,8 @@ let connect path domid (args : string list)
   , Unix.out_channel_of_descr server_to_slave_w
   , slave_to_server_r
   , server_to_slave_w
-  , pid )
+  , pid
+  )
 
 (** Wait for the (hopefully dead) child process *)
 let disconnect (_, _, r, w, pid) =
@@ -208,7 +209,8 @@ let non_debug_receive ?debug_callback cnx =
         error "Memory F %Ld KiB S %Ld KiB T %Ld MiB"
           (p.free_pages |> of_nativeint |> kib_of_pages)
           (p.scrub_pages |> of_nativeint |> kib_of_pages)
-          (p.total_pages |> of_nativeint |> mib_of_pages_free))
+          (p.total_pages |> of_nativeint |> mib_of_pages_free)
+    )
   in
   try
     match non_debug_receive ?debug_callback cnx with
@@ -239,5 +241,7 @@ let with_connection (task : Xenops_task.task_handle) path domid
             if !cancelled then
               Xenops_task.raise_cancelled task
             else
-              raise e))
+              raise e
+      )
+    )
     (fun () -> disconnect t)
diff --git a/xc/hotplug.ml b/xc/hotplug.ml
index 21621a42b..3dffd4966 100644
--- a/xc/hotplug.ml
+++ b/xc/hotplug.ml
@@ -78,7 +78,8 @@ let path_written_by_hotplug_scripts (x : device) =
   | k ->
       failwith
         (Printf.sprintf "No xenstore interface for this kind of device: %s"
-           (string_of_kind k))
+           (string_of_kind k)
+        )
 
 let error_path_written_by_hotplug_scripts (x : device) =
   sprintf "/local/domain/%d/backend/%s/%d/%d/hotplug-error" x.backend.domid
@@ -176,7 +177,8 @@ let wait_for_plug (task : Xenops_task.task_handle) ~xs (x : device) =
           (* If an error node exists, return the error *)
           raise (Hotplug_error (xs.Xs.read error_path))
         with Xs_protocol.Enoent _ -> ()
-        (* common case *)) ;
+        (* common case *)
+    ) ;
     debug "Synchronised ok with hotplug script: %s" (string_of_device x)
   with Watch.Timeout _ -> raise (Device_timeout x)
 
@@ -190,7 +192,8 @@ let wait_for_unplug (task : Xenops_task.task_handle) ~xs (x : device) =
             [Watch.map (fun _ -> ()) (Watch.key_to_disappear path)]
             [] task ~xs ~timeout:!Xenopsd.hotplug_timeout ()
         in
-        ()) ;
+        ()
+    ) ;
     debug "Synchronised ok with hotplug script: %s" (string_of_device x)
   with Watch.Timeout _ -> raise (Device_timeout x)
 
@@ -202,12 +205,10 @@ let wait_for_frontend_plug (task : Xenops_task.task_handle) ~xs (x : device) =
       Watch.value_to_appear (frontend_status_node x) |> Watch.map (fun _ -> ())
     in
     let tapdisk_error_watch =
-      Watch.value_to_appear (tapdisk_error_node ~xs x)
-      |> Watch.map (fun _ -> ())
+      Watch.value_to_appear (tapdisk_error_node ~xs x) |> Watch.map (fun _ -> ())
     in
     let blkback_error_watch =
-      Watch.value_to_appear (blkback_error_node ~xs x)
-      |> Watch.map (fun _ -> ())
+      Watch.value_to_appear (blkback_error_node ~xs x) |> Watch.map (fun _ -> ())
     in
     let cancel = Device x in
     Stats.time_this "udev frontend add event" (fun () ->
@@ -228,7 +229,8 @@ let wait_for_frontend_plug (task : Xenops_task.task_handle) ~xs (x : device) =
           let e = tapdisk_error ^ "/" ^ blkback_error in
           error "Failed waiting for frontend device %s: %s" (string_of_device x)
             e ;
-          raise (Frontend_device_error e))
+          raise (Frontend_device_error e)
+    )
   with Watch.Timeout _ ->
     error "Timed out waiting for the frontend udev event to fire on device: %s"
       (string_of_device x) ;
@@ -244,9 +246,9 @@ let wait_for_frontend_unplug (task : Xenops_task.task_handle) ~xs (x : device) =
             [Watch.map (fun _ -> ()) (Watch.key_to_disappear path)]
             [] task ~xs ~timeout:!Xenopsd.hotplug_timeout ()
         in
-        ()) ;
-    debug "Synchronised ok with frontend hotplug script: %s"
-      (string_of_device x)
+        ()
+    ) ;
+    debug "Synchronised ok with frontend hotplug script: %s" (string_of_device x)
   with Watch.Timeout _ -> raise (Frontend_device_timeout x)
 
 (* If we're running the hotplug scripts ourselves then we must wait for the VIF
@@ -266,7 +268,8 @@ let wait_for_connect (task : Xenops_task.task_handle) ~xs (x : device) =
             ]
             [] task ~xs ~timeout:!Xenopsd.hotplug_timeout ()
         in
-        ()) ;
+        ()
+    ) ;
     debug "Synchronised ok with device backend: %s" (string_of_device x)
   with Watch.Timeout _ -> raise (Device_timeout x)
 
@@ -292,7 +295,8 @@ let release (task : Xenops_task.task_handle) ~xc ~xs (x : device) =
   Xs.transaction xs (fun t ->
       t.Xst.rm hotplug_path ;
       Option.iter t.Xst.rm private_data_path ;
-      t.Xst.rm extra_xenserver_path)
+      t.Xst.rm extra_xenserver_path
+  )
 
 let run_hotplug_script device args =
   let kind = string_of_kind device.backend.kind in
diff --git a/xc/list_domains.ml b/xc/list_domains.ml
index f34bf6630..2edd2e8fa 100644
--- a/xc/list_domains.ml
+++ b/xc/list_domains.ml
@@ -105,7 +105,8 @@ let select table keys =
     (fun key ->
       if not (Hashtbl.mem table key) then
         failwith (Printf.sprintf "Failed to find key: %s" key) ;
-      Hashtbl.find table key)
+      Hashtbl.find table key
+    )
     keys
 
 let columns () =
@@ -160,16 +161,20 @@ let _ =
          , Arg.Unit
              (fun () ->
                memory := true ;
-               all_the_rest := true)
-         , " show all available stats (needs a wide window!)" )
+               all_the_rest := true
+             )
+         , " show all available stats (needs a wide window!)"
+         )
        ; ("-bytes", Arg.Set bytes, " use bytes for memory values")
        ; ( "-domid"
          , Arg.Int (fun i -> domid := Some i)
-         , " show only a particular domain" )
+         , " show only a particular domain"
+         )
        ; ("-memory", Arg.Set memory, " show memory statistics")
        ; ("-minimal", Arg.Set minimal, " show only domain UUID")
        ; ("-pages", Arg.Set pages, " use pages for memory values")
-       ])
+       ]
+    )
     (fun x -> Printf.printf "Warning, ignoring unknown argument: %s" x)
     "List domains" ;
   let cols = columns () in
diff --git a/xc/memory_breakdown.ml b/xc/memory_breakdown.ml
index 8b66db068..8cce64000 100644
--- a/xc/memory_breakdown.ml
+++ b/xc/memory_breakdown.ml
@@ -37,10 +37,12 @@ let cli_arguments_named =
   [
     ( "-pad"
     , Arg.Set_string cli_argument_existing_file_to_pad
-    , "Pads an existing data file" )
+    , "Pads an existing data file"
+    )
   ; ( "-period"
     , Arg.Set_float cli_argument_delay_period_seconds
-    , "Delay between updates" )
+    , "Delay between updates"
+    )
   ]
 
 let cli_arguments_extra x = Printf.fprintf stderr "Ignoring argument: %s" x
@@ -162,8 +164,7 @@ let guest_balloonable xc xs g =
     (xs_exists xs (supports_ballooning_path (guest_domain_id xc xs g)))
 
 let guest_uncooperative xc xs g =
-  string_of_bool
-    (xs_exists xs (is_uncooperative_path (guest_domain_id xc xs g)))
+  string_of_bool (xs_exists xs (is_uncooperative_path (guest_domain_id xc xs g)))
 
 let guest_shadow_bytes xc xs g =
   Int64.to_string
@@ -221,7 +222,8 @@ let print_memory_field_values xc xs =
   let guests =
     List.sort
       (fun g1 g2 ->
-        compare_guests control_domain_id g1.Xenctrl.handle g2.Xenctrl.handle)
+        compare_guests control_domain_id g1.Xenctrl.handle g2.Xenctrl.handle
+      )
       (Xenctrl.domain_getinfolist xc 0)
   in
   let print_host_info field =
@@ -239,8 +241,7 @@ let print_memory_field_values xc xs =
   flush stdout
 
 (** Sleeps for the given time period in seconds. *)
-let sleep time_period_seconds =
-  ignore (Unix.select [] [] [] time_period_seconds)
+let sleep time_period_seconds = ignore (Unix.select [] [] [] time_period_seconds)
 
 (** Prints a header line of memory field names, and then periodically prints a
     line of memory field values. *)
@@ -250,7 +251,8 @@ let record_new_data () =
       while true do
         print_memory_field_values xc xs ;
         sleep !cli_argument_delay_period_seconds
-      done)
+      done
+  )
 
 (** {2 Functions that transform sparse data files into padded data files} *)
 
@@ -291,7 +293,8 @@ let pad_value_list guest_ids_all guest_ids values default_value =
            "Expected: guest_ids subset of guest_ids_all"
          else
            "Unknown failure"
-         ))
+         )
+      )
   in
   let rec pad ids_all ids vs vs_padded =
     match (ids_all, ids, vs) with
@@ -313,13 +316,16 @@ let pad_value_string guest_ids_all guest_ids (value_string, default_value) =
     (String.concat " "
        (pad_value_list guest_ids_all guest_ids
           (Astring.String.cuts ~sep:" " value_string)
-          default_value))
+          default_value
+       )
+    )
 
 let pad_value_strings guest_ids_all guest_ids value_strings =
   String.concat " "
     (List.map
        (pad_value_string guest_ids_all guest_ids)
-       (List.combine value_strings (List.tl guest_field_defaults)))
+       (List.combine value_strings (List.tl guest_field_defaults))
+    )
 
 let pad_data_line guest_ids_all line =
   match sections_of_line line with
@@ -327,7 +333,8 @@ let pad_data_line guest_ids_all line =
       Printf.sprintf "| %s | %s" host_string
         (pad_value_strings guest_ids_all
            (guest_ids_of_string guest_ids_string)
-           value_strings)
+           value_strings
+        )
   | _ ->
       line
 
@@ -351,8 +358,12 @@ let print_padded_header_line guest_count =
             String.concat " "
               (List.map
                  (Printf.sprintf "%s_%i" name)
-                 (range 0 (guest_count - 1))))
-          (List.tl guest_field_names)))
+                 (range 0 (guest_count - 1))
+              )
+          )
+          (List.tl guest_field_names)
+       )
+    )
 
 let pad_existing_data () =
   let guest_ids_all = guest_ids_of_file !cli_argument_existing_file_to_pad in
diff --git a/xc/memory_summary.ml b/xc/memory_summary.ml
index a0526a610..ecd92f98f 100644
--- a/xc/memory_summary.ml
+++ b/xc/memory_summary.ml
@@ -47,7 +47,8 @@ let _ =
     let domains =
       List.map
         (fun di ->
-          (di.Xenctrl.domid, Int64.of_nativeint di.Xenctrl.total_memory_pages))
+          (di.Xenctrl.domid, Int64.of_nativeint di.Xenctrl.total_memory_pages)
+        )
         domains
     in
     if not !hash then (
@@ -81,7 +82,8 @@ let _ =
       List.iter
         (fun (domid, total) ->
           Printf.printf "%10s %s (%Ld MiB)\n" (string_of_int domid)
-            (hashes total) (total /* 256L))
+            (hashes total) (total /* 256L)
+        )
         domains
     )
   done
diff --git a/xc/readln.ml b/xc/readln.ml
index ca3e5b199..dfdc0fab6 100644
--- a/xc/readln.ml
+++ b/xc/readln.ml
@@ -20,7 +20,8 @@ let read fd =
       else
         Error
           (Printf.sprintf "Unconsumed data at EOF: '%s'"
-             (Bytes.to_string pending))
+             (Bytes.to_string pending)
+          )
   | n ->
       let data = Bytes.sub buffer 0 n in
       let inpt = try Hashtbl.find input fd with Not_found -> Bytes.empty in
diff --git a/xc/stats.ml b/xc/stats.ml
index 2c602cf12..e75fe8fd6 100644
--- a/xc/stats.ml
+++ b/xc/stats.ml
@@ -80,7 +80,8 @@ let sample (name : string) (x : float) : unit =
           Normal_population.empty
       in
       let p' = Normal_population.sample p x' in
-      Hashtbl.replace timings name p')
+      Hashtbl.replace timings name p'
+  )
 
 (** Helper function to time a specific thing *)
 let time_this (name : string) f =
@@ -91,11 +92,13 @@ let time_this (name : string) f =
         sample name (end_time -. start_time)
       with e ->
         warn "Ignoring exception %s while timing: %s" (Printexc.to_string e)
-          name)
+          name
+  )
 
 let summarise () =
   Mutex.execute timings_m (fun () ->
-      Hashtbl.fold (fun k v acc -> (k, string_of v) :: acc) timings [])
+      Hashtbl.fold (fun k v acc -> (k, string_of v) :: acc) timings []
+  )
 
 (*****************************)
 (* Database stats            *)
@@ -151,7 +154,8 @@ let log_db_call task_opt dbcall ty =
               :: (try Hashtbl.find dbstats_task task with _ -> [])
               )
         | None ->
-            ())
+            ()
+    )
 
 let summarise_db_calls () =
   let string_of_ty = function
@@ -181,8 +185,10 @@ let summarise_db_calls () =
             ( k
             , List.map
                 (fun (dbcall, ty) -> (string_of_ty ty, dbcall))
-                (List.rev v) )
-            :: acc)
+                (List.rev v)
+            )
+            :: acc
+          )
           dbstats_task []
       , List.sort
           (fun (a, _) (b, _) -> compare a b)
@@ -191,6 +197,11 @@ let summarise_db_calls () =
                ( k
                , List.map
                    (fun (dbcall, ty) -> (string_of_ty ty, dbcall))
-                   (List.rev v) )
-               :: acc)
-             dbstats_threads []) ))
+                   (List.rev v)
+               )
+               :: acc
+             )
+             dbstats_threads []
+          )
+      )
+  )
diff --git a/xc/xc_resources.ml b/xc/xc_resources.ml
index 93b8b8098..a5e9761bf 100644
--- a/xc/xc_resources.ml
+++ b/xc/xc_resources.ml
@@ -64,11 +64,13 @@ let essentials =
   ; ( X_OK
     , "setup-vif-rules"
     , setup_vif_rules
-    , "path to the setup-vif-rules script" )
+    , "path to the setup-vif-rules script"
+    )
   ; ( X_OK
     , "setup-pvs-proxy-rules"
     , setup_pvs_proxy_rules
-    , "path to the setup-pvs-proxy-rules script" )
+    , "path to the setup-pvs-proxy-rules script"
+    )
   ]
   @ Resources.network_configuration
 
@@ -77,7 +79,8 @@ let nonessentials =
     ( X_OK
     , "pci-flr-script"
     , pci_flr_script
-    , "path to the PCI function-level reset script" )
+    , "path to the PCI function-level reset script"
+    )
   ; (X_OK, "alternatives", alternatives, "path to the alternative xenguests")
   ; (X_OK, "vgpu", vgpu, "path to the vgpu binary")
   ; (X_OK, "varstored", varstored, "path to the varstored binary")
@@ -86,7 +89,8 @@ let nonessentials =
   ; ( X_OK
     , "igmp-query-injector-script"
     , igmp_query_injector_script
-    , "path to the igmp query injector script" )
+    , "path to the igmp query injector script"
+    )
   ]
   @ Resources.hvm_guests
   @ Resources.pv_guests
diff --git a/xc/xenbus_utils.ml b/xc/xenbus_utils.ml
index 6340ca9c6..ccdfa1c63 100644
--- a/xc/xenbus_utils.ml
+++ b/xc/xenbus_utils.ml
@@ -93,6 +93,7 @@ let device_frontend device =
     ; other= NONE
     ; acl= [(device.backend.domid, READ)]
     }
+  
 
 let device_backend device =
   Xs_protocol.ACL.
@@ -101,6 +102,7 @@ let device_backend device =
     ; other= NONE
     ; acl= [(device.frontend.domid, READ)]
     }
+  
 
 let hotplug device =
   Xs_protocol.ACL.{owner= device.backend.domid; other= NONE; acl= []}
diff --git a/xc/xenguestHelper.ml b/xc/xenguestHelper.ml
index c0eaf3f6d..f146d686a 100644
--- a/xc/xenguestHelper.ml
+++ b/xc/xenguestHelper.ml
@@ -82,7 +82,8 @@ let connect path domid (args : string list)
   , Unix.out_channel_of_descr server_to_slave_w
   , slave_to_server_r
   , server_to_slave_w
-  , pid )
+  , pid
+  )
 
 (** Wait for the (hopefully dead) child process *)
 let disconnect (_, _, r, w, pid) =
@@ -121,7 +122,9 @@ let with_connection (task : Xenops_task.task_handle) path domid
             if !cancelled then
               Xenops_task.raise_cancelled task
             else
-              raise e))
+              raise e
+      )
+    )
     (fun () -> disconnect t)
 
 (** immediately write a command to the control channel *)
@@ -206,7 +209,8 @@ let non_debug_receive ?debug_callback cnx =
         error "Memory F %Ld KiB S %Ld KiB T %Ld MiB"
           (p.free_pages |> of_nativeint |> kib_of_pages)
           (p.scrub_pages |> of_nativeint |> kib_of_pages)
-          (p.total_pages |> of_nativeint |> mib_of_pages_free))
+          (p.total_pages |> of_nativeint |> mib_of_pages_free)
+    )
   in
   try
     match non_debug_receive ?debug_callback cnx with
@@ -233,7 +237,8 @@ let receive_success ?(debug_callback = fun s -> debug "%s" s) cnx =
       | "hvm_build_params" :: code :: msg ->
           raise
             (Domain_builder_error
-               ("hvm_build_params", int_of_string code, pp msg))
+               ("hvm_build_params", int_of_string code, pp msg)
+            )
       | "hvm_build_mem" :: code :: msg ->
           raise
             (Domain_builder_error ("hvm_build_mem", int_of_string code, pp msg))
diff --git a/xc/xenops_helpers.ml b/xc/xenops_helpers.ml
index 193ec9bb9..1039bb4ac 100644
--- a/xc/xenops_helpers.ml
+++ b/xc/xenops_helpers.ml
@@ -22,7 +22,8 @@ let with_xc_and_xs f = Xenctrl.with_intf (fun xc -> with_xs (fun xs -> f xc xs))
 
 let with_xc_and_xs_final f cf =
   with_xc_and_xs (fun xc xs ->
-      Xapi_stdext_pervasives.Pervasiveext.finally (fun () -> f xc xs) cf)
+      Xapi_stdext_pervasives.Pervasiveext.finally (fun () -> f xc xs) cf
+  )
 
 exception Domain_not_found
 
diff --git a/xc/xenops_server_xen.ml b/xc/xenops_server_xen.ml
index 4e054e760..6d721708a 100644
--- a/xc/xenops_server_xen.ml
+++ b/xc/xenops_server_xen.ml
@@ -70,7 +70,8 @@ let choose_qemu_dm x =
     if List.mem_assoc _device_model x then
       Profile.of_string (List.assoc _device_model x)
     else
-      Profile.fallback)
+      Profile.fallback
+  )
 
 (* We allow xenguest to be overriden via a platform flag *)
 let choose_xenguest x = choose_alternative _xenguest !Xc_resources.xenguest x
@@ -208,6 +209,7 @@ module DB = struct
               x
           )
       }
+    
 
   let revision_of vm persistent = persistent |> revise_profile_qemu_trad vm
 end
@@ -258,7 +260,10 @@ let di_of_uuid ~xc ~xs uuid =
         (Xenopsd_error
            (Internal_error
               (Printf.sprintf "More than one domain with uuid (%s): %s" uuid'
-                 domid_list)))
+                 domid_list
+              )
+           )
+        )
 
 let domid_of_uuid ~xc ~xs uuid =
   (* We don't fully control the domain lifecycle because libxenguest will
@@ -280,7 +285,10 @@ let domid_of_uuid ~xc ~xs uuid =
           (Xenopsd_error
              (Internal_error
                 (Printf.sprintf "More than one domain with uuid (%s): %s"
-                   (Uuidm.to_string uuid) domid_list)))
+                   (Uuidm.to_string uuid) domid_list
+                )
+             )
+          )
   with e ->
     error "Failed to read %s: has this domain already been cleaned up?" dir ;
     None
@@ -312,7 +320,9 @@ let params_of_backend backend =
                 ^ (Storage_interface.(rpc_of backend) backend
                   |> Jsonrpc.to_string
                   )
-                )))
+                )
+             )
+          )
   in
   let params, extra_keys =
     match (blockdevs, files, nbds, xendisks) with
@@ -328,7 +338,9 @@ let params_of_backend backend =
                 ^ (Storage_interface.(rpc_of backend) backend
                   |> Jsonrpc.to_string
                   )
-                )))
+                )
+             )
+          )
   in
   (params, xenstore_data, extra_keys)
 
@@ -359,7 +371,9 @@ let create_vbd_frontend ~xc ~xs task frontend_domid vdi =
                   ^ (Storage_interface.(rpc_of backend) vdi.attach_info
                     |> Jsonrpc.to_string
                     )
-                  )))
+                  )
+               )
+            )
     )
   | Some backend_domid ->
       let params, xenstore_data, extra_keys =
@@ -386,7 +400,8 @@ let create_vbd_frontend ~xc ~xs task frontend_domid vdi =
       in
       let device =
         Xenops_task.with_subtask task "Vbd.add" (fun () ->
-            Device.Vbd.add task ~xc ~xs ~hvm:false t frontend_domid)
+            Device.Vbd.add task ~xc ~xs ~hvm:false t frontend_domid
+        )
       in
       Device device
 
@@ -400,7 +415,8 @@ let destroy_vbd_frontend ~xc ~xs task disk =
              this can be safely ignored because we're controlling the frontend
              and all users of it. *)
           Device.Vbd.clean_shutdown_async ~xs device ;
-          Device.Vbd.clean_shutdown_wait task ~xs ~ignore_transients:true device)
+          Device.Vbd.clean_shutdown_wait task ~xs ~ignore_transients:true device
+      )
 
 module Storage = struct
   open Storage
@@ -422,9 +438,12 @@ module Storage = struct
     let backend =
       Xenops_task.with_subtask task
         (Printf.sprintf "Policy.get_backend_vm %s %s %s" vm (Sr.string_of sr)
-           (Vdi.string_of vdi))
+           (Vdi.string_of vdi)
+        )
         (transform_exception (fun () ->
-             Client.Policy.get_backend_vm "attach_and_activate" vm sr vdi))
+             Client.Policy.get_backend_vm "attach_and_activate" vm sr vdi
+         )
+        )
     in
     match domid_of_uuid ~xc ~xs (uuid_of_string backend) with
     | None ->
@@ -483,7 +502,8 @@ module NbdClient = struct
         try stop_nbd_client ~nbd_device
         with e ->
           warn "ignoring exception while disconnecting nbd-client from %s: %s"
-            nbd_device (Printexc.to_string e))
+            nbd_device (Printexc.to_string e)
+      )
 
   let with_nbd_device ~nbd =
     let unix_socket_path, export_name = Storage_interface.parse_nbd_uri nbd in
@@ -521,8 +541,10 @@ let with_disk ~xc ~xs task disk write f =
               | Nbd nbd ->
                   debug "with_disk: using nbd-client for %s"
                     (Storage_interface.(rpc_of nbd) nbd |> Jsonrpc.to_string) ;
-                  NbdClient.with_nbd_device ~nbd f)
-            (fun () -> destroy_vbd_frontend ~xc ~xs task device))
+                  NbdClient.with_nbd_device ~nbd f
+            )
+            (fun () -> destroy_vbd_frontend ~xc ~xs task device)
+        )
         (fun () -> dp_destroy task dp)
 
 module Mem = struct
@@ -542,7 +564,8 @@ module Mem = struct
             let vms =
               List.map (get_uuid ~xc) domids |> List.map Uuidm.to_string
             in
-            raise (Xenopsd_error (Vms_failed_to_cooperate vms)))
+            raise (Xenopsd_error (Vms_failed_to_cooperate vms))
+        )
     | Unix.Unix_error (Unix.ECONNREFUSED, "connect", _) ->
         info
           "ECONNREFUSED talking to squeezed: assuming it has been switched off" ;
@@ -569,7 +592,8 @@ module Mem = struct
         | None ->
             let s = do_login dbg in
             cached_session_id := Some s ;
-            s)
+            s
+    )
 
   (** If we fail to allocate because VMs either failed to co-operate or because
       they are still booting and haven't written their feature-balloon flag then
@@ -612,12 +636,14 @@ module Mem = struct
               in
               debug "Memory reservation size = %Ld (reservation_id = %s)" kib
                 reservation_id ;
-              (reservation_id, kib))
+              (reservation_id, kib)
+          )
         in
         (* Post condition: *)
         assert (reserved_memory >= min) ;
         assert (reserved_memory <= max) ;
-        (reserved_memory, (reservation_id, reserved_memory)))
+        (reserved_memory, (reservation_id, reserved_memory))
+      )
       (get_session_id dbg)
 
   let reserve_memory_range dbg min max : (int64 * (string * int64)) option =
@@ -628,7 +654,8 @@ module Mem = struct
     Option.map
       (fun session_id ->
         debug "delete_reservation %s" reservation_id ;
-        Client.delete_reservation dbg session_id reservation_id)
+        Client.delete_reservation dbg session_id reservation_id
+      )
       (get_session_id dbg)
 
   let delete_reservation dbg r =
@@ -734,7 +761,8 @@ module DeviceCache = struct
   let discard (cache, mutex) domid =
     Mutex.execute mutex (fun () ->
         debug "removing device cache for domid %d" domid ;
-        remove cache domid)
+        remove cache domid
+    )
 
   exception NotFoundIn of string option list
 
@@ -747,7 +775,8 @@ module DeviceCache = struct
             let domid_cache = PerVMCache.create 16 in
             debug "adding device cache for domid %d" domid ;
             replace cache domid domid_cache ;
-            domid_cache)
+            domid_cache
+      )
     in
     Mutex.execute domid_mutex (fun () ->
         let refresh_cache () =
@@ -776,7 +805,8 @@ module DeviceCache = struct
             try PerVMCache.fold (fun k v acc -> k :: acc) domid_cache []
             with _ -> []
           in
-          raise (NotFoundIn keys))
+          raise (NotFoundIn keys)
+    )
 end
 
 let device_cache = DeviceCache.create 256
@@ -961,7 +991,8 @@ module HOST = struct
       , find "flags"
       , find "stepping"
       , find "model"
-      , find "cpu family" )
+      , find "cpu family"
+      )
     in
     let vendor, modelname, speed, flags, stepping, model, family =
       get_cpuinfo ()
@@ -1013,7 +1044,8 @@ module HOST = struct
         ; hypervisor=
             {Host.version= xen_version_string; capabilities= xen_capabilities}
         ; chipset_info= {iommu; hvm}
-        })
+        }
+    )
 
   let stat () =
     match !stat_cache with
@@ -1032,7 +1064,8 @@ module HOST = struct
           x = 13 || x = 10 || (x >= 0x20 && x <= 0x7e)
         in
         Xenctrl.readconsolering xc
-        |> String.mapi (fun i c -> if not (is_printable c) then ' ' else c))
+        |> String.mapi (fun i c -> if not (is_printable c) then ' ' else c)
+    )
 
   let get_total_memory_mib () =
     with_xc_and_xs (fun xc xs ->
@@ -1040,7 +1073,9 @@ module HOST = struct
         Int64.(
           div
             ((Xenctrl.physinfo xc).Xenctrl.total_pages |> of_nativeint)
-            pages_per_mib))
+            pages_per_mib
+        )
+    )
 
   let send_debug_keys keys =
     with_xc_and_xs (fun xc xs -> Xenctrl.send_debug_keys xc keys)
@@ -1068,9 +1103,13 @@ module HOST = struct
                   (if feature.Host.licensed then "1" else "0") ;
                 List.iter
                   (fun (key, value) ->
-                    write_with_perms (Filename.concat parameters_root key) value)
-                  feature.Host.parameters)
-              features))
+                    write_with_perms (Filename.concat parameters_root key) value
+                  )
+                  feature.Host.parameters
+              )
+              features
+        )
+    )
 end
 
 let dB_m = Mutex.create ()
@@ -1086,7 +1125,8 @@ let dm_of ~vm =
             Device.Profile.fallback
         | Some x, _ ->
             x
-      with _ -> Device.Profile.fallback)
+      with _ -> Device.Profile.fallback
+  )
 
 module VM = struct
   open Vm
@@ -1141,7 +1181,8 @@ module VM = struct
   let get_initial_target ~xs domid =
     Int64.of_string
       (xs.Xs.read
-         (Printf.sprintf "/local/domain/%d/memory/initial-target" domid))
+         (Printf.sprintf "/local/domain/%d/memory/initial-target" domid)
+      )
 
   let domain_type_path domid =
     Printf.sprintf "/local/domain/%d/domain-type" domid
@@ -1219,6 +1260,7 @@ module VM = struct
         last_start_time= 0.0
       ; profile= profile_of ~vm
       }
+    
     |> rpc_of VmExtra.persistent_t
     |> Jsonrpc.to_string
 
@@ -1254,13 +1296,17 @@ module VM = struct
         (List.fold_left
            (fun (idx, acc) mask ->
              ( idx + 1
-             , (Printf.sprintf "vcpu/%d/affinity" idx, bitmap mask) :: acc ))
-           (0, []) masks)
+             , (Printf.sprintf "vcpu/%d/affinity" idx, bitmap mask) :: acc
+             )
+           )
+           (0, []) masks
+        )
     in
     let weight =
       vm.scheduler_params.priority
       |> Option.map (fun (w, c) ->
-             [("vcpu/weight", string_of_int w); ("vcpu/cap", string_of_int c)])
+             [("vcpu/weight", string_of_int w); ("vcpu/cap", string_of_int c)]
+         )
       |> Option.value ~default:[]
     in
     let vcpus =
@@ -1268,7 +1314,8 @@ module VM = struct
         ("vcpu/number", string_of_int vm.vcpu_max)
       ; ( "vcpu/current"
         , string_of_int
-            (match vm.ty with PVinPVH _ -> vm.vcpu_max | _ -> vm.vcpus) )
+            (match vm.ty with PVinPVH _ -> vm.vcpu_max | _ -> vm.vcpus)
+        )
       ]
       @ affinity
       @ weight
@@ -1377,8 +1424,10 @@ module VM = struct
                     ; pci_power_mgmt= vm.Vm.pci_power_mgmt
                     ; platformdata= vm.Vm.platformdata
                     }
+                  
                 in
-                Some VmExtra.{persistent})
+                Some VmExtra.{persistent}
+            )
         in
         let _ =
           DB.update k (fun vmextra ->
@@ -1416,7 +1465,8 @@ module VM = struct
                       debug "VM = %s; using stored suspend_memory_bytes = %Ld"
                         vm.Vm.id persistent.VmExtra.suspend_memory_bytes ;
                       ( persistent.VmExtra.suspend_memory_bytes
-                      , persistent.VmExtra.suspend_memory_bytes )
+                      , persistent.VmExtra.suspend_memory_bytes
+                      )
                     ) else (
                       debug
                         "VM = %s; using memory_dynamic_min = %Ld and \
@@ -1441,8 +1491,8 @@ module VM = struct
                            stored some persistent data but it was before we
                            recorded emulation flags. Let's regenerate them now
                            and store them persistently *)
-                        ( (* Sanity check *)
-                        match vm.Xenops_interface.Vm.ty with
+                        (* Sanity check *)
+                        ( match vm.Xenops_interface.Vm.ty with
                         | PVinPVH _ ->
                             failwith
                               "Invalid state! No domain_config persistently \
@@ -1454,6 +1504,7 @@ module VM = struct
                         let persistent =
                           VmExtra.
                             {persistent with domain_config= Some domain_config}
+                          
                         in
                         (domain_config, persistent)
                   in
@@ -1491,9 +1542,12 @@ module VM = struct
                       (i < vm.vcpus)
                   done ;
                   set_domain_type ~xs domid vm ;
-                  Some VmExtra.{persistent}))
+                  Some VmExtra.{persistent}
+              )
+          )
         in
-        ())
+        ()
+    )
 
   let create = create_exn
 
@@ -1504,7 +1558,8 @@ module VM = struct
         | None ->
             raise (Xenopsd_error (Does_not_exist ("domain", vm.Vm.id)))
         | Some di ->
-            f xc xs task vm di)
+            f xc xs task vm di
+    )
 
   let on_domain_if_exists f (task : Xenops_task.task_handle) vm =
     try on_domain f task vm
@@ -1528,25 +1583,31 @@ module VM = struct
               ; ("domid", string_of_int di.Xenctrl.domid)
               ; ("vm", "/vm/" ^ vm.Vm.id)
               ; ( "memory/dynamic-min"
-                , Int64.(to_string (div vm.Vm.memory_dynamic_min 1024L)) )
+                , Int64.(to_string (div vm.Vm.memory_dynamic_min 1024L))
+                )
               ; ( "memory/target"
-                , Int64.(to_string (div vm.Vm.memory_dynamic_min 1024L)) )
+                , Int64.(to_string (div vm.Vm.memory_dynamic_min 1024L))
+                )
               ; ( "memory/dynamic-max"
-                , Int64.(to_string (div vm.Vm.memory_dynamic_max 1024L)) )
+                , Int64.(to_string (div vm.Vm.memory_dynamic_max 1024L))
+                )
               ]
               |> List.map (fun (k, v) ->
-                     (Printf.sprintf "/local/domain/%d/%s" di.Xenctrl.domid k, v))
+                     (Printf.sprintf "/local/domain/%d/%s" di.Xenctrl.domid k, v)
+                 )
             in
             let minimal_vm_kvs =
               [
                 ("uuid", vm.Vm.id)
               ; ("name", vm.Vm.name)
               ; ( Printf.sprintf "domains/%d" di.Xenctrl.domid
-                , Printf.sprintf "/local/domain/%d" di.Xenctrl.domid )
+                , Printf.sprintf "/local/domain/%d" di.Xenctrl.domid
+                )
               ; (Printf.sprintf "domains/%d/create-time" di.Xenctrl.domid, "0")
               ]
               |> List.map (fun (k, v) ->
-                     (Printf.sprintf "/vm/%s/%s" vm.Vm.id k, v))
+                     (Printf.sprintf "/vm/%s/%s" vm.Vm.id k, v)
+                 )
             in
             List.iter
               (fun (k, v) ->
@@ -1558,8 +1619,10 @@ module VM = struct
                 then (
                   debug "xenstore-write %s <- %s" k v ;
                   xs.Xs.write k v
-                ))
-              (minimal_local_kvs @ minimal_vm_kvs))
+                )
+              )
+              (minimal_local_kvs @ minimal_vm_kvs)
+    )
 
   let rename old_name new_name when' =
     with_xc_and_xs @@ fun xc xs ->
@@ -1606,7 +1669,8 @@ module VM = struct
         log_exn_continue "Error stoping vncterm, already dead ?"
           (fun () -> Device.PV_Vnc.stop ~xs domid)
           ()
-        (* If qemu is in a different domain to storage, detach disks *))
+        (* If qemu is in a different domain to storage, detach disks *)
+    )
 
   let destroy =
     on_domain_if_exists (fun xc xs task vm di ->
@@ -1619,7 +1683,8 @@ module VM = struct
               List.filter
                 (fun dev ->
                   let open Device_common in
-                  match dev.frontend.kind with Vbd _ -> true | _ -> false)
+                  match dev.frontend.kind with Vbd _ -> true | _ -> false
+                )
                 devices
             in
             let dps =
@@ -1652,24 +1717,30 @@ module VM = struct
                 try Storage.dp_destroy task dp
                 with e ->
                   warn "Ignoring exception in VM.destroy: %s"
-                    (Printexc.to_string e))
-              dps)
+                    (Printexc.to_string e)
+              )
+              dps
+          )
           (fun () ->
             (* Finally, discard any device caching for the domid destroyed *)
             DeviceCache.discard device_cache di.Xenctrl.domid ;
-            Device.(Qemu.SignalMask.unset Qemu.signal_mask di.Xenctrl.domid)))
+            Device.(Qemu.SignalMask.unset Qemu.signal_mask di.Xenctrl.domid)
+          )
+    )
 
   let pause =
     on_domain (fun xc xs _ _ di ->
         if di.Xenctrl.total_memory_pages = 0n then
           raise (Xenopsd_error Domain_not_built) ;
-        Domain.pause ~xc di.Xenctrl.domid)
+        Domain.pause ~xc di.Xenctrl.domid
+    )
 
   let unpause =
     on_domain (fun xc xs _ _ di ->
         if di.Xenctrl.total_memory_pages = 0n then
           raise (Xenopsd_error Domain_not_built) ;
-        Domain.unpause ~xc di.Xenctrl.domid)
+        Domain.unpause ~xc di.Xenctrl.domid
+    )
 
   let set_xsdata task vm xsdata =
     on_domain
@@ -1697,7 +1768,8 @@ module VM = struct
           for (* need to plug cpus *)
               i = current to target - 1 do
             Device.Vcpu.set ~xs ~dm:(dm_of ~vm) ~devid:i domid true
-          done)
+          done
+      )
       task vm
 
   let set_shadow_multiplier task vm target =
@@ -1721,7 +1793,8 @@ module VM = struct
         if
           not
             (Domain.wait_xen_free_mem xc
-               (Int64.mul (Int64.of_int needed_mib) 1024L))
+               (Int64.mul (Int64.of_int needed_mib) 1024L)
+            )
         then (
           error
             "VM = %s; domid = %d; Failed waiting for Xen to free %d MiB: some \
@@ -1729,12 +1802,14 @@ module VM = struct
             vm.Vm.id domid needed_mib ;
           raise
             (Xenopsd_error
-               (Not_enough_memory
-                  (Memory.bytes_of_mib (Int64.of_int needed_mib))))
+               (Not_enough_memory (Memory.bytes_of_mib (Int64.of_int needed_mib))
+               )
+            )
         ) ;
         debug "VM = %s; domid = %d; shadow_allocation_setto %d MiB" vm.Vm.id
           domid newshadow ;
-        Xenctrl.shadow_allocation_set xc domid newshadow)
+        Xenctrl.shadow_allocation_set xc domid newshadow
+      )
       task vm
 
   let set_memory_dynamic_range task vm min max =
@@ -1745,7 +1820,8 @@ module VM = struct
           ~min:(Int64.to_int (Int64.div min 1024L))
           ~max:(Int64.to_int (Int64.div max 1024L))
           domid ;
-        Mem.balance_memory (Xenops_task.get_dbg task))
+        Mem.balance_memory (Xenops_task.get_dbg task)
+      )
       task vm
 
   let qemu_device_of_vbd_frontend = function
@@ -1786,7 +1862,8 @@ module VM = struct
             | Vgpu, [] ->
                 raise
                   (Xenopsd_error
-                     (Internal_error "Vgpu mode specified but no vGPUs"))
+                     (Internal_error "Vgpu mode specified but no vGPUs")
+                  )
             | Vgpu, vgpus ->
                 Device.Dm.Vgpu vgpus
             | _ ->
@@ -1800,8 +1877,7 @@ module VM = struct
             let static_max_mib =
               Memory.mib_of_kib_used build_info.Domain.memory_max
             in
-            Memory.kib_of_mib
-              (Memory.HVM.build_max_mib static_max_mib video_mib)
+            Memory.kib_of_mib (Memory.HVM.build_max_mib static_max_mib video_mib)
           in
           let open Device.Dm in
           {
@@ -1833,7 +1909,8 @@ module VM = struct
               | Network.Local b | Network.Remote (_, b) ->
                   Some (vif.Vif.mac, b, vif.Vif.position)
               | Network.Sriov _ ->
-                  None)
+                  None
+            )
             vifs
         in
         match ty with
@@ -1863,7 +1940,8 @@ module VM = struct
                     | Vbd.CDROM, _ ->
                         Some (index, path, Cdrom)
                   else
-                    None)
+                    None
+                )
                 vbds
             in
             let usb_enabled =
@@ -1896,7 +1974,8 @@ module VM = struct
                  ?vnc_ip:hvm_info.vnc_ip ~usb ~parallel
                  ~pci_emulations:hvm_info.pci_emulations
                  ~pci_passthrough:hvm_info.pci_passthrough
-                 ~boot_order:hvm_info.boot_order ~nics ~disks ~vgpus ())
+                 ~boot_order:hvm_info.boot_order ~nics ~disks ~vgpus ()
+              )
       )
 
   let clean_memory_reservation task domid =
@@ -1962,7 +2041,8 @@ module VM = struct
                   }
               in
               ( make_build_info !Resources.hvmloader builder_spec_info
-              , hvm_info.timeoffset )
+              , hvm_info.timeoffset
+              )
           | PV {boot= Direct direct} ->
               let builder_spec_info =
                 Domain.BuildPV
@@ -1988,7 +2068,9 @@ module VM = struct
                       }
                   in
                   ( make_build_info b.Bootloader.kernel_path builder_spec_info
-                  , "" ))
+                  , ""
+                  )
+              )
           | PVinPVH {boot= Direct direct} ->
               debug "Checking xen cmdline" ;
               let builder_spec_info =
@@ -2008,6 +2090,7 @@ module VM = struct
                     ; shadow_multiplier= 1.
                     ; video_mib= 0
                     }
+                  
               in
               (make_build_info !Resources.pvinpvh_xen builder_spec_info, "")
           | PVinPVH {boot= Indirect {devices= []}} ->
@@ -2028,7 +2111,8 @@ module VM = struct
                           cmdline= pvinpvh_xen_cmdline
                         ; modules=
                             ( b.Bootloader.kernel_path
-                            , Some b.Bootloader.kernel_args )
+                            , Some b.Bootloader.kernel_args
+                            )
                             ::
                             ( match b.Bootloader.initrd_path with
                             | Some r ->
@@ -2039,8 +2123,10 @@ module VM = struct
                         ; shadow_multiplier= 1.
                         ; video_mib= 0
                         }
+                      
                   in
-                  (make_build_info !Resources.pvinpvh_xen builder_spec_info, ""))
+                  (make_build_info !Resources.pvinpvh_xen builder_spec_info, "")
+              )
         in
         Domain.build task ~xc ~xs ~store_domid ~console_domid ~timeoffset
           ~extras ~vgpus build_info
@@ -2049,7 +2135,8 @@ module VM = struct
         Int64.(
           let min = to_int (div vm.Vm.memory_dynamic_min 1024L)
           and max = to_int (div vm.Vm.memory_dynamic_max 1024L) in
-          Domain.set_memory_dynamic_range ~xc ~xs ~min ~max domid) ;
+          Domain.set_memory_dynamic_range ~xc ~xs ~min ~max domid
+        ) ;
         debug "VM = %s; domid = %d; Domain build completed" vm.Vm.id domid ;
         let _ =
           DB.update_exn vm.Vm.id (fun d ->
@@ -2062,9 +2149,12 @@ module VM = struct
                         build_info= Some build_info
                       ; ty= Some vm.ty
                       }
-                  })
+                  }
+                
+          )
         in
-        ())
+        ()
+      )
       (fun () -> Option.iter Bootloader.delete !kernel_to_cleanup)
 
   let build_domain vm vbds vifs vgpus vusbs extras force xc xs task _ di =
@@ -2115,7 +2205,8 @@ module VM = struct
               Printf.sprintf "VM = %s; domid = %d; Error: %s" vm.Vm.id domid
                 (Printexc.to_string e)
             in
-            debug "%s" m ; raise e)
+            debug "%s" m ; raise e
+      )
       (fun () -> clean_memory_reservation task di.Xenctrl.domid)
 
   let build ?restore_fd task vm vbds vifs vgpus vusbs extras force =
@@ -2140,7 +2231,8 @@ module VM = struct
                 task ~xc ~xs ~dm:qemu_dm info di.Xenctrl.domid ;
               Device.Serial.update_xenstore ~xs di.Xenctrl.domid
           | Vm.PV _ | Vm.PVinPVH _ ->
-              assert false)
+              assert false
+        )
         (create_device_model_config vm vmextra vbds vifs vgpus vusbs) ;
       match vm.Vm.ty with
       | Vm.PV {vncterm= true; vncterm_ip= ip}
@@ -2166,17 +2258,18 @@ module VM = struct
                         xen_platform= Some (xen_platform_of ~vm ~vmextra:d)
                       }
                   }
+                
             | _ ->
                 d
           in
           let () =
             on_domain
-              (create_device_model_exn vbds vifs vgpus vusbs saved_state
-                 vmextra)
+              (create_device_model_exn vbds vifs vgpus vusbs saved_state vmextra)
               task vm
           in
           (* Ensure that the updated vmextra is written back to the DB *)
-          Some vmextra)
+          Some vmextra
+      )
     in
     ()
 
@@ -2201,7 +2294,8 @@ module VM = struct
           Domain.shutdown_wait_for_ack task ~timeout:ack_delay ~xc ~xs domid
             domain_type reason ;
           true
-        with Watch.Timeout _ -> false)
+        with Watch.Timeout _ -> false
+      )
       task vm
 
   let wait_shutdown task vm reason timeout =
@@ -2213,7 +2307,8 @@ module VM = struct
           debug "EVENT on other VM: %s" id ;
           false
       | _ ->
-          debug "OTHER EVENT" ; false)
+          debug "OTHER EVENT" ; false
+      )
 
   (* Mount a filesystem somewhere, with optional type *)
   let mount ?(ty = None) src dest write =
@@ -2253,13 +2348,15 @@ module VM = struct
     finally
       (fun () ->
         mount ~ty:(Some "ext2") device mount_point false ;
-        f mount_point)
+        f mount_point
+      )
       (fun () ->
         ( try umount mount_point
           with e -> debug "Caught %s" (Printexc.to_string e)
         ) ;
         try Unix.rmdir mount_point
-        with e -> debug "Caught %s" (Printexc.to_string e))
+        with e -> debug "Caught %s" (Printexc.to_string e)
+      )
 
   (** open a file, and make sure the close is always done *)
   let with_data ~xc ~xs task data write f =
@@ -2273,7 +2370,8 @@ module VM = struct
                     | `Ok _ ->
                         true
                     | _ ->
-                        false)
+                        false
+                )
               in
               match (write, is_raw_image) with
               | true, _ ->
@@ -2286,7 +2384,8 @@ module VM = struct
                   (* Assume reading from filesystem *)
                   with_mounted_dir_ro p (fun dir ->
                       let filename = dir ^ "/suspend-image" in
-                      Unixext.with_file filename [Unix.O_RDONLY] 0o600 f)
+                      Unixext.with_file filename [Unix.O_RDONLY] 0o600 f
+                  )
             in
             with_fd_of_path path (fun fd ->
                 finally
@@ -2297,7 +2396,10 @@ module VM = struct
                       error
                         "Caught EIO in fsync after suspend; suspend image may \
                          be corrupt" ;
-                      raise (Xenopsd_error IO_error))))
+                      raise (Xenopsd_error IO_error)
+                  )
+            )
+        )
     | FD fd ->
         f fd
 
@@ -2332,8 +2434,10 @@ module VM = struct
             with Watch.Timeout _ ->
               raise
                 (Xenops_interface.Xenopsd_error
-                   Ballooning_timeout_before_migration)
-          ))
+                   Ballooning_timeout_before_migration
+                )
+          )
+      )
       task vm
 
   let assert_can_save vm =
@@ -2343,7 +2447,8 @@ module VM = struct
         | None ->
             failwith (Printf.sprintf "VM %s disappeared" (Uuidm.to_string uuid))
         | Some domid ->
-            Device.Dm.assert_can_suspend ~xs ~dm:(dm_of ~vm) domid)
+            Device.Dm.assert_can_suspend ~xs ~dm:(dm_of ~vm) domid
+    )
 
   let save task progress_callback vm flags data vgpu_data pre_suspend_callback =
     let flags' = List.map (function Live -> Domain.Live) flags in
@@ -2388,7 +2493,8 @@ module VM = struct
                 if not (request_shutdown task vm Suspend 30.) then
                   raise (Xenopsd_error Failed_to_acknowledge_suspend_request) ;
                 if not (wait_shutdown task vm Suspend 1200.) then
-                  raise (Xenopsd_error (Failed_to_suspend (vm.Vm.id, 1200.)))) ;
+                  raise (Xenopsd_error (Failed_to_suspend (vm.Vm.id, 1200.)))
+            ) ;
             (* Record the final memory usage of the domain so we know how much
                to allocate for the resume *)
             let di = Xenctrl.domain_getinfo xc domid in
@@ -2407,7 +2513,8 @@ module VM = struct
                   | Device_common.Vbd _ ->
                       true
                   | _ ->
-                      false)
+                      false
+                )
                 devices
             in
             List.iter (Device.Vbd.hard_shutdown_request ~xs) vbds ;
@@ -2432,7 +2539,10 @@ module VM = struct
                             (Xenopsd_error
                                (Internal_error
                                   (Printf.sprintf
-                                     "Failed to unmarshal VBD backend: %s" m)))
+                                     "Failed to unmarshal VBD backend: %s" m
+                                  )
+                               )
+                            )
                     in
                     let dp = Device.Generic.get_private_key ~xs device _dp_id in
                     match backend with
@@ -2441,8 +2551,10 @@ module VM = struct
                         ()
                     | Some (VDI path) ->
                         let sr, vdi = Storage.get_disk_by_name task path in
-                        Storage.deactivate task dp sr vdi vmid)
-                  vbds_chunk)
+                        Storage.deactivate task dp sr vdi vmid
+                  )
+                  vbds_chunk
+              )
               (Xenops_utils.chunks 10 vbds) ;
             debug "VM = %s; domid = %d; Storing final memory usage" vm.Vm.id
               domid ;
@@ -2456,9 +2568,13 @@ module VM = struct
                             d.persistent with
                             suspend_memory_bytes= Memory.bytes_of_pages pages
                           }
-                      })
+                      }
+                    
+              )
             in
-            ()))
+            ()
+        )
+      )
       task vm
 
   let inject_igmp_query domid vifs =
@@ -2493,8 +2609,7 @@ module VM = struct
               | {VmExtra.build_info= None} ->
                   error "VM = %s; No stored build_info: cannot safely restore"
                     vm.Vm.id ;
-                  raise
-                    (Xenopsd_error (Does_not_exist ("build_info", vm.Vm.id)))
+                  raise (Xenopsd_error (Does_not_exist ("build_info", vm.Vm.id)))
               | {VmExtra.build_info= Some x; VmExtra.ty} ->
                   let initial_target = get_initial_target ~xs domid in
                   let timeoffset =
@@ -2530,10 +2645,10 @@ module VM = struct
                       ~console_domid
                       ~no_incr_generationid (* XXX progress_callback *)
                       ~timeoffset ~extras build_info ~manager_path domid fd
-                      vgpu_fd)
+                      vgpu_fd
+                )
               with e ->
-                error "VM %s: restore failed: %s" vm.Vm.id
-                  (Printexc.to_string e) ;
+                error "VM %s: restore failed: %s" vm.Vm.id (Printexc.to_string e) ;
                 (* As of xen-unstable.hg 779c0ef9682 libxenguest will destroy
                    the domain on failure *)
                 ( if
@@ -2557,27 +2672,31 @@ module VM = struct
             Int64.(
               let min = to_int (div vm.Vm.memory_dynamic_min 1024L)
               and max = to_int (div vm.Vm.memory_dynamic_max 1024L) in
-              Domain.set_memory_dynamic_range ~xc ~xs ~min ~max domid) ;
+              Domain.set_memory_dynamic_range ~xc ~xs ~min ~max domid
+            ) ;
             try inject_igmp_query domid vifs |> ignore
             with e ->
               error "VM %s: inject IGMP query failed: %s" vm.Vm.id
-                (Printexc.to_string e))
-          (fun () -> clean_memory_reservation task di.Xenctrl.domid))
+                (Printexc.to_string e)
+          )
+          (fun () -> clean_memory_reservation task di.Xenctrl.domid)
+      )
       task vm
 
   let s3suspend =
     (* XXX: TODO: monitor the guest's response; track the s3 state *)
     on_domain (fun xc xs task vm di ->
-        Domain.shutdown ~xc ~xs di.Xenctrl.domid Domain.S3Suspend)
+        Domain.shutdown ~xc ~xs di.Xenctrl.domid Domain.S3Suspend
+    )
 
   let s3resume =
     (* XXX: TODO: monitor the guest's response; track the s3 state *)
-    on_domain (fun xc xs task vm di ->
-        Domain.send_s3resume ~xc di.Xenctrl.domid)
+    on_domain (fun xc xs task vm di -> Domain.send_s3resume ~xc di.Xenctrl.domid)
 
   let soft_reset =
     on_domain (fun xc xs task vm di ->
-        Domain.soft_reset ~xc ~xs di.Xenctrl.domid)
+        Domain.soft_reset ~xc ~xs di.Xenctrl.domid
+    )
 
   let get_state vm =
     let uuid = uuid_of_vm vm in
@@ -2604,7 +2723,8 @@ module VM = struct
                   | Device.Socket.Port port ->
                       {Vm.protocol= Vm.Rfb; port; path= ""}
                   | Device.Socket.Unix path ->
-                      {Vm.protocol= Vm.Rfb; port= 0; path})
+                      {Vm.protocol= Vm.Rfb; port= 0; path}
+                  )
                 (Device.get_vnc_port ~xs ~dm:(dm_of ~vm) di.Xenctrl.domid)
             in
             let tc =
@@ -2659,8 +2779,7 @@ module VM = struct
             let rtc =
               try
                 xs.Xs.read
-                  (Printf.sprintf "/vm/%s/rtc/timeoffset"
-                     (Uuidm.to_string uuid))
+                  (Printf.sprintf "/vm/%s/rtc/timeoffset" (Uuidm.to_string uuid))
               with Xs_protocol.Enoent _ -> ""
             in
             let ls_l ~depth root dir =
@@ -2693,7 +2812,8 @@ module VM = struct
                   | Some ((k, v) as entry) ->
                       ( quota
                         - Xenops_utils.xenstore_encoded_entry_size_bytes k v
-                      , entry :: acc )
+                      , entry :: acc
+                      )
                   | None ->
                       (quota, acc)
                 in
@@ -2722,7 +2842,8 @@ module VM = struct
                    (fun acc (dir, excludes, depth) ->
                      ls_lR ?excludes ~depth
                        (Printf.sprintf "/local/domain/%d" di.Xenctrl.domid)
-                       acc dir)
+                       acc dir
+                   )
                    (quota, [])
               |> fun (quota, acc) ->
               (quota, map_tr (fun (k, v) -> (k, Xenops_utils.utf8_recode v)) acc)
@@ -2855,7 +2976,8 @@ module VM = struct
                 | Some x ->
                     List.assoc "featureset" x.VmExtra.persistent.platformdata
                 )
-            })
+            }
+    )
 
   let request_rdp vm enabled =
     let uuid = uuid_of_vm vm in
@@ -2867,7 +2989,8 @@ module VM = struct
             let path =
               Printf.sprintf "/local/domain/%d/control/ts" di.Xenctrl.domid
             in
-            xs.Xs.write path (if enabled then "1" else "0"))
+            xs.Xs.write path (if enabled then "1" else "0")
+    )
 
   let run_script task vm script =
     let uuid = uuid_of_vm vm in
@@ -2885,9 +3008,12 @@ module VM = struct
                     (Xenopsd_error
                        (Unimplemented
                           "run-script is not supported on the given VM (or it \
-                           is still booting)"))
+                           is still booting)"
+                       )
+                    )
               in
-              (di.Xenctrl.domid, path ^ "/control/batcmd"))
+              (di.Xenctrl.domid, path ^ "/control/batcmd")
+      )
     in
     let () =
       with_xc_and_xs (fun xc xs ->
@@ -2902,23 +3028,28 @@ module VM = struct
                 (Xenopsd_error
                    (Failed_to_run_script
                       "A residual run-script instance in progress, either wait \
-                       for its completion or reboot the VM."))
+                       for its completion or reboot the VM."
+                   )
+                )
           | _ ->
               info
                 "Found previous run_script state %s leftover (either not \
                  started or completed), remove."
                 state ;
-              xs.Xs.rm path)
+              xs.Xs.rm path
+      )
     in
     let () =
       Xs.transaction () (fun xs ->
           xs.Xs.write (path ^ "/script") script ;
-          xs.Xs.write (path ^ "/state") "READY")
+          xs.Xs.write (path ^ "/state") "READY"
+      )
     in
     let watch_succ =
       List.map
         (fun s ->
-          Watch.map (fun _ -> ()) (Watch.value_to_become (path ^ "/state") s))
+          Watch.map (fun _ -> ()) (Watch.value_to_become (path ^ "/state") s)
+        )
         ["SUCCESS"; "TRUNCATED"; "FAILURE"]
     in
     let watch_fail = [Watch.key_to_disappear path] in
@@ -2933,7 +3064,8 @@ module VM = struct
           let stdout = try xs.Xs.read (path ^ "/stdout") with _ -> "" in
           let stderr = try xs.Xs.read (path ^ "/stderr") with _ -> "" in
           xs.Xs.rm path ;
-          (succ, flag, rc, stdout, stderr))
+          (succ, flag, rc, stdout, stderr)
+      )
     in
     if not succ then Xenops_task.raise_cancelled task ;
     let truncate s =
@@ -2960,7 +3092,10 @@ module VM = struct
           (Xenopsd_error
              (Failed_to_run_script
                 (Printf.sprintf "flag = %s, rc = %s, stdour = %s, stderr = %s"
-                   flag rc stdout stderr)))
+                   flag rc stdout stderr
+                )
+             )
+          )
 
   let set_domain_action_request vm request =
     let uuid = uuid_of_vm vm in
@@ -2983,7 +3118,8 @@ module VM = struct
                      poweroff"
                     vm.Vm.id ;
                   Some "poweroff"
-              ))
+              )
+    )
 
   let get_domain_action_request vm =
     let uuid = uuid_of_vm vm in
@@ -3024,7 +3160,8 @@ module VM = struct
                   Some Needs_poweroff
               | None ->
                   None
-          ))
+          )
+    )
 
   (* Some hook scripts need to know the domid to avoid confusion when migrating
      vms, now that the behaviour concerning uuids has changed *)
@@ -3034,7 +3171,8 @@ module VM = struct
         | None ->
             []
         | Some domid ->
-            [Xenops_hooks.arg__vmdomid; string_of_int domid])
+            [Xenops_hooks.arg__vmdomid; string_of_int domid]
+    )
 
   let get_internal_state vdi_map vif_map vm =
     let state = DB.read_exn vm.Vm.id in
@@ -3078,7 +3216,9 @@ module VM = struct
           raise
             (Xenopsd_error
                (Internal_error
-                  (Printf.sprintf "Failed to unmarshal persistent_t: %s" m)))
+                  (Printf.sprintf "Failed to unmarshal persistent_t: %s" m)
+               )
+            )
     in
     (* Don't take the timeoffset from [state] (last boot record). Put back the
        one from [vm] which came straight from the platform keys. *)
@@ -3146,7 +3286,8 @@ let on_frontend f frontend =
         | Some x ->
             x
       in
-      f xc xs frontend_di.Xenctrl.domid (VM.get_domain_type ~xs frontend_di))
+      f xc xs frontend_di.Xenctrl.domid (VM.get_domain_type ~xs frontend_di)
+  )
 
 module PCI = struct
   open Pci
@@ -3162,7 +3303,8 @@ module PCI = struct
           | None ->
               []
         in
-        {plugged= List.mem pci_addr all})
+        {plugged= List.mem pci_addr all}
+    )
 
   let get_state vm pci = get_state' vm pci.address
 
@@ -3188,11 +3330,13 @@ module PCI = struct
         let persistent = vm_t.VmExtra.persistent in
         xs.Xs.write
           (Printf.sprintf "/local/domain/0/backend/pci/%d/0/msitranslate"
-             frontend_domid)
+             frontend_domid
+          )
           (if persistent.VmExtra.pci_msitranslate then "1" else "0") ;
         xs.Xs.write
           (Printf.sprintf "/local/domain/0/backend/pci/%d/0/power_mgmt"
-             frontend_domid)
+             frontend_domid
+          )
           (if persistent.VmExtra.pci_power_mgmt then "1" else "0") ;
         if not (Sys.file_exists "/sys/bus/pci/drivers/pciback") then (
           error "PCIBack has not been loaded" ;
@@ -3207,8 +3351,10 @@ module PCI = struct
         let device =
           Device.PCI.
             {host= pci.address; guest= (index, guest_pci); qmp_add= advertise}
+          
         in
-        Device.PCI.add ~xc ~xs ~hvm [device] frontend_domid)
+        Device.PCI.add ~xc ~xs ~hvm [device] frontend_domid
+      )
       vm
 
   let unplug task vm pci =
@@ -3233,7 +3379,8 @@ let set_active_device path active =
       if active then
         xs.Xs.write path "1"
       else
-        safe_rm xs path)
+        safe_rm xs path
+  )
 
 module VGPU = struct
   open Vgpu
@@ -3259,7 +3406,8 @@ module VGPU = struct
           | Some p ->
               p
         in
-        Device.Dm.restore_vgpu task ~xc ~xs frontend_domid vgpus vcpus profile)
+        Device.Dm.restore_vgpu task ~xc ~xs frontend_domid vgpus vcpus profile
+      )
       vm
 
   let active_path vm vgpu =
@@ -3289,7 +3437,8 @@ module VGPU = struct
         | Some pid ->
             {Vgpu.active= true; plugged= true; emulator_pid}
         | None ->
-            {Vgpu.active= get_active vm vgpu; plugged= false; emulator_pid})
+            {Vgpu.active= get_active vm vgpu; plugged= false; emulator_pid}
+      )
       vm
 end
 
@@ -3309,7 +3458,8 @@ module VUSB = struct
         | Some pid, true ->
             {plugged= true}
         | _, _ ->
-            {plugged= false})
+            {plugged= false}
+      )
       vm
 
   let get_device_action_request vm vusb =
@@ -3338,7 +3488,8 @@ module VUSB = struct
           Device.Vusb.vusb_plug ~xs ~privileged ~domid:frontend_domid
             ~id:(snd vusb.Vusb.id) ~hostbus:vusb.Vusb.hostbus
             ~hostport:vusb.Vusb.hostport ~version:vusb.Vusb.version
-            ~speed:vusb.Vusb.speed)
+            ~speed:vusb.Vusb.speed
+      )
       vm
 
   let unplug task vm vusb =
@@ -3348,7 +3499,8 @@ module VUSB = struct
           let privileged = is_privileged vm in
           Device.Vusb.vusb_unplug ~xs ~privileged ~domid:frontend_domid
             ~id:(snd vusb.Vusb.id) ~hostbus:vusb.Vusb.hostbus
-            ~hostport:vusb.Vusb.hostport)
+            ~hostport:vusb.Vusb.hostport
+        )
         vm
     with
     | Xenopsd_error (Does_not_exist (_, _)) ->
@@ -3384,6 +3536,7 @@ module VBD = struct
                     ; BlockDevice {path= ""}
                     ]
                 }
+              
           }
       | Some (Local path) ->
           {
@@ -3397,6 +3550,7 @@ module VBD = struct
                     ; BlockDevice {path}
                     ]
                 }
+              
           }
       | Some (VDI path) ->
           let sr, vdi = Storage.get_disk_by_name task path in
@@ -3441,7 +3595,8 @@ module VBD = struct
             in
             Storage.epoch_begin task sr vdi storage_vm persistent
         | _ ->
-            ())
+            ()
+    )
 
   let epoch_end task vm disk =
     with_xc_and_xs (fun xc xs ->
@@ -3456,7 +3611,8 @@ module VBD = struct
             in
             Storage.epoch_end task sr vdi storage_vm
         | _ ->
-            ())
+            ()
+    )
 
   let _backend_kind = "backend-kind"
 
@@ -3482,15 +3638,16 @@ module VBD = struct
           let _, xenstore_data, _ = params_of_backend vdi.attach_info in
           (* Use the storage manager's preference *)
           if List.mem_assoc _backend_kind xenstore_data then
-            Device_common.kind_of_string
-              (List.assoc _backend_kind xenstore_data)
+            Device_common.kind_of_string (List.assoc _backend_kind xenstore_data)
           else
             Device_common.Vbd !Xenopsd.default_vbd_backend_kind
       | Some (Error (`Msg m)) ->
           raise
             (Xenopsd_error
                (Internal_error
-                  (Printf.sprintf "Error unmarshalling attached_vdi: %s" m)))
+                  (Printf.sprintf "Error unmarshalling attached_vdi: %s" m)
+               )
+            )
 
   let vdi_path_of_device ~xs device =
     Device_common.backend_path_of_device ~xs device ^ "/vdi"
@@ -3571,14 +3728,16 @@ module VBD = struct
                 (fun () ->
                   Device.Vbd.add task ~xc ~xs
                     ~hvm:(domain_type = Vm.Domain_HVM)
-                    x frontend_domid)
+                    x frontend_domid
+                )
             in
             (* We store away the disk so we can implement VBD.stat *)
             Option.iter
               (fun d ->
                 xs.Xs.write
                   (vdi_path_of_device ~xs dev)
-                  (d |> rpc_of disk |> Jsonrpc.to_string))
+                  (d |> rpc_of disk |> Jsonrpc.to_string)
+              )
               vbd.backend ;
             (* NB now the frontend position has been resolved *)
             let open Device_common in
@@ -3632,10 +3791,14 @@ module VBD = struct
                                 qemu_vbds=
                                   (vbd.Vbd.id, q) :: vm_t.persistent.qemu_vbds
                               }
-                          })
+                          }
+                        
+                  )
                 in
-                ())
-              qemu_frontend)
+                ()
+              )
+              qemu_frontend
+        )
         vm
 
   let unplug task vm vbd force =
@@ -3659,12 +3822,10 @@ module VBD = struct
               Some (device_by_id xc xs vm (device_kind_of ~xs vbd) (id_of vbd))
             with
             | Xenopsd_error (Does_not_exist (_, _)) ->
-                debug "VM = %s; VBD = %s; Ignoring missing domain" vm
-                  (id_of vbd) ;
+                debug "VM = %s; VBD = %s; Ignoring missing domain" vm (id_of vbd) ;
                 None
             | Xenopsd_error Device_not_connected ->
-                debug "VM = %s; VBD = %s; Ignoring missing device" vm
-                  (id_of vbd) ;
+                debug "VM = %s; VBD = %s; Ignoring missing device" vm (id_of vbd) ;
                 None
           in
           let backend =
@@ -3685,7 +3846,10 @@ module VBD = struct
                     (Xenopsd_error
                        (Internal_error
                           (Printf.sprintf "Failed to unmarshal VBD backend: %s"
-                             m)))
+                             m
+                          )
+                       )
+                    )
             )
           in
           Option.iter
@@ -3702,7 +3866,9 @@ module VBD = struct
                 (Printf.sprintf "Vbd.clean_shutdown %s" (id_of vbd))
                 (fun () ->
                   (if force then Device.hard_shutdown else Device.clean_shutdown)
-                    task ~xs dev))
+                    task ~xs dev
+                )
+            )
             dev ;
           (* We now have a shutdown device but an active DP: we should destroy
              the DP if the backend is of type VDI *)
@@ -3712,7 +3878,8 @@ module VBD = struct
                 (fun dev ->
                   Xenops_task.with_subtask task
                     (Printf.sprintf "Vbd.release %s" (id_of vbd))
-                    (fun () -> Device.Vbd.release task ~xc ~xs dev))
+                    (fun () -> Device.Vbd.release task ~xc ~xs dev)
+                )
                 dev ;
               (* If we have a qemu frontend, detach this too. *)
               let _ =
@@ -3737,20 +3904,26 @@ module VBD = struct
                                      persistent.qemu_vbds
                                }
                            }
+                         
                        ) else
-                         vm_t))
+                         vm_t
+                   )
+                  )
               in
-              ())
+              ()
+            )
             (fun () ->
               match (domid, backend) with
               | Some x, None | Some x, Some (VDI _) ->
                   Storage.dp_destroy task
                     (Storage.id_of (string_of_int x) vbd.Vbd.id)
               | _ ->
-                  ())
+                  ()
+            )
         with Device_common.Device_error (_, s) ->
           debug "Caught Device_error: %s" s ;
-          raise (Xenopsd_error (Device_detach_rejected ("VBD", id_of vbd, s))))
+          raise (Xenopsd_error (Device_detach_rejected ("VBD", id_of vbd, s)))
+    )
 
   let insert task vm vbd d =
     on_frontend
@@ -3771,7 +3944,8 @@ module VBD = struct
             (vdi_path_of_device ~xs device)
             (d |> rpc_of disk |> Jsonrpc.to_string) ;
           Device.Vbd.media_insert ~xs ~dm:(dm_of ~vm) ~phystype ~params device ;
-          Device_common.add_backend_keys ~xs device "sm-data" xenstore_data)
+          Device_common.add_backend_keys ~xs device "sm-data" xenstore_data
+      )
       vm
 
   let eject task vm vbd =
@@ -3786,7 +3960,9 @@ module VBD = struct
         Storage.dp_destroy task
           (Storage.id_of
              (string_of_int (frontend_domid_of_device device))
-             vbd.Vbd.id))
+             vbd.Vbd.id
+          )
+      )
       vm
 
   let ionice qos pid =
@@ -3812,8 +3988,10 @@ module VBD = struct
                   paths
               with e ->
                 error "Failed to ionice kthread-pid: %s" (Printexc.to_string e)
-            ))
-          vbd.Vbd.qos)
+            )
+            )
+          vbd.Vbd.qos
+    )
 
   let get_qos xc xs vm vbd device =
     try
@@ -3865,7 +4043,9 @@ module VBD = struct
                     raise
                       (Xenopsd_error
                          (Internal_error
-                            (Printf.sprintf "Failed to unmarshal disk: %s" m)))
+                            (Printf.sprintf "Failed to unmarshal disk: %s" m)
+                         )
+                      )
                 )
           in
           {
@@ -3878,7 +4058,8 @@ module VBD = struct
         | Xenopsd_error (Does_not_exist (_, _))
         | Xenopsd_error Device_not_connected
         ->
-          {unplugged_vbd with Vbd.active= get_active vm vbd})
+          {unplugged_vbd with Vbd.active= get_active vm vbd}
+    )
 
   let get_device_action_request vm vbd =
     with_xc_and_xs (fun xc xs ->
@@ -3906,7 +4087,8 @@ module VBD = struct
         with Xenopsd_error Device_not_connected ->
           debug "VM = %s; VBD = %s; Device_not_connected so no action required"
             vm (id_of vbd) ;
-          None)
+          None
+    )
 end
 
 module VIF = struct
@@ -3979,7 +4161,9 @@ module VIF = struct
             (Xenopsd_error
                (Internal_error
                   "Static IPv4 configuration selected, but no address \
-                   specified."))
+                   specified."
+               )
+            )
     in
     let ipv6_setting =
       match vif.ipv6_configuration with
@@ -4001,7 +4185,9 @@ module VIF = struct
             (Xenopsd_error
                (Internal_error
                   "Static IPv6 configuration selected, but no address \
-                   specified."))
+                   specified."
+               )
+            )
     in
     let settings = constant_setting @ ipv4_setting @ ipv6_setting in
     List.map
@@ -4025,10 +4211,13 @@ module VIF = struct
               let open Printf in
               [
                 ( sprintf "pvs-server-%d-addresses" i
-                , String.concat "," server.addresses )
+                , String.concat "," server.addresses
+                )
               ; ( sprintf "pvs-server-%d-ports" i
-                , sprintf "%d-%d" server.first_port server.last_port )
-              ])
+                , sprintf "%d-%d" server.first_port server.last_port
+                )
+              ]
+            )
             srvs
           |> List.flatten
         in
@@ -4084,7 +4273,8 @@ module VIF = struct
           in
           List.iter
             (fun interface ->
-              Interface.DB.write interface.Interface.Interface.name interface)
+              Interface.DB.write interface.Interface.Interface.name interface
+            )
             interfaces ;
           Xenops_task.with_subtask task
             (Printf.sprintf "Vif.add %s" (id_of vif))
@@ -4098,7 +4288,8 @@ module VIF = struct
                     let setup_pvs_proxy_rules =
                       [
                         ( "setup-pvs-proxy-rules"
-                        , !Xc_resources.setup_pvs_proxy_rules )
+                        , !Xc_resources.setup_pvs_proxy_rules
+                        )
                       ]
                     in
                     let pvs_proxy = xenstore_of_pvs_proxy vif.pvs_proxy in
@@ -4131,7 +4322,9 @@ module VIF = struct
                       ~extra_xenserver_keys:(static_ip_setting @ [("mac", mac)])
                       task frontend_domid
                   in
-                  ()))
+                  ()
+            )
+        )
         vm
 
   let plug task vm = plug_exn task vm
@@ -4154,7 +4347,8 @@ module VIF = struct
                     else
                       Device.clean_shutdown
                     )
-                      task ~xs device) ;
+                      task ~xs device
+                  ) ;
                 Xenops_task.with_subtask task
                   (Printf.sprintf "Vif.release %s" (id_of vif))
                   (fun () -> Device.Vif.release task ~xc ~xs device)
@@ -4183,10 +4377,13 @@ module VIF = struct
                                        vm_t.persistent.qemu_vifs
                                  }
                              }
+                           
                        | _, _ ->
                            vm_t
                      else
-                       vm_t))
+                       vm_t
+                 )
+                )
               |> ignore
           | Network.Sriov _ ->
               Xenops_task.with_subtask task
@@ -4201,13 +4398,15 @@ module VIF = struct
           let interfaces = interfaces_of_vif domid vif.id vif.position in
           List.iter
             (fun interface ->
-              Interface.DB.remove interface.Interface.Interface.name)
+              Interface.DB.remove interface.Interface.Interface.name
+            )
             interfaces
         with
         | Xenopsd_error (Does_not_exist (_, _)) ->
             debug "VM = %s; Ignoring missing domain" (id_of vif)
         | Xenopsd_error Device_not_connected ->
-            debug "VM = %s; Ignoring missing device" (id_of vif)) ;
+            debug "VM = %s; Ignoring missing device" (id_of vif)
+    ) ;
     ()
 
   let move task vm vif network =
@@ -4246,17 +4445,20 @@ module VIF = struct
                                     persistent.qemu_vifs
                               }
                           }
+                        
                   | _, _ ->
                       Some vm_t
                 else
-                  Some vm_t)
+                  Some vm_t
+            )
           in
           ()
         with
         | Xenopsd_error (Does_not_exist (_, _)) ->
             debug "VM = %s; Ignoring missing domain" (id_of vif)
         | Xenopsd_error Device_not_connected ->
-            debug "VM = %s; Ignoring missing device" (id_of vif)) ;
+            debug "VM = %s; Ignoring missing device" (id_of vif)
+    ) ;
     ()
 
   let set_carrier task vm vif carrier =
@@ -4276,7 +4478,8 @@ module VIF = struct
         | Xenopsd_error (Does_not_exist (_, _)) ->
             debug "VM = %s; Ignoring missing domain" (id_of vif)
         | Xenopsd_error Device_not_connected ->
-            debug "VM = %s; Ignoring missing device" (id_of vif))
+            debug "VM = %s; Ignoring missing device" (id_of vif)
+    )
 
   let set_locking_mode task vm vif mode =
     with_xc_and_xs (fun xc xs ->
@@ -4308,7 +4511,8 @@ module VIF = struct
             ignore
               (run
                  !Xc_resources.setup_vif_rules
-                 ["classic"; vif_interface_name; vm; devid; "filter"]) ;
+                 ["classic"; vif_interface_name; vm; devid; "filter"]
+              ) ;
             (* Update rules for the tap device if the VM has booted HVM with no
                PV drivers. *)
             let di = Xenctrl.domain_getinfo xc device.frontend.domid in
@@ -4316,7 +4520,9 @@ module VIF = struct
               ignore
                 (run
                    !Xc_resources.setup_vif_rules
-                   ["classic"; tap_interface_name; vm; devid; "filter"]))
+                   ["classic"; tap_interface_name; vm; devid; "filter"]
+                )
+    )
 
   let set_ip_unspecified xs xenstore_path suffix =
     Xs.transaction xs (fun t ->
@@ -4331,7 +4537,8 @@ module VIF = struct
         let ip_setting_gateway =
           Printf.sprintf "%s/%s%s" xenstore_path "gateway" suffix
         in
-        t.Xst.rm ip_setting_gateway)
+        t.Xst.rm ip_setting_gateway
+    )
 
   let set_ip_static xs xenstore_path suffix address gateway =
     Xs.transaction xs (fun t ->
@@ -4351,7 +4558,8 @@ module VIF = struct
             t.Xst.rm ip_setting_gateway
         | Some value ->
             debug "xenstore-write %s <- %s" ip_setting_gateway value ;
-            t.Xst.write ip_setting_gateway value)
+            t.Xst.write ip_setting_gateway value
+    )
 
   let set_ipv4_configuration task vm vif ipv4_configuration =
     with_xc_and_xs (fun xc xs ->
@@ -4371,7 +4579,10 @@ module VIF = struct
               (Xenopsd_error
                  (Internal_error
                     "Static IPv4 configuration selected, but no address \
-                     specified.")))
+                     specified."
+                 )
+              )
+    )
 
   let set_ipv6_configuration task vm vif ipv6_configuration =
     with_xc_and_xs (fun xc xs ->
@@ -4391,7 +4602,10 @@ module VIF = struct
               (Xenopsd_error
                  (Internal_error
                     "Static IPv6 configuration selected, but no address \
-                     specified.")))
+                     specified."
+                 )
+              )
+    )
 
   let set_pvs_proxy task vm vif proxy =
     with_xc_and_xs (fun xc xs ->
@@ -4424,7 +4638,8 @@ module VIF = struct
                    ; vif_interface_name
                    ; private_path
                    ; hotplug_path
-                   ]) ;
+                   ]
+                ) ;
               if VM.get_domain_type ~xs di = Vm.Domain_HVM then
                 try
                   ignore
@@ -4436,7 +4651,8 @@ module VIF = struct
                        ; tap_interface_name
                        ; private_path
                        ; hotplug_path
-                       ])
+                       ]
+                    )
                 with _ ->
                   (* There won't be a tap device if the VM has PV drivers
                      loaded. *)
@@ -4451,13 +4667,17 @@ module VIF = struct
                       if
                         Astring.String.is_prefix ~affix:pvs_proxy_key_prefix key
                       then
-                        t.Xs.rm (Printf.sprintf "%s/%s" private_path key))
-                    keys)
+                        t.Xs.rm (Printf.sprintf "%s/%s" private_path key)
+                    )
+                    keys
+              )
             ) else (
               Xs.transaction xs (fun t ->
-                  t.Xs.writev private_path (xenstore_of_pvs_proxy proxy)) ;
+                  t.Xs.writev private_path (xenstore_of_pvs_proxy proxy)
+              ) ;
               setup "add"
-            ))
+            )
+    )
 
   let get_state vm vif =
     with_xc_and_xs (fun xc xs ->
@@ -4513,7 +4733,8 @@ module VIF = struct
         | Xenopsd_error (Does_not_exist (_, _))
         | Xenopsd_error Device_not_connected
         ->
-          {unplugged_vif with Vif.active= get_active vm vif})
+          {unplugged_vif with Vif.active= get_active vm vif}
+    )
 
   let get_device_action_request vm vif =
     with_xc_and_xs (fun xc xs ->
@@ -4530,7 +4751,8 @@ module VIF = struct
             else
               Some Needs_unplug
           with Xenopsd_error Device_not_connected -> None
-        ))
+        )
+    )
 end
 
 module UPDATES = struct
@@ -4566,7 +4788,9 @@ module Actions = struct
                  VmExtra.{persistent}
              | _ ->
                  extra
-             )))
+             )
+             )
+          )
     in
     ()
 
@@ -4582,7 +4806,8 @@ module Actions = struct
             let pv_drivers_detected =
               match
                 ( value = xenbus_connected
-                , persistent.VmExtra.pv_drivers_detected )
+                , persistent.VmExtra.pv_drivers_detected
+                )
               with
               | true, false ->
                   (* State "connected" (4) means that PV drivers are present for
@@ -4602,9 +4827,11 @@ module Actions = struct
                         try
                           xs.Xs.read
                             (Device_common.backend_state_path_of_device ~xs
-                               device)
+                               device
+                            )
                           = xenbus_connected
-                        with Xs_protocol.Enoent _ -> false)
+                        with Xs_protocol.Enoent _ -> false
+                      )
                       devices
                   in
                   if not found then (* No devices in state "connected" (4) *)
@@ -4620,7 +4847,9 @@ module Actions = struct
                      let persistent =
                        {persistent with VmExtra.pv_drivers_detected}
                      in
-                     VmExtra.{persistent}))
+                     VmExtra.{persistent}
+                     )
+                  )
             in
             if updated then
               Updates.add (Dynamic.Vm vm) internal_updates
@@ -4629,7 +4858,8 @@ module Actions = struct
             ()
             (* the path must have disappeared immediately after the watch fired.
                Let's treat this as if we never saw it. *)
-        ))
+        )
+        )
       (DB.read vm)
 
   let interesting_paths_for_domain domid uuid =
@@ -4672,7 +4902,8 @@ module Actions = struct
     let devid = dev.frontend.devid in
     List.map
       (fun k ->
-        Printf.sprintf "/local/domain/%d/backend/%s/%d/%d/%s" be kind fe devid k)
+        Printf.sprintf "/local/domain/%d/backend/%s/%d/%d/%s" be kind fe devid k
+      )
       interesting_backend_keys
 
   let unmanaged_domain domid id = domid > 0 && not (DB.exists id)
@@ -4689,7 +4920,8 @@ module Actions = struct
     let token = watch_token domid in
     List.iter
       (fun d ->
-        List.iter (Xenstore_watch.unwatch ~xs token) (watches_of_device d))
+        List.iter (Xenstore_watch.unwatch ~xs token) (watches_of_device d)
+      )
       (try IntMap.find domid !device_watches with Not_found -> []) ;
     device_watches := IntMap.remove domid !device_watches ;
     (* Anyone blocked on a domain/device operation which won't happen because
@@ -4870,8 +5102,7 @@ module Actions = struct
           register_rrd_plugin ~domid:(int_of_string domid) ~name ~grant_refs
             ~protocol
         with e ->
-          debug "Failed to register RRD plugin: caught %s"
-            (Printexc.to_string e)
+          debug "Failed to register RRD plugin: caught %s" (Printexc.to_string e)
       )
     | ["local"; "domain"; domid; "rrd"; name; "shutdown"] ->
         let value =
@@ -4897,7 +5128,8 @@ module Actions = struct
             (* Store the rtc/timeoffset for migrate *)
             store_rtc_timeoffset uuid timeoffset ;
             (* Tell the higher-level toolstack about this too *)
-            Updates.add (Dynamic.Vm uuid) internal_updates)
+            Updates.add (Dynamic.Vm uuid) internal_updates
+          )
           timeoffset
     | _ ->
         debug "Ignoring unexpected watch: %s" path
@@ -4980,7 +5212,8 @@ let init () =
   if !Xenopsd.run_hotplug_scripts then
     with_xs (fun xs ->
         xs.Xs.write disable_udev_path "1" ;
-        info "Written %s to disable the hotplug/udev scripts" disable_udev_path) ;
+        info "Written %s to disable the hotplug/udev scripts" disable_udev_path
+    ) ;
   (* XXX: is this completely redundant now? The Citrix PV drivers don't need
      this any more *)
   (* Special XS entry looked for by the XenSource PV drivers (see
@@ -4993,7 +5226,8 @@ let init () =
   with_xs (fun xs ->
       xs.Xs.write xe_key xe_val ;
       xs.Xs.setperms xe_key
-        {Xs_protocol.ACL.owner= 0; other= Xs_protocol.ACL.READ; acl= []}) ;
+        {Xs_protocol.ACL.owner= 0; other= Xs_protocol.ACL.READ; acl= []}
+  ) ;
   Device.Backend.init () ;
   Domain.numa_init () ;
   debug "xenstore is responding to requests" ;
@@ -5010,7 +5244,8 @@ module DEBUG = struct
             | None ->
                 raise (Xenopsd_error (Does_not_exist ("domain", k)))
             | Some di ->
-                Xenctrl.domain_shutdown xc di.Xenctrl.domid Xenctrl.Reboot)
+                Xenctrl.domain_shutdown xc di.Xenctrl.domid Xenctrl.Reboot
+        )
     | _ ->
         debug "DEBUG.trigger cmd=%s Unimplemented" cmd ;
         raise (Xenopsd_error (Unimplemented cmd))
diff --git a/xc/xenstore_readdir.ml b/xc/xenstore_readdir.ml
index d77fd1b5e..10049b960 100644
--- a/xc/xenstore_readdir.ml
+++ b/xc/xenstore_readdir.ml
@@ -57,7 +57,8 @@ let ls ~xs = function
           for i = String.length path to longest + 5 do
             print_string " "
           done ;
-          print_endline (Xsraw.string_of_perms perm))
+          print_endline (Xsraw.string_of_perms perm)
+        )
         paths
   | _ ->
       failwith "ls takes exactly one argument"
@@ -125,9 +126,11 @@ let _ =
       if !mode = "" then
         mode := x
       else
-        paths := x :: !paths)
+        paths := x :: !paths
+    )
     (Printf.sprintf "Manipulate xenstore\nAvailable commands are:\n%s\n"
-       (available_commands ())) ;
+       (available_commands ())
+    ) ;
   let paths = List.rev !paths in
   let mode = !mode in
   let xs = Xs.daemon_open () in

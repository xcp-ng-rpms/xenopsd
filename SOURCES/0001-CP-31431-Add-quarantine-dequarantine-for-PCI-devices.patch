From 6a95c01ae3f6eed7efd91fa82b1f8b291988d03c Mon Sep 17 00:00:00 2001
From: Ming Lu <ming.lu@citrix.com>
Date: Tue, 25 Jun 2019 14:22:17 +0800
Subject: [PATCH] CP-31431: Add quarantine/dequarantine for PCI devices

This commit makes changes for CA-297891, in which a special domain is
used in Xen to quarantine the PCI devices for pass-through. The
quarantine means a separate I/O address space for DMA of PCI device. Two
cases are considered in this commit:

1. when a PCI device is going to be passed-through to a guest domain, it
will be placed into quarantine firstly (done by toolstack). Later on,
when it is deassigned from the guest domain, it will be placed (done by
Xen) to quarantine domain, rather than the dom0.

2. when a PCI device, which had been passed-through to a guest domain and
now it is in quarantine, is going to be managed by host driver running on
dom0 to emulate virtual devices (not PCI pass-through), it should be
moved out from quarantine and assigned back to dom0. I.E. NVIDIA vGPUs
and Intel vGPUs.
---
 c_stubs/xenctrlext_stubs.c | 50 +++++++++++++++++++++++++++++++++++++++++---
 lib/xenopsd.ml             |  2 ++
 xc/device.ml               | 52 +++++++++++++++++++++++++++++++++++-----------
 xc/device.mli              | 10 ++++-----
 xc/xenctrlext.ml           | 10 +++++++++
 xc/xenctrlext.mli          |  8 +++++++
 xc/xenops_server_xen.ml    | 14 ++++++-------
 7 files changed, 119 insertions(+), 27 deletions(-)

diff --git a/c_stubs/xenctrlext_stubs.c b/c_stubs/xenctrlext_stubs.c
index 0e94895..e225753 100644
--- a/c_stubs/xenctrlext_stubs.c
+++ b/c_stubs/xenctrlext_stubs.c
@@ -27,28 +27,44 @@
 #include <caml/fail.h>
 #include <caml/signals.h>
 #include <caml/callback.h>
+#include <caml/unixsupport.h>
 
 #define _H(__h) ((xc_interface *)(__h))
 #define _D(__d) ((uint32_t)Int_val(__d))
 
 /* From xenctrl_stubs */
 #define ERROR_STRLEN 1024
+
+static void raise_unix_errno_msg(int err_code, const char *err_msg)
+{
+        CAMLparam0();
+        value args[] = { unix_error_of_code(err_code), caml_copy_string(err_msg) };
+
+        caml_raise_with_args(*caml_named_value("Xenctrlext.Unix_error"),
+                             sizeof(args)/sizeof(args[0]), args);
+        CAMLnoreturn;
+}
+
 static void failwith_xc(xc_interface *xch)
 {
         static char error_str[ERROR_STRLEN];
+        int real_errno = -1;
         if (xch) {
                 const xc_error *error = xc_get_last_error(xch);
-                if (error->code == XC_ERROR_NONE)
+                if (error->code == XC_ERROR_NONE) {
+                        real_errno = errno;
                         snprintf(error_str, ERROR_STRLEN, "%d: %s", errno, strerror(errno));
-                else
+                } else {
+                        real_errno = error->code;
                         snprintf(error_str, ERROR_STRLEN, "%d: %s: %s",
                                  error->code,
                                  xc_error_code_to_desc(error->code),
                                  error->message);
+                }
         } else {
                 snprintf(error_str, ERROR_STRLEN, "Unable to open XC interface");
         }
-        caml_raise_with_string(*caml_named_value("xc.error"), error_str);
+        raise_unix_errno_msg(real_errno, error_str);
 }
 
 CAMLprim value stub_xenctrlext_get_runstate_info(value xch, value domid)
@@ -195,6 +211,34 @@ CAMLprim value stub_xenctrlext_domain_set_target(value xch,
 	CAMLreturn(Val_unit);
 }
 
+CAMLprim value stub_xenctrlext_assign_device(value xch, value domid,
+        value machine_sbdf, value flag)
+{
+    CAMLparam4(xch, domid, machine_sbdf, flag);
+    caml_enter_blocking_section();
+    int retval = xc_assign_device(_H(xch), _D(domid), Int_val(machine_sbdf), Int_val(flag));
+    caml_leave_blocking_section();
+    if (retval)
+        failwith_xc(_H(xch));
+    CAMLreturn(Val_unit);
+}
+
+CAMLprim value stub_xenctrlext_deassign_device(value xch, value domid, value machine_sbdf)
+{
+    CAMLparam3(xch, domid, machine_sbdf);
+    caml_enter_blocking_section();
+    int retval = xc_deassign_device(_H(xch), _D(domid), Int_val(machine_sbdf));
+    caml_leave_blocking_section();
+    if (retval)
+        failwith_xc(_H(xch));
+    CAMLreturn(Val_unit);
+}
+
+CAMLprim value stub_xenctrlext_domid_quarantine(value unit)
+{
+    CAMLparam1(unit);
+    CAMLreturn(Val_int(DOMID_IO));
+}
 
 /*
 * Local variables:
diff --git a/lib/xenopsd.ml b/lib/xenopsd.ml
index 5b80c10..0f4fcce 100644
--- a/lib/xenopsd.ml
+++ b/lib/xenopsd.ml
@@ -30,6 +30,7 @@ let hotplug_timeout = ref 300.
 let qemu_dm_ready_timeout = ref 300.
 let vgpu_ready_timeout = ref 30.
 let use_upstream_qemu = ref false
+let pci_quarantine = ref true
 
 let watch_queue_length = ref 1000
 
@@ -64,6 +65,7 @@ let options = [
   "action-after-qemu-crash", Arg.String (fun x -> action_after_qemu_crash := if x="" then None else Some x), (fun () -> match !action_after_qemu_crash with None->"" | Some x->x), "Action to take for VMs if QEMU crashes or dies unexpectedly: pause, poweroff. Otherwise, no action (default).";
   "feature-flags-path", Arg.Set_string feature_flags_path, (fun () -> !feature_flags_path), "Directory of experimental feature flags";
   "pvinpvh-xen-cmdline", Arg.Set_string pvinpvh_xen_cmdline, (fun () -> !pvinpvh_xen_cmdline), "Command line for the inner-xen for PV-in-PVH guests";
+  "pci-quarantine", Arg.Bool (fun b -> pci_quarantine := b), (fun () -> string_of_bool !pci_quarantine), "True if IOMMU contexts of PCI devices are needed to be placed in quarantine";
 ]
 
 let path () = Filename.concat !sockets_path "xenopsd"
diff --git a/xc/device.ml b/xc/device.ml
index fbd289a..ba7ea76 100644
--- a/xc/device.ml
+++ b/xc/device.ml
@@ -1079,10 +1079,35 @@ module PCI = struct
     (* Sort into the order the devices were plugged *)
     List.sort (fun a b -> compare (fst a) (fst b)) pairs
 
-  let add ~xs pcidevs domid =
+  let encode_bdf pci =
+    (pci.Xenops_interface.Pci.domain lsl 16)
+    lor ((pci.bus land 0xff) lsl 8)
+    lor ((pci.dev land 0x1f) lsl 3)
+    lor (pci.fn  land 0x7)
+
+  let _quarantine xc pci quarantine =
+    let pci_bdf = encode_bdf pci in
+    let domid = Xenctrlext.domid_quarantine () in
+    try
+      match quarantine with
+      | true -> Xenctrlext.assign_device xc domid pci_bdf 0; true
+      | false -> Xenctrlext.deassign_device xc domid pci_bdf; true
+    with
+    | Xenctrlext.Unix_error (Unix.ESRCH, _) -> false
+    | Xenctrlext.Unix_error (Unix.ENODEV, _) -> false
+    | e -> raise e
+
+  let quarantine xc pci =
+    _quarantine xc pci true
+
+  let dequarantine xc pci =
+    _quarantine xc pci false
+
+  let add ~xc ~xs pcidevs domid =
     try
       let current = read_pcidir ~xs domid in
       let next_idx = List.fold_left max (-1) (List.map fst current) + 1 in
+      if !Xenopsd.pci_quarantine then List.iter (fun x -> ignore(quarantine xc x)) pcidevs;
       add_xl pcidevs domid;
       List.iteri
         (fun count address ->
@@ -2682,7 +2707,7 @@ module Dm = struct
 
   (* the following functions depend on the functions above that use the qemu backend Q *)
 
-  let start_vgpu ~xs task ?(restore=false) domid vgpus vcpus profile =
+  let start_vgpu ~xc ~xs task ?(restore=false) domid vgpus vcpus profile =
     let open Xenops_interface.Vgpu in
     match vgpus with
     | [{physical_pci_address = pci; implementation = Nvidia vgpu}] ->
@@ -2695,6 +2720,8 @@ module Dm = struct
            			 * a vGPU on a device which is passed through to a guest. *)
         debug "start_vgpu: got VGPU with physical pci address %s"
           (Xenops_interface.Pci.string_of_address pci);
+        let pcis = List.map (fun x -> x.physical_pci_address) vgpus in
+        if !Xenopsd.pci_quarantine then List.iter (fun x -> ignore(PCI.dequarantine xc x)) pcis;
         PCI.bind [pci] PCI.Nvidia;
         let args = vgpu_args_of_nvidia domid vcpus vgpu pci restore in
         let vgpu_pid = start_daemon ~path:!Xc_resources.vgpu ~args ~name:"vgpu"
@@ -2721,6 +2748,7 @@ module Dm = struct
         raise (Ioemu_failed ("vgpu", Printf.sprintf "Daemon vgpu returned error: %s" error_code))
       end
     | [{physical_pci_address = pci; implementation = GVT_g vgpu}] ->
+      if !Xenopsd.pci_quarantine then ignore(PCI.dequarantine xc pci);
       PCI.bind [pci] PCI.I915
     | [{physical_pci_address = pci; implementation = MxGPU vgpu}] ->
       Mutex.execute gimtool_m (fun () ->
@@ -2736,7 +2764,7 @@ module Dm = struct
   type action = Start | Restore | StartVNC
 
   let __start (task: Xenops_task.task_handle)
-      ~xs ~dm ?(timeout = !Xenopsd.qemu_dm_ready_timeout) action info domid =
+      ~xc ~xs ~dm ?(timeout = !Xenopsd.qemu_dm_ready_timeout) action info domid =
 
     let args = match action with
       | Start    -> qemu_args ~xs ~dm info false domid
@@ -2751,7 +2779,7 @@ module Dm = struct
     let () = match info.disp with
       | VNC (Vgpu vgpus, _, _, _, _)
       | SDL (Vgpu vgpus, _) ->
-        start_vgpu ~xs task domid vgpus info.vcpus dm
+        start_vgpu ~xc ~xs task domid vgpus info.vcpus dm
       | _ -> ()
     in
 
@@ -2805,18 +2833,18 @@ module Dm = struct
               xs.Xs.write (Qemu.pid_path_signal domid) crash_reason
         ))
 
-  let start (task: Xenops_task.task_handle) ~xs ~dm ?timeout info domid =
-    __start task ~xs ~dm ?timeout Start info domid
+  let start (task: Xenops_task.task_handle) ~xc ~xs ~dm ?timeout info domid =
+    __start task ~xc ~xs ~dm ?timeout Start info domid
 
-  let restore (task: Xenops_task.task_handle) ~xs ~dm ?timeout info domid =
-    __start task ~xs ~dm ?timeout Restore info domid
+  let restore (task: Xenops_task.task_handle) ~xc ~xs ~dm ?timeout info domid =
+    __start task ~xc ~xs ~dm ?timeout Restore info domid
 
-  let start_vnconly (task: Xenops_task.task_handle) ~xs ~dm ?timeout info domid =
-    __start task ~xs ~dm ?timeout StartVNC info domid
+  let start_vnconly (task: Xenops_task.task_handle) ~xc ~xs ~dm ?timeout info domid =
+    __start task ~xc ~xs ~dm ?timeout StartVNC info domid
 
-  let restore_vgpu (task: Xenops_task.task_handle) ~xs domid vgpu vcpus =
+  let restore_vgpu (task: Xenops_task.task_handle) ~xc ~xs domid vgpu vcpus =
     debug "Called Dm.restore_vgpu";
-    start_vgpu ~xs task ~restore:true domid [vgpu] vcpus Profile.Qemu_trad
+    start_vgpu ~xc ~xs task ~restore:true domid [vgpu] vcpus Profile.Qemu_trad
 
 end (* Dm *)
 
diff --git a/xc/device.mli b/xc/device.mli
index 2c19bb0..313e587 100644
--- a/xc/device.mli
+++ b/xc/device.mli
@@ -203,7 +203,7 @@ sig
 
   exception Cannot_use_pci_with_no_pciback of t list
 
-  val add : xs:Xenstore.Xs.xsh -> address list -> Xenctrl.domid -> unit
+  val add : xc:Xenctrl.handle -> xs:Xenstore.Xs.xsh -> address list -> Xenctrl.domid -> unit
   val release : address list -> Xenctrl.domid -> unit
   val reset : xs:Xenstore.Xs.xsh -> address -> unit
   val bind : address list -> supported_driver -> unit
@@ -282,13 +282,13 @@ sig
     -> int  (** domid *)
     -> qemu_args
 
-  val start : Xenops_task.task_handle -> xs:Xenstore.Xs.xsh -> dm:Profile.t -> ?timeout:float -> info -> Xenctrl.domid -> unit
-  val start_vnconly : Xenops_task.task_handle -> xs:Xenstore.Xs.xsh -> dm:Profile.t -> ?timeout:float -> info -> Xenctrl.domid -> unit
-  val restore : Xenops_task.task_handle -> xs:Xenstore.Xs.xsh -> dm:Profile.t -> ?timeout:float -> info -> Xenctrl.domid -> unit
+  val start : Xenops_task.task_handle -> xc:Xenctrl.handle -> xs:Xenstore.Xs.xsh -> dm:Profile.t -> ?timeout:float -> info -> Xenctrl.domid -> unit
+  val start_vnconly : Xenops_task.task_handle -> xc:Xenctrl.handle -> xs:Xenstore.Xs.xsh -> dm:Profile.t -> ?timeout:float -> info -> Xenctrl.domid -> unit
+  val restore : Xenops_task.task_handle -> xc:Xenctrl.handle -> xs:Xenstore.Xs.xsh -> dm:Profile.t -> ?timeout:float -> info -> Xenctrl.domid -> unit
   val suspend : Xenops_task.task_handle -> xs:Xenstore.Xs.xsh -> qemu_domid:int -> dm:Profile.t -> Xenctrl.domid -> unit
   val resume : Xenops_task.task_handle -> xs:Xenstore.Xs.xsh -> qemu_domid:int -> Xenctrl.domid -> unit
   val stop : xs:Xenstore.Xs.xsh -> qemu_domid:int -> dm:Profile.t -> Xenctrl.domid -> unit
-  val restore_vgpu : Xenops_task.task_handle -> xs:Xenstore.Xs.xsh -> Xenctrl.domid  -> Xenops_interface.Vgpu.t -> int -> unit
+  val restore_vgpu : Xenops_task.task_handle -> xc:Xenctrl.handle -> xs:Xenstore.Xs.xsh -> Xenctrl.domid  -> Xenops_interface.Vgpu.t -> int -> unit
 
   val after_suspend_image: xs:Xenstore.Xs.xsh -> dm:Profile.t -> qemu_domid:int -> int -> unit
 end
diff --git a/xc/xenctrlext.ml b/xc/xenctrlext.ml
index 5c8b0b0..72c5ae5 100644
--- a/xc/xenctrlext.ml
+++ b/xc/xenctrlext.ml
@@ -23,6 +23,10 @@ external domain_get_acpi_s_state: handle -> domid -> int = "stub_xenctrlext_doma
 
 external domain_suppress_spurious_page_faults: handle -> domid -> unit = "stub_xenctrlext_domain_suppress_spurious_page_faults"
 
+exception Unix_error of Unix.error * string
+
+let _ = Callback.register_exception "Xenctrlext.Unix_error" (Unix_error(Unix.E2BIG, ""))
+
 type runstateinfo = {
   state : int32;
   missed_changes: int32;
@@ -40,3 +44,9 @@ external domain_get_runstate_info : handle -> int -> runstateinfo = "stub_xenctr
 external get_max_nr_cpus: handle -> int = "stub_xenctrlext_get_max_nr_cpus"
 
 external domain_set_target: handle -> domid -> domid -> unit = "stub_xenctrlext_domain_set_target"
+
+external assign_device: handle -> domid -> int -> int -> unit = "stub_xenctrlext_assign_device"
+
+external deassign_device: handle -> domid -> int -> unit = "stub_xenctrlext_deassign_device"
+
+external domid_quarantine: unit -> int = "stub_xenctrlext_domid_quarantine"
diff --git a/xc/xenctrlext.mli b/xc/xenctrlext.mli
index 5c8b0b0..8be6c9a 100644
--- a/xc/xenctrlext.mli
+++ b/xc/xenctrlext.mli
@@ -23,6 +23,8 @@ external domain_get_acpi_s_state: handle -> domid -> int = "stub_xenctrlext_doma
 
 external domain_suppress_spurious_page_faults: handle -> domid -> unit = "stub_xenctrlext_domain_suppress_spurious_page_faults"
 
+exception Unix_error of Unix.error * string
+
 type runstateinfo = {
   state : int32;
   missed_changes: int32;
@@ -40,3 +42,9 @@ external domain_get_runstate_info : handle -> int -> runstateinfo = "stub_xenctr
 external get_max_nr_cpus: handle -> int = "stub_xenctrlext_get_max_nr_cpus"
 
 external domain_set_target: handle -> domid -> domid -> unit = "stub_xenctrlext_domain_set_target"
+
+external assign_device: handle -> domid -> int -> int -> unit = "stub_xenctrlext_assign_device"
+
+external deassign_device: handle -> domid -> int -> unit = "stub_xenctrlext_deassign_device"
+
+external domid_quarantine: unit -> int = "stub_xenctrlext_domid_quarantine"
diff --git a/xc/xenops_server_xen.ml b/xc/xenops_server_xen.ml
index 1540098..3c76670 100644
--- a/xc/xenops_server_xen.ml
+++ b/xc/xenops_server_xen.ml
@@ -1589,19 +1589,19 @@ module VM = struct
             Opt.iter
               (fun stubdom_domid ->
                  Stubdom.build task ~xc ~xs ~dm:qemu_dm ~store_domid ~console_domid info xenguest di.Xenctrl.domid stubdom_domid;
-                 Device.Dm.start_vnconly task ~xs ~dm:qemu_dm info stubdom_domid
+                 Device.Dm.start_vnconly task ~xc ~xs ~dm:qemu_dm info stubdom_domid
               ) (get_stubdom ~xs di.Xenctrl.domid);
           | Vm.HVM { Vm.qemu_stubdom = false } ->
             (if saved_state then Device.Dm.restore else Device.Dm.start)
-              task ~xs ~dm:qemu_dm info di.Xenctrl.domid
+              task ~xc ~xs ~dm:qemu_dm info di.Xenctrl.domid
           | Vm.PV _ ->
             Device.Vfb.add ~xc ~xs di.Xenctrl.domid;
             Device.Vkbd.add ~xc ~xs di.Xenctrl.domid;
-            Device.Dm.start_vnconly task ~xs ~dm:qemu_dm info di.Xenctrl.domid
+            Device.Dm.start_vnconly task ~xc ~xs ~dm:qemu_dm info di.Xenctrl.domid
           | Vm.PVinPVH _ ->
             Device.Vfb.add ~xc ~xs di.Xenctrl.domid;
             Device.Vkbd.add ~xc ~xs di.Xenctrl.domid;
-            Device.Dm.start_vnconly task ~xs ~dm:qemu_dm info di.Xenctrl.domid
+            Device.Dm.start_vnconly task ~xc ~xs ~dm:qemu_dm info di.Xenctrl.domid
         ) (create_device_model_config vm vmextra vbds vifs vgpus vusbs);
       match vm.Vm.ty with
       | Vm.PV { vncterm = true; vncterm_ip = ip }
@@ -2202,7 +2202,7 @@ module PCI = struct
          end;
 
          Device.PCI.bind [ pci.address ] Device.PCI.Pciback;
-         Device.PCI.add xs [ pci.address ] frontend_domid
+         Device.PCI.add xc xs [ pci.address ] frontend_domid
       ) vm
 
   let unplug task vm pci =
@@ -2228,7 +2228,7 @@ module VGPU = struct
 
   let start task vm vgpu saved_state =
     on_frontend
-      (fun _ xs frontend_domid _ ->
+      (fun xc xs frontend_domid _ ->
          let vmextra = DB.read_exn vm in
          let vcpus = match vmextra.VmExtra.persistent with
            | { VmExtra.build_info = None } ->
@@ -2237,7 +2237,7 @@ module VGPU = struct
            | { VmExtra.build_info = Some build_info } ->
              build_info.Domain.vcpus
          in
-         Device.Dm.restore_vgpu task ~xs frontend_domid vgpu vcpus
+         Device.Dm.restore_vgpu task ~xc ~xs frontend_domid vgpu vcpus
       ) vm
 
   let get_state vm vgpu =
-- 
2.7.4

